{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sn\n",
    "from keras.utils import to_categorical, plot_model, np_utils\n",
    "from random import randrange\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, LabelBinarizer\n",
    "\n",
    "num_classes = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(gerar_estatisticas=False):\n",
    "    # Formata os arquivos em dicionário na forma:\n",
    "    # {'a': [0...[0...[0...30]...100]...10]}\n",
    "    # 30 dados (gx, gy, gz, ax, ay, az para 5 dedos)\n",
    "    # com 100 amostras para cada sinal\n",
    "    # e realizado 10 vezes\n",
    "\n",
    "    directory = 'Dados_completos'\n",
    "    letras = os.listdir(directory) \n",
    "    num_letras = len(letras)\n",
    "\n",
    "    dataset = pd.DataFrame()\n",
    "\n",
    "    files = {}\n",
    "    for letra in letras:\n",
    "        files[letra] = os.listdir(directory+'/'+letra)\n",
    "\n",
    "    stats = []\n",
    "    all_dataframe = {}\n",
    "\n",
    "    for letra, value_list in files.items():\n",
    "        for f in value_list:\n",
    "            with open(directory+\"/\"+letra+\"/\"+f) as file:\n",
    "                lines = [line.strip() for line in file]\n",
    "                lines = ast.literal_eval(lines[0])\n",
    "                test = pd.DataFrame(lines)\n",
    "                test['label'] = letra\n",
    "                dataset = dataset.append(test, ignore_index = True)\n",
    "                \n",
    "                if gerar_estatisticas:\n",
    "                    d = {'media':test.mean(), \n",
    "                         'desvio_padrao': test.std(), \n",
    "                         'max': test.max(), \n",
    "                         'min': test.min()\n",
    "                        }\n",
    "                    stats.append(pd.DataFrame(d))\n",
    "\n",
    "                    if letra not in all_dataframe:\n",
    "                        all_dataframe[letra] = []\n",
    "                    all_dataframe[letra].append(test)\n",
    "    \n",
    "    if gerar_estatisticas:\n",
    "        if not os.path.exists('./estatisticas'):\n",
    "            os.mkdir('./estatisticas')\n",
    "\n",
    "        estatisticas = {}\n",
    "        i = 0;\n",
    "        for letr in letras:\n",
    "            estatisticas[letr] = stats[i:i+10]\n",
    "            i+=10\n",
    "\n",
    "        for key,list_values in estatisticas.items():\n",
    "            for i,v in enumerate(list_values):\n",
    "                v.to_excel('./estatisticas/' + key+'_'+str(i)+'.xlsx')\n",
    "                \n",
    "    return dataset, all_dataframe, letras\n",
    "\n",
    "def get_minidataset(dataset):\n",
    "    directory = 'Dados_completos'\n",
    "    letras = os.listdir(directory) \n",
    "    \n",
    "    # mini_dataset_train = []\n",
    "    mini_dataset_test = []\n",
    "    nums_gerados = []\n",
    "    mini_dataset_test = pd.DataFrame()\n",
    "    mini_dataset_train = pd.DataFrame()\n",
    "    for letr in letras:\n",
    "        for i in range(10):\n",
    "    #         aleat = randrange(100)+100*i\n",
    "            aleat = [ num + 100*i for num in random.sample(range(100), 11) ]\n",
    "            nums_gerados = nums_gerados + aleat\n",
    "    #         mini_dataset_train.append(dataset[dataset.label==letr].iloc[aleat[0]])\n",
    "            # 10*10 amostras para treino\n",
    "            mini_dataset_train = mini_dataset_train.append(dataset[dataset.label==letr].iloc[aleat[:10]])\n",
    "            # 1 * 10 amostras para teste\n",
    "            mini_dataset_test = mini_dataset_test.append(dataset[dataset.label==letr].iloc[aleat[10]])\n",
    "\n",
    "    mini_dataset_train = pd.DataFrame(mini_dataset_train).reset_index()\n",
    "    mini_dataset_train = mini_dataset_train.drop('index', 1)\n",
    "\n",
    "    mini_dataset_test = pd.DataFrame(mini_dataset_test).reset_index()\n",
    "    mini_dataset_test = mini_dataset_test.drop('index', 1)\n",
    "\n",
    "    # Apaga os dados de teste do dataset\n",
    "    tmp = 0\n",
    "    for i,num in enumerate(nums_gerados):\n",
    "        if(i!= 0 and i%110==0):\n",
    "            tmp += 1000\n",
    "        dataset = dataset.drop(num+tmp)\n",
    "\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "    # mini_dataset_train.to_csv('mini_dataset_train.csv')\n",
    "    # mini_dataset_test.to_csv('mini_dataset_test.csv')\n",
    "    \n",
    "# save_histogramas(all_dataframe, letras)\n",
    "# get_estatisticas_por_letra(estatisticas, letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dic_conv_hist():\n",
    "    nome_dados = ['ax0', 'ay0', 'az0', 'gx0', 'gy0', 'gz0',\n",
    "                 'ax1', 'ay1', 'az1', 'gx1', 'gy1', 'gz1',\n",
    "                 'ax2', 'ay2', 'az2', 'gx2', 'gy2', 'gz2',\n",
    "                 'ax3', 'ay3', 'az3', 'gx3', 'gy3', 'gz3',\n",
    "                 'ax4', 'ay4', 'az4', 'gx4', 'gy4', 'gz4']\n",
    "\n",
    "    dic_conv_hist = {}\n",
    "    for i,nom in enumerate(nome_dados):\n",
    "        dic_conv_hist[i] = nom\n",
    "    return dic_conv_hist\n",
    "        \n",
    "\n",
    "def save_histogramas(all_dataframe, letras):\n",
    "    if not os.path.exists('./histogramas'):\n",
    "        os.mkdir('./histogramas')\n",
    "\n",
    "    for letra in letras:\n",
    "        if not os.path.exists('./histogramas/'+letra):\n",
    "            os.mkdir('./histogramas/'+letra)\n",
    "        for ex in range(10):\n",
    "            if not os.path.exists('./histogramas/'+letra+\"/\"+str(ex)):\n",
    "                os.mkdir('./histogramas/'+letra+\"/\"+str(ex))\n",
    "        \n",
    "    dic_conv_hist = gerar_dic_conv_hist()\n",
    "\n",
    "    for letra in letras:\n",
    "        for ex in range(10):\n",
    "            direc = './histogramas/'+letra+\"/\"+ str(ex) + \"/\"\n",
    "            for dado in range(30):\n",
    "                figure = all_dataframe[letra][ex].iloc[:,dado].hist(bins=100, range=[-16384, 16383]).get_figure()\n",
    "                plt.tight_layout()\n",
    "                figure.savefig(direc + letra + \"_\" + dic_conv_hist[dado] + \".png\")\n",
    "                plt.clf()\n",
    "                \n",
    "\n",
    "def get_estatisticas_por_letra(estatisticas, letras):\n",
    "\n",
    "    est_letra = {}\n",
    "    for key,list_values in estatisticas.items():\n",
    "        est_letra[key] = pd.DataFrame()\n",
    "        for i,v in enumerate(list_values):\n",
    "            est_letra[key] = est_letra[key].append(pd.DataFrame(v))\n",
    "        est_letra[key] = est_letra[key].reset_index()\n",
    "\n",
    "    est_tmp = {}\n",
    "    dic_conv_hist = gerar_dic_conv_hist()\n",
    "\n",
    "    for letra in letras:\n",
    "        est_tmp[letra] = []\n",
    "        for i in range(30):\n",
    "            tmp_pd = est_letra[letra][i::30]\n",
    "            dic_tmp = {'desvio_padrao': tmp_pd['desvio_padrao'].std(ddof=0), \n",
    "                       'max': tmp_pd['max'].max(), \n",
    "                       'min': tmp_pd['min'].min(),\n",
    "                       'media': tmp_pd['media'].mean(),\n",
    "#                        'label': dic_conv_hist[i]\n",
    "                      }\n",
    "            est_tmp[letra].append(pd.DataFrame(dic_tmp, index=[i]))\n",
    "    \n",
    "    if not os.path.exists('./estatisticas_gerais'):\n",
    "        os.mkdir('./estatisticas_gerais')\n",
    "    \n",
    "    estatisticas_geral = {}\n",
    "    for letra in letras:\n",
    "        estatisticas_geral[letra] = pd.concat(est_tmp[letra])\n",
    "        estatisticas_geral[letra].to_csv('./estatisticas_gerais/'+letra+'.csv')\n",
    "        \n",
    "    return estatisticas_geral\n",
    "\n",
    "# Check num of samples of the same class\n",
    "def get_index_letra(letra, _y):\n",
    "    _lst_letra = []\n",
    "    for i,y in enumerate(_y):\n",
    "        if y.argmax()==letra:\n",
    "            _lst_letra.append(i)\n",
    "    return _lst_letra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, all_dataframe, letras = get_dataset(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save_histogramas(all_dataframe, letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:30] \n",
    "y = dataset.iloc[:,30] \n",
    "\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X = X/16384\n",
    "# 50% treino + 50% (val + test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, stratify=y) \n",
    "# 25% val e 25% test\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, stratify=y_test)\n",
    "\n",
    "X_train = X_train.reset_index().iloc[:,1:31]\n",
    "X_test = X_test.reset_index().iloc[:,1:31]\n",
    "X_val = X_val.reset_index().iloc[:,1:31]\n",
    "\n",
    "# Tranform training labels to one-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Tranform test labels to one-hot encoding\n",
    "y_val = np_utils.to_categorical(y_val, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.363037</td>\n",
       "      <td>0.869141</td>\n",
       "      <td>-0.257080</td>\n",
       "      <td>-0.009460</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>0.302734</td>\n",
       "      <td>0.884521</td>\n",
       "      <td>-0.383789</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995361</td>\n",
       "      <td>-0.014832</td>\n",
       "      <td>-0.014832</td>\n",
       "      <td>-0.007263</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.955322</td>\n",
       "      <td>-0.123047</td>\n",
       "      <td>-0.026733</td>\n",
       "      <td>0.028259</td>\n",
       "      <td>-0.006958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.804688</td>\n",
       "      <td>-0.468018</td>\n",
       "      <td>0.391846</td>\n",
       "      <td>-0.038269</td>\n",
       "      <td>-0.018127</td>\n",
       "      <td>-0.017273</td>\n",
       "      <td>-0.129150</td>\n",
       "      <td>-0.731445</td>\n",
       "      <td>0.599854</td>\n",
       "      <td>-0.081482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825928</td>\n",
       "      <td>-0.030823</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.135498</td>\n",
       "      <td>0.506104</td>\n",
       "      <td>0.824951</td>\n",
       "      <td>-0.055298</td>\n",
       "      <td>0.032654</td>\n",
       "      <td>-0.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.276855</td>\n",
       "      <td>-0.964844</td>\n",
       "      <td>-0.111816</td>\n",
       "      <td>-0.013916</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.145264</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.383545</td>\n",
       "      <td>-0.032654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791260</td>\n",
       "      <td>0.021362</td>\n",
       "      <td>-0.021851</td>\n",
       "      <td>-0.002197</td>\n",
       "      <td>0.204346</td>\n",
       "      <td>0.958496</td>\n",
       "      <td>0.127197</td>\n",
       "      <td>-0.014771</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.508545</td>\n",
       "      <td>0.880615</td>\n",
       "      <td>-0.007080</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.043030</td>\n",
       "      <td>0.278076</td>\n",
       "      <td>0.948975</td>\n",
       "      <td>-0.346191</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730469</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>-0.034363</td>\n",
       "      <td>0.023804</td>\n",
       "      <td>0.336426</td>\n",
       "      <td>-0.758545</td>\n",
       "      <td>-0.686035</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.026245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.832275</td>\n",
       "      <td>-0.472412</td>\n",
       "      <td>0.453613</td>\n",
       "      <td>-0.071960</td>\n",
       "      <td>0.058533</td>\n",
       "      <td>0.080444</td>\n",
       "      <td>-0.318359</td>\n",
       "      <td>-0.689209</td>\n",
       "      <td>0.649414</td>\n",
       "      <td>0.041260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463623</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>-0.039612</td>\n",
       "      <td>0.055481</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>-0.955811</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>-0.011230</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>0.055359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13495</td>\n",
       "      <td>0.595947</td>\n",
       "      <td>-0.658203</td>\n",
       "      <td>0.599609</td>\n",
       "      <td>-0.046753</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>-0.013184</td>\n",
       "      <td>0.308350</td>\n",
       "      <td>-0.904053</td>\n",
       "      <td>0.119629</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660400</td>\n",
       "      <td>-0.031677</td>\n",
       "      <td>-0.004700</td>\n",
       "      <td>-0.018250</td>\n",
       "      <td>0.246826</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.763916</td>\n",
       "      <td>-0.044800</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>-0.038147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13496</td>\n",
       "      <td>-0.284180</td>\n",
       "      <td>-0.959473</td>\n",
       "      <td>0.120361</td>\n",
       "      <td>-0.028748</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.251709</td>\n",
       "      <td>0.928223</td>\n",
       "      <td>0.323975</td>\n",
       "      <td>-0.053406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837891</td>\n",
       "      <td>-0.010132</td>\n",
       "      <td>-0.004639</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>0.959961</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>-0.035706</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>-0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13497</td>\n",
       "      <td>-0.833252</td>\n",
       "      <td>-0.445068</td>\n",
       "      <td>0.361328</td>\n",
       "      <td>-0.026672</td>\n",
       "      <td>-0.064575</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.248047</td>\n",
       "      <td>-0.679443</td>\n",
       "      <td>0.637451</td>\n",
       "      <td>-0.083923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452393</td>\n",
       "      <td>-0.063171</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>0.926025</td>\n",
       "      <td>0.315430</td>\n",
       "      <td>-0.087769</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>-0.007996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13498</td>\n",
       "      <td>0.568848</td>\n",
       "      <td>-0.460693</td>\n",
       "      <td>0.820068</td>\n",
       "      <td>-0.038147</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.527832</td>\n",
       "      <td>-0.816162</td>\n",
       "      <td>0.114258</td>\n",
       "      <td>-0.039612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675293</td>\n",
       "      <td>-0.014038</td>\n",
       "      <td>-0.015808</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.478027</td>\n",
       "      <td>0.340576</td>\n",
       "      <td>0.801025</td>\n",
       "      <td>-0.026917</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>-0.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13499</td>\n",
       "      <td>-0.823242</td>\n",
       "      <td>-0.044678</td>\n",
       "      <td>0.621826</td>\n",
       "      <td>-0.069946</td>\n",
       "      <td>-0.005310</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>-0.278564</td>\n",
       "      <td>0.425537</td>\n",
       "      <td>0.859131</td>\n",
       "      <td>-0.066101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819092</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.004639</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.760986</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>-0.058105</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.001709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13500 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.363037  0.869141 -0.257080 -0.009460  0.007141 -0.000671  0.302734   \n",
       "1     -0.804688 -0.468018  0.391846 -0.038269 -0.018127 -0.017273 -0.129150   \n",
       "2     -0.276855 -0.964844 -0.111816 -0.013916  0.016663  0.019043  0.145264   \n",
       "3      0.508545  0.880615 -0.007080  0.005798  0.003845  0.043030  0.278076   \n",
       "4     -0.832275 -0.472412  0.453613 -0.071960  0.058533  0.080444 -0.318359   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13495  0.595947 -0.658203  0.599609 -0.046753  0.016663 -0.013184  0.308350   \n",
       "13496 -0.284180 -0.959473  0.120361 -0.028748  0.016296  0.000854  0.251709   \n",
       "13497 -0.833252 -0.445068  0.361328 -0.026672 -0.064575  0.001892 -0.248047   \n",
       "13498  0.568848 -0.460693  0.820068 -0.038147  0.018433  0.005310  0.527832   \n",
       "13499 -0.823242 -0.044678  0.621826 -0.069946 -0.005310  0.009094 -0.278564   \n",
       "\n",
       "              7         8         9  ...        20        21        22  \\\n",
       "0      0.884521 -0.383789 -0.036865  ... -0.995361 -0.014832 -0.014832   \n",
       "1     -0.731445  0.599854 -0.081482  ...  0.825928 -0.030823  0.007996   \n",
       "2      0.925293  0.383545 -0.032654  ...  0.791260  0.021362 -0.021851   \n",
       "3      0.948975 -0.346191  0.007935  ... -0.730469  0.022400 -0.034363   \n",
       "4     -0.689209  0.649414  0.041260  ...  0.463623  0.032898 -0.039612   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "13495 -0.904053  0.119629 -0.071411  ...  0.660400 -0.031677 -0.004700   \n",
       "13496  0.928223  0.323975 -0.053406  ...  0.837891 -0.010132 -0.004639   \n",
       "13497 -0.679443  0.637451 -0.083923  ...  0.452393 -0.063171  0.015198   \n",
       "13498 -0.816162  0.114258 -0.039612  ...  0.675293 -0.014038 -0.015808   \n",
       "13499  0.425537  0.859131 -0.066101  ...  0.819092 -0.035339 -0.004639   \n",
       "\n",
       "             23        24        25        26        27        28        29  \n",
       "0     -0.007263  0.042480  0.955322 -0.123047 -0.026733  0.028259 -0.006958  \n",
       "1      0.024414  0.135498  0.506104  0.824951 -0.055298  0.032654 -0.000732  \n",
       "2     -0.002197  0.204346  0.958496  0.127197 -0.014771  0.018860  0.002319  \n",
       "3      0.023804  0.336426 -0.758545 -0.686035  0.005493  0.004333  0.026245  \n",
       "4      0.055481  0.185791 -0.955811  0.229492 -0.011230  0.017639  0.055359  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "13495 -0.018250  0.246826  0.566895  0.763916 -0.044800  0.013428 -0.038147  \n",
       "13496  0.008118  0.157715  0.959961  0.232422 -0.035706  0.015320 -0.003540  \n",
       "13497  0.023315  0.172363  0.926025  0.315430 -0.087769  0.018799 -0.007996  \n",
       "13498  0.004272  0.478027  0.340576  0.801025 -0.026917  0.009033 -0.013611  \n",
       "13499  0.014465  0.048340  0.760986  0.609375 -0.058105  0.012085  0.001709  \n",
       "\n",
       "[13500 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.to_csv('dataset_train.csv')\n",
    "# X_val.to_csv('dataset_validation.csv')\n",
    "# X_test.to_csv('dataset_test.csv')\n",
    "\n",
    "# np.savetxt(\"labels_train.csv\", y_train, delimiter=\",\")\n",
    "# np.savetxt(\"labels_validation.csv\", y_val, delimiter=\",\")\n",
    "# np.savetxt(\"labels_test.csv\", y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"dataset_train.csv\")\n",
    "X_val = pd.read_csv('dataset_validation.csv')\n",
    "X_test = pd.read_csv('dataset_test.csv')\n",
    "\n",
    "X_train = X_train.iloc[:,1:31]\n",
    "X_val = X_val.iloc[:,1:31]\n",
    "X_test = X_test.iloc[:,1:31]\n",
    "\n",
    "y_train = np.loadtxt(\"labels_train.csv\", delimiter=\",\")\n",
    "y_val = np.loadtxt(\"labels_validation.csv\", delimiter=\",\")\n",
    "y_test = np.loadtxt(\"labels_test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = X_train.append(X_test, ignore_index=True).append(X_val, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>-0.807617</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.610352</td>\n",
       "      <td>-0.013184</td>\n",
       "      <td>0.046021</td>\n",
       "      <td>-0.034485</td>\n",
       "      <td>-0.175049</td>\n",
       "      <td>0.449463</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791504</td>\n",
       "      <td>0.013184</td>\n",
       "      <td>-0.021179</td>\n",
       "      <td>-0.044434</td>\n",
       "      <td>0.114990</td>\n",
       "      <td>0.813721</td>\n",
       "      <td>0.536865</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.046265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>-0.905273</td>\n",
       "      <td>-0.030518</td>\n",
       "      <td>0.358887</td>\n",
       "      <td>-0.070557</td>\n",
       "      <td>-0.004578</td>\n",
       "      <td>-0.003357</td>\n",
       "      <td>-0.222168</td>\n",
       "      <td>0.628174</td>\n",
       "      <td>0.705322</td>\n",
       "      <td>-0.063660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600830</td>\n",
       "      <td>-0.029419</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.917236</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>-0.048157</td>\n",
       "      <td>0.024170</td>\n",
       "      <td>-0.014221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.111572</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.017517</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>-0.279053</td>\n",
       "      <td>0.420654</td>\n",
       "      <td>0.789307</td>\n",
       "      <td>-0.028015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841797</td>\n",
       "      <td>0.020203</td>\n",
       "      <td>-0.014343</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.582275</td>\n",
       "      <td>0.691650</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.015930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>-0.818604</td>\n",
       "      <td>-0.031982</td>\n",
       "      <td>0.630615</td>\n",
       "      <td>-0.079712</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>-0.250488</td>\n",
       "      <td>0.384521</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>-0.041382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829834</td>\n",
       "      <td>-0.006714</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.751465</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>-0.026794</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>-0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>-0.812500</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.583496</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>-0.014282</td>\n",
       "      <td>-0.316650</td>\n",
       "      <td>0.471680</td>\n",
       "      <td>0.791992</td>\n",
       "      <td>-0.061340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918457</td>\n",
       "      <td>-0.010071</td>\n",
       "      <td>-0.007385</td>\n",
       "      <td>0.011047</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.676270</td>\n",
       "      <td>0.667480</td>\n",
       "      <td>-0.030273</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13399</td>\n",
       "      <td>-0.842773</td>\n",
       "      <td>-0.057129</td>\n",
       "      <td>0.549561</td>\n",
       "      <td>-0.024536</td>\n",
       "      <td>-0.005676</td>\n",
       "      <td>-0.009216</td>\n",
       "      <td>-0.288086</td>\n",
       "      <td>0.431641</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>-0.058777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809814</td>\n",
       "      <td>-0.024414</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>-0.001648</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.799316</td>\n",
       "      <td>0.537109</td>\n",
       "      <td>-0.038452</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>-0.030701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13423</td>\n",
       "      <td>-0.840332</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.574707</td>\n",
       "      <td>-0.037170</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>-0.006165</td>\n",
       "      <td>-0.290283</td>\n",
       "      <td>0.459717</td>\n",
       "      <td>0.821289</td>\n",
       "      <td>-0.060669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803467</td>\n",
       "      <td>-0.016357</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.007629</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.823975</td>\n",
       "      <td>0.537598</td>\n",
       "      <td>-0.039001</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>-0.008179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13463</td>\n",
       "      <td>-0.771484</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>-0.041260</td>\n",
       "      <td>-0.008423</td>\n",
       "      <td>-0.018311</td>\n",
       "      <td>-0.173096</td>\n",
       "      <td>0.401611</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>-0.050476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792236</td>\n",
       "      <td>-0.011902</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>-0.008240</td>\n",
       "      <td>0.108154</td>\n",
       "      <td>0.759277</td>\n",
       "      <td>0.555420</td>\n",
       "      <td>-0.028564</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>-0.025330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13476</td>\n",
       "      <td>-0.740967</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.769043</td>\n",
       "      <td>-0.062561</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>0.935547</td>\n",
       "      <td>-0.064758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846924</td>\n",
       "      <td>-0.026489</td>\n",
       "      <td>-0.007996</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>0.134033</td>\n",
       "      <td>0.719727</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>-0.053894</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>-0.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13499</td>\n",
       "      <td>-0.823242</td>\n",
       "      <td>-0.044678</td>\n",
       "      <td>0.621826</td>\n",
       "      <td>-0.069946</td>\n",
       "      <td>-0.005310</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>-0.278564</td>\n",
       "      <td>0.425537</td>\n",
       "      <td>0.859131</td>\n",
       "      <td>-0.066101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819092</td>\n",
       "      <td>-0.035339</td>\n",
       "      <td>-0.004639</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.048340</td>\n",
       "      <td>0.760986</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>-0.058105</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.001709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "100   -0.807617  0.044678  0.610352 -0.013184  0.046021 -0.034485 -0.175049   \n",
       "112   -0.905273 -0.030518  0.358887 -0.070557 -0.004578 -0.003357 -0.222168   \n",
       "115   -0.765625 -0.111572  0.573975  0.017517  0.002319 -0.029114 -0.279053   \n",
       "136   -0.818604 -0.031982  0.630615 -0.079712  0.011780  0.015991 -0.250488   \n",
       "146   -0.812500 -0.046875  0.583496 -0.000366 -0.003906 -0.014282 -0.316650   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13399 -0.842773 -0.057129  0.549561 -0.024536 -0.005676 -0.009216 -0.288086   \n",
       "13423 -0.840332  0.006592  0.574707 -0.037170  0.006042 -0.006165 -0.290283   \n",
       "13463 -0.771484  0.041016  0.591797 -0.041260 -0.008423 -0.018311 -0.173096   \n",
       "13476 -0.740967  0.009033  0.769043 -0.062561  0.004639  0.014709 -0.176758   \n",
       "13499 -0.823242 -0.044678  0.621826 -0.069946 -0.005310  0.009094 -0.278564   \n",
       "\n",
       "              7         8         9  ...        20        21        22  \\\n",
       "100    0.449463  0.843750  0.019470  ...  0.791504  0.013184 -0.021179   \n",
       "112    0.628174  0.705322 -0.063660  ...  0.600830 -0.029419  0.003723   \n",
       "115    0.420654  0.789307 -0.028015  ...  0.841797  0.020203 -0.014343   \n",
       "136    0.384521  0.856934 -0.041382  ...  0.829834 -0.006714 -0.002136   \n",
       "146    0.471680  0.791992 -0.061340  ...  0.918457 -0.010071 -0.007385   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "13399  0.431641  0.816406 -0.058777  ...  0.809814 -0.024414  0.019531   \n",
       "13423  0.459717  0.821289 -0.060669  ...  0.803467 -0.016357  0.002991   \n",
       "13463  0.401611  0.854004 -0.050476  ...  0.792236 -0.011902  0.005249   \n",
       "13476  0.255859  0.935547 -0.064758  ...  0.846924 -0.026489 -0.007996   \n",
       "13499  0.425537  0.859131 -0.066101  ...  0.819092 -0.035339 -0.004639   \n",
       "\n",
       "             23        24        25        26        27        28        29  \n",
       "100   -0.044434  0.114990  0.813721  0.536865  0.004944 -0.004456 -0.046265  \n",
       "112    0.005798  0.037842  0.917236  0.265869 -0.048157  0.024170 -0.014221  \n",
       "115    0.013916  0.043945  0.582275  0.691650  0.014465  0.012024  0.015930  \n",
       "136    0.015015  0.075195  0.751465  0.609375 -0.026794  0.017944 -0.005554  \n",
       "146    0.011047  0.009766  0.676270  0.667480 -0.030273  0.007568  0.000488  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "13399 -0.001648  0.025391  0.799316  0.537109 -0.038452  0.015747 -0.030701  \n",
       "13423  0.007629  0.030029  0.823975  0.537598 -0.039001  0.016602 -0.008179  \n",
       "13463 -0.008240  0.108154  0.759277  0.555420 -0.028564  0.017883 -0.025330  \n",
       "13476  0.015442  0.134033  0.719727  0.664062 -0.053894  0.006348 -0.011658  \n",
       "13499  0.014465  0.048340  0.760986  0.609375 -0.058105  0.012085  0.001709  \n",
       "\n",
       "[500 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[get_index_letra(4, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar K-Means de 1 a 270 com clusters aleatórios\n",
    "for i in range(1,271):\n",
    "    km = KMeans(n_clusters=i, verbose=0)\n",
    "    km.fit(X_train)\n",
    "    centroides = km.cluster_centers_\n",
    "    \n",
    "    if not os.path.exists('./k-means centroides/aleatorios'):\n",
    "        os.mkdir('./k-means centroides/aleatorios')\n",
    "    np.savetxt(\"./k-means centroides/aleatorios/\"+ str(i) + \"_clusters.csv\", centroides, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate(y, n):\n",
    "    y = np.expand_dims(y,axis=0)\n",
    "    y_ret = y\n",
    "    for i in range(n-1):\n",
    "        y_ret = np.concatenate((y_ret, y))\n",
    "    return y_ret\n",
    "\n",
    "for j in range(1,11):\n",
    "    centroides = []\n",
    "    y_train_total = []\n",
    "    for i in range(27):\n",
    "        km = KMeans(n_clusters=j, verbose=0)\n",
    "        X_train_letra = X_train.iloc[get_index_letra(i, y_train)]\n",
    "        km.fit(X_train_letra)\n",
    "        if len(centroides)==0:\n",
    "            centroides = km.cluster_centers_\n",
    "        else:\n",
    "            centroides = np.concatenate((centroides, km.cluster_centers_))\n",
    "        _y_train = np_utils.to_categorical(i, 27)\n",
    "        _y_train = duplicate(_y_train, j)\n",
    "        if len(y_train_total) == 0:\n",
    "            y_train_total = _y_train\n",
    "        else:\n",
    "            y_train_total = np.concatenate((y_train_total, _y_train))\n",
    "\n",
    "    if not os.path.exists('./k-means centroides/por_letra'):\n",
    "        os.mkdir('./k-means centroides/por_letra')\n",
    "    np.savetxt(\"./k-means centroides/por_letra/\"+ str((i+1)*j) + \"_clusters.csv\", centroides, delimiter=\",\")\n",
    "    \n",
    "    np.savetxt(\"./k-means centroides/por_letra/\"+ str((i+1)*j) +\"_labels_knn-kmeans.csv\", y_train_total, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
