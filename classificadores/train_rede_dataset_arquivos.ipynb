{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "# from tensorflow.contrib import lite\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, LabelBinarizer\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import random\n",
    "from random import randrange\n",
    "\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_one_hot(letra, nb_classes):\n",
    "    # Gera um dicionário de mapeamento de letra em valor inteiro (a->0, b->1, ..., w->20)\n",
    "    dic_conv = {}\n",
    "    for i,letra in enumerate(letras):\n",
    "        dic_conv[letra] = i\n",
    "    \n",
    "    num = dic_conv[letra]\n",
    "    return [[0 if i!=num else 1 for i in range(nb_classes)]]\n",
    "\n",
    "\n",
    "def get_incorrects(model, data, labels):\n",
    "    p = model.predict(data)\n",
    "    \n",
    "    errors = []\n",
    "    for i in range(len(data)):\n",
    "        equal = (np.where(labels[i] == np.amax(labels[i]))[0][0]) == (np.where(p[i] == np.amax(p[i])))[0][0]\n",
    "        if not equal:\n",
    "            print((np.where(labels[i] == np.amax(labels[i]))[0][0]), (np.where(p[i] == np.amax(p[i])))[0][0])\n",
    "            print()\n",
    "            errors.append(i)\n",
    "        \n",
    "    print(len(errors))\n",
    "    return errors\n",
    "\n",
    "\n",
    "def test_file(model, file_name):\n",
    "    letra = file_name[0].lower()\n",
    "    dataset_test = pd.DataFrame()\n",
    "\n",
    "    with open(file_name) as file:\n",
    "        lines_test = [l.strip() for l in file]\n",
    "        lines_test = ast.literal_eval(lines_test[0])\n",
    "        temp = pd.DataFrame(lines_test)\n",
    "        temp['label'] = 'c'\n",
    "        dataset_test = dataset_test.append(temp, ignore_index = True)\n",
    "\n",
    "    X_DT = dataset_test.iloc[:,0:30] # [all rows, col from index 2 to the last one excludind 'label']\n",
    "    X_DT = X_DT/32768\n",
    "\n",
    "    # Tranform training labels to one-hot encoding\n",
    "    y_DT = indices_to_one_hot(letra,20)\n",
    "\n",
    "    y_DT = y_DT*100\n",
    "    \n",
    "    errors = get_incorrects(model, X_DT, y_DT)\n",
    "    return errors\n",
    "\n",
    "\n",
    "def print_acc_results(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "#     plt.title('Resultados no treinamento')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(['Treinamento', 'Teste'], loc='best')\n",
    "    plt.grid()\n",
    "#     plt.ylim((0, 1)) \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_loss_results(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "#     plt.title('Resultados no teste')\n",
    "    plt.ylabel('Entropia Cruzada')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(['Treinamento', 'Teste'], loc='best')\n",
    "    plt.grid()\n",
    "#     plt.ylim((0, 10)) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"mini_dataset_train.csv\")\n",
    "X_val = pd.read_csv('mini_dataset_validation.csv')\n",
    "\n",
    "X_train = X_train.iloc[:,1:31]\n",
    "X_val = X_val.iloc[:,1:31]\n",
    "\n",
    "y_train = np.loadtxt(\"labels_train.csv\", delimiter=\",\")\n",
    "y_val = np.loadtxt(\"labels_validation.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "#         print(input_shape)\n",
    "#         print(self.units)\n",
    "        self.mu = self.add_weight(name='mu',\n",
    "                                  shape=(int(input_shape[1]), self.units),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.mu\n",
    "        l2 = K.sum(K.pow(diff, 2), axis=1)\n",
    "        res = K.exp(-1 * self.gamma * l2)\n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 216 samples, validate on 54 samples\n",
      "Epoch 1/10000\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 3.3383 - acc: 0.0231 - val_loss: 3.3256 - val_acc: 0.0185\n",
      "Epoch 2/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.3250 - acc: 0.0417 - val_loss: 3.3243 - val_acc: 0.0185\n",
      "Epoch 3/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.3167 - acc: 0.0417 - val_loss: 3.3231 - val_acc: 0.0185\n",
      "Epoch 4/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.3101 - acc: 0.0417 - val_loss: 3.3225 - val_acc: 0.0185\n",
      "Epoch 5/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.3041 - acc: 0.0417 - val_loss: 3.3219 - val_acc: 0.0185\n",
      "Epoch 6/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2991 - acc: 0.0417 - val_loss: 3.3212 - val_acc: 0.0185\n",
      "Epoch 7/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.2949 - acc: 0.0417 - val_loss: 3.3204 - val_acc: 0.0185\n",
      "Epoch 8/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.2902 - acc: 0.0556 - val_loss: 3.3205 - val_acc: 0.0185\n",
      "Epoch 9/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.2861 - acc: 0.0463 - val_loss: 3.3206 - val_acc: 0.0370\n",
      "Epoch 10/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.2823 - acc: 0.0741 - val_loss: 3.3209 - val_acc: 0.0370\n",
      "Epoch 11/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2787 - acc: 0.0694 - val_loss: 3.3206 - val_acc: 0.0370\n",
      "Epoch 12/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.2748 - acc: 0.0741 - val_loss: 3.3201 - val_acc: 0.0370\n",
      "Epoch 13/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.2719 - acc: 0.0787 - val_loss: 3.3192 - val_acc: 0.0556\n",
      "Epoch 14/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2679 - acc: 0.0880 - val_loss: 3.3188 - val_acc: 0.0556\n",
      "Epoch 15/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.2646 - acc: 0.1157 - val_loss: 3.3179 - val_acc: 0.0556\n",
      "Epoch 16/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.2612 - acc: 0.1204 - val_loss: 3.3170 - val_acc: 0.0556\n",
      "Epoch 17/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.2575 - acc: 0.1157 - val_loss: 3.3167 - val_acc: 0.0741\n",
      "Epoch 18/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.2545 - acc: 0.1389 - val_loss: 3.3158 - val_acc: 0.0741\n",
      "Epoch 19/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.2506 - acc: 0.1713 - val_loss: 3.3150 - val_acc: 0.0741\n",
      "Epoch 20/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2466 - acc: 0.1667 - val_loss: 3.3135 - val_acc: 0.0741\n",
      "Epoch 21/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.2431 - acc: 0.1620 - val_loss: 3.3121 - val_acc: 0.0741\n",
      "Epoch 22/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.2391 - acc: 0.1620 - val_loss: 3.3104 - val_acc: 0.0741\n",
      "Epoch 23/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2348 - acc: 0.1667 - val_loss: 3.3083 - val_acc: 0.0741\n",
      "Epoch 24/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.2314 - acc: 0.1759 - val_loss: 3.3064 - val_acc: 0.0741\n",
      "Epoch 25/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 3.2262 - acc: 0.1852 - val_loss: 3.3039 - val_acc: 0.0741\n",
      "Epoch 26/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.2222 - acc: 0.1806 - val_loss: 3.3013 - val_acc: 0.0741\n",
      "Epoch 27/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.2171 - acc: 0.1852 - val_loss: 3.2978 - val_acc: 0.0741\n",
      "Epoch 28/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.2122 - acc: 0.1852 - val_loss: 3.2951 - val_acc: 0.0741\n",
      "Epoch 29/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.2069 - acc: 0.1759 - val_loss: 3.2916 - val_acc: 0.0741\n",
      "Epoch 30/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2026 - acc: 0.1852 - val_loss: 3.2880 - val_acc: 0.0741\n",
      "Epoch 31/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1965 - acc: 0.1852 - val_loss: 3.2842 - val_acc: 0.0556\n",
      "Epoch 32/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1907 - acc: 0.1806 - val_loss: 3.2804 - val_acc: 0.0556\n",
      "Epoch 33/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1855 - acc: 0.1713 - val_loss: 3.2762 - val_acc: 0.0556\n",
      "Epoch 34/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.1792 - acc: 0.1667 - val_loss: 3.2712 - val_acc: 0.0556\n",
      "Epoch 35/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.1731 - acc: 0.1806 - val_loss: 3.2667 - val_acc: 0.0556\n",
      "Epoch 36/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1670 - acc: 0.1806 - val_loss: 3.2616 - val_acc: 0.0556\n",
      "Epoch 37/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.1600 - acc: 0.1574 - val_loss: 3.2564 - val_acc: 0.0556\n",
      "Epoch 38/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.1530 - acc: 0.1620 - val_loss: 3.2506 - val_acc: 0.0556\n",
      "Epoch 39/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.1463 - acc: 0.1620 - val_loss: 3.2448 - val_acc: 0.0741\n",
      "Epoch 40/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.1388 - acc: 0.1574 - val_loss: 3.2393 - val_acc: 0.0556\n",
      "Epoch 41/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.1305 - acc: 0.1528 - val_loss: 3.2325 - val_acc: 0.0741\n",
      "Epoch 42/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1232 - acc: 0.1667 - val_loss: 3.2255 - val_acc: 0.0741\n",
      "Epoch 43/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.1145 - acc: 0.1528 - val_loss: 3.2182 - val_acc: 0.0741\n",
      "Epoch 44/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.1068 - acc: 0.1620 - val_loss: 3.2106 - val_acc: 0.0741\n",
      "Epoch 45/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.0978 - acc: 0.1667 - val_loss: 3.2038 - val_acc: 0.0741\n",
      "Epoch 46/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.0889 - acc: 0.1759 - val_loss: 3.1955 - val_acc: 0.0741\n",
      "Epoch 47/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.0802 - acc: 0.1713 - val_loss: 3.1875 - val_acc: 0.0741\n",
      "Epoch 48/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.0712 - acc: 0.1620 - val_loss: 3.1793 - val_acc: 0.0741\n",
      "Epoch 49/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.0623 - acc: 0.1759 - val_loss: 3.1704 - val_acc: 0.0926\n",
      "Epoch 50/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.0527 - acc: 0.1759 - val_loss: 3.1621 - val_acc: 0.0926\n",
      "Epoch 51/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.0436 - acc: 0.1852 - val_loss: 3.1526 - val_acc: 0.0926\n",
      "Epoch 52/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.0335 - acc: 0.1759 - val_loss: 3.1437 - val_acc: 0.0926\n",
      "Epoch 53/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.0235 - acc: 0.1898 - val_loss: 3.1344 - val_acc: 0.1111\n",
      "Epoch 54/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.0145 - acc: 0.1898 - val_loss: 3.1258 - val_acc: 0.1111\n",
      "Epoch 55/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.0043 - acc: 0.1944 - val_loss: 3.1165 - val_acc: 0.1111\n",
      "Epoch 56/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.9943 - acc: 0.1944 - val_loss: 3.1081 - val_acc: 0.1111\n",
      "Epoch 57/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.9843 - acc: 0.1991 - val_loss: 3.0989 - val_acc: 0.1111\n",
      "Epoch 58/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.9738 - acc: 0.2083 - val_loss: 3.0895 - val_acc: 0.1296\n",
      "Epoch 59/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.9628 - acc: 0.2176 - val_loss: 3.0791 - val_acc: 0.1296\n",
      "Epoch 60/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 2.9524 - acc: 0.2176 - val_loss: 3.0682 - val_acc: 0.1296\n",
      "Epoch 61/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.9419 - acc: 0.2222 - val_loss: 3.0580 - val_acc: 0.1481\n",
      "Epoch 62/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.9311 - acc: 0.2130 - val_loss: 3.0480 - val_acc: 0.1667\n",
      "Epoch 63/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.9206 - acc: 0.2083 - val_loss: 3.0375 - val_acc: 0.1667\n",
      "Epoch 64/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 2.9100 - acc: 0.2130 - val_loss: 3.0275 - val_acc: 0.1667\n",
      "Epoch 65/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.8987 - acc: 0.2222 - val_loss: 3.0169 - val_acc: 0.1667\n",
      "Epoch 66/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.8884 - acc: 0.2176 - val_loss: 3.0059 - val_acc: 0.1852\n",
      "Epoch 67/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.8778 - acc: 0.2176 - val_loss: 2.9956 - val_acc: 0.1667\n",
      "Epoch 68/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.8665 - acc: 0.2269 - val_loss: 2.9845 - val_acc: 0.1852\n",
      "Epoch 69/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.8560 - acc: 0.2222 - val_loss: 2.9741 - val_acc: 0.1852\n",
      "Epoch 70/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.8448 - acc: 0.2500 - val_loss: 2.9630 - val_acc: 0.1852\n",
      "Epoch 71/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.8339 - acc: 0.2454 - val_loss: 2.9519 - val_acc: 0.1852\n",
      "Epoch 72/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.8225 - acc: 0.2593 - val_loss: 2.9403 - val_acc: 0.1852\n",
      "Epoch 73/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.8118 - acc: 0.2593 - val_loss: 2.9299 - val_acc: 0.1852\n",
      "Epoch 74/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.8002 - acc: 0.2546 - val_loss: 2.9186 - val_acc: 0.1852\n",
      "Epoch 75/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.7900 - acc: 0.2685 - val_loss: 2.9084 - val_acc: 0.1852\n",
      "Epoch 76/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.7786 - acc: 0.2778 - val_loss: 2.8972 - val_acc: 0.1852\n",
      "Epoch 77/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.7682 - acc: 0.2685 - val_loss: 2.8859 - val_acc: 0.1852\n",
      "Epoch 78/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.7569 - acc: 0.2731 - val_loss: 2.8747 - val_acc: 0.2222\n",
      "Epoch 79/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.7459 - acc: 0.2778 - val_loss: 2.8633 - val_acc: 0.2222\n",
      "Epoch 80/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.7352 - acc: 0.2778 - val_loss: 2.8521 - val_acc: 0.2407\n",
      "Epoch 81/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.7243 - acc: 0.2824 - val_loss: 2.8409 - val_acc: 0.2407\n",
      "Epoch 82/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.7127 - acc: 0.2824 - val_loss: 2.8302 - val_acc: 0.2407\n",
      "Epoch 83/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.7025 - acc: 0.2917 - val_loss: 2.8194 - val_acc: 0.2407\n",
      "Epoch 84/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.6914 - acc: 0.3009 - val_loss: 2.8078 - val_acc: 0.2222\n",
      "Epoch 85/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.6812 - acc: 0.3102 - val_loss: 2.7966 - val_acc: 0.2407\n",
      "Epoch 86/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.6698 - acc: 0.3056 - val_loss: 2.7852 - val_acc: 0.2593\n",
      "Epoch 87/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.6593 - acc: 0.3241 - val_loss: 2.7742 - val_acc: 0.2593\n",
      "Epoch 88/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.6490 - acc: 0.3102 - val_loss: 2.7626 - val_acc: 0.2593\n",
      "Epoch 89/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.6381 - acc: 0.3333 - val_loss: 2.7517 - val_acc: 0.3148\n",
      "Epoch 90/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.6282 - acc: 0.3519 - val_loss: 2.7414 - val_acc: 0.3519\n",
      "Epoch 91/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.6172 - acc: 0.3426 - val_loss: 2.7307 - val_acc: 0.3519\n",
      "Epoch 92/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 2.6063 - acc: 0.3565 - val_loss: 2.7200 - val_acc: 0.3704\n",
      "Epoch 93/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5965 - acc: 0.3704 - val_loss: 2.7092 - val_acc: 0.3889\n",
      "Epoch 94/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5862 - acc: 0.3611 - val_loss: 2.6985 - val_acc: 0.4074\n",
      "Epoch 95/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.5758 - acc: 0.3472 - val_loss: 2.6882 - val_acc: 0.4074\n",
      "Epoch 96/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 2.5654 - acc: 0.3843 - val_loss: 2.6776 - val_acc: 0.4074\n",
      "Epoch 97/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 2.5554 - acc: 0.3843 - val_loss: 2.6677 - val_acc: 0.4074\n",
      "Epoch 98/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5454 - acc: 0.3796 - val_loss: 2.6575 - val_acc: 0.4074\n",
      "Epoch 99/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.5349 - acc: 0.3704 - val_loss: 2.6467 - val_acc: 0.4074\n",
      "Epoch 100/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.5248 - acc: 0.3843 - val_loss: 2.6364 - val_acc: 0.4074\n",
      "Epoch 101/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 2.5148 - acc: 0.3935 - val_loss: 2.6254 - val_acc: 0.4074\n",
      "Epoch 102/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.5052 - acc: 0.3889 - val_loss: 2.6153 - val_acc: 0.4074\n",
      "Epoch 103/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4947 - acc: 0.3981 - val_loss: 2.6048 - val_acc: 0.3704\n",
      "Epoch 104/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.4852 - acc: 0.3981 - val_loss: 2.5946 - val_acc: 0.3704\n",
      "Epoch 105/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.4755 - acc: 0.3843 - val_loss: 2.5850 - val_acc: 0.3704\n",
      "Epoch 106/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.4654 - acc: 0.3889 - val_loss: 2.5747 - val_acc: 0.3704\n",
      "Epoch 107/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.4557 - acc: 0.3981 - val_loss: 2.5637 - val_acc: 0.3704\n",
      "Epoch 108/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4461 - acc: 0.4028 - val_loss: 2.5538 - val_acc: 0.3704\n",
      "Epoch 109/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.4361 - acc: 0.4213 - val_loss: 2.5438 - val_acc: 0.3704\n",
      "Epoch 110/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4272 - acc: 0.4120 - val_loss: 2.5337 - val_acc: 0.3704\n",
      "Epoch 111/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 2.4168 - acc: 0.4120 - val_loss: 2.5235 - val_acc: 0.3704\n",
      "Epoch 112/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4074 - acc: 0.4028 - val_loss: 2.5136 - val_acc: 0.3704\n",
      "Epoch 113/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.3981 - acc: 0.4259 - val_loss: 2.5033 - val_acc: 0.3704\n",
      "Epoch 114/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3882 - acc: 0.4213 - val_loss: 2.4929 - val_acc: 0.3704\n",
      "Epoch 115/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3795 - acc: 0.4213 - val_loss: 2.4834 - val_acc: 0.3704\n",
      "Epoch 116/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3692 - acc: 0.4306 - val_loss: 2.4736 - val_acc: 0.3889\n",
      "Epoch 117/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.3603 - acc: 0.4120 - val_loss: 2.4639 - val_acc: 0.3889\n",
      "Epoch 118/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3506 - acc: 0.4398 - val_loss: 2.4543 - val_acc: 0.4074\n",
      "Epoch 119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 93us/step - loss: 2.3411 - acc: 0.4352 - val_loss: 2.4443 - val_acc: 0.4074\n",
      "Epoch 120/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3317 - acc: 0.4583 - val_loss: 2.4345 - val_acc: 0.4074\n",
      "Epoch 121/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.3228 - acc: 0.4491 - val_loss: 2.4241 - val_acc: 0.4074\n",
      "Epoch 122/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3133 - acc: 0.4583 - val_loss: 2.4143 - val_acc: 0.4074\n",
      "Epoch 123/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3043 - acc: 0.4583 - val_loss: 2.4045 - val_acc: 0.4074\n",
      "Epoch 124/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.2947 - acc: 0.4676 - val_loss: 2.3951 - val_acc: 0.4259\n",
      "Epoch 125/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.2856 - acc: 0.4861 - val_loss: 2.3857 - val_acc: 0.4259\n",
      "Epoch 126/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.2763 - acc: 0.4769 - val_loss: 2.3756 - val_acc: 0.4444\n",
      "Epoch 127/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.2672 - acc: 0.4815 - val_loss: 2.3661 - val_acc: 0.4444\n",
      "Epoch 128/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2576 - acc: 0.4815 - val_loss: 2.3561 - val_acc: 0.4444\n",
      "Epoch 129/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2488 - acc: 0.4861 - val_loss: 2.3468 - val_acc: 0.4444\n",
      "Epoch 130/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2392 - acc: 0.4907 - val_loss: 2.3369 - val_acc: 0.4444\n",
      "Epoch 131/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.2304 - acc: 0.4954 - val_loss: 2.3271 - val_acc: 0.4444\n",
      "Epoch 132/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.2215 - acc: 0.4954 - val_loss: 2.3179 - val_acc: 0.4444\n",
      "Epoch 133/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.2116 - acc: 0.5000 - val_loss: 2.3080 - val_acc: 0.4630\n",
      "Epoch 134/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.2033 - acc: 0.5046 - val_loss: 2.2982 - val_acc: 0.4630\n",
      "Epoch 135/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.1940 - acc: 0.4907 - val_loss: 2.2881 - val_acc: 0.4630\n",
      "Epoch 136/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.1849 - acc: 0.5231 - val_loss: 2.2789 - val_acc: 0.4630\n",
      "Epoch 137/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.1757 - acc: 0.5278 - val_loss: 2.2697 - val_acc: 0.4630\n",
      "Epoch 138/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 2.1675 - acc: 0.5231 - val_loss: 2.2602 - val_acc: 0.4815\n",
      "Epoch 139/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 2.1580 - acc: 0.5139 - val_loss: 2.2509 - val_acc: 0.4815\n",
      "Epoch 140/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.1493 - acc: 0.5324 - val_loss: 2.2419 - val_acc: 0.4815\n",
      "Epoch 141/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.1406 - acc: 0.5231 - val_loss: 2.2337 - val_acc: 0.4815\n",
      "Epoch 142/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 2.1319 - acc: 0.5370 - val_loss: 2.2243 - val_acc: 0.4815\n",
      "Epoch 143/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.1230 - acc: 0.5509 - val_loss: 2.2157 - val_acc: 0.4815\n",
      "Epoch 144/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.1142 - acc: 0.5370 - val_loss: 2.2069 - val_acc: 0.4815\n",
      "Epoch 145/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.1056 - acc: 0.5602 - val_loss: 2.1972 - val_acc: 0.4815\n",
      "Epoch 146/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.0970 - acc: 0.5694 - val_loss: 2.1886 - val_acc: 0.4815\n",
      "Epoch 147/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0880 - acc: 0.5833 - val_loss: 2.1795 - val_acc: 0.4815\n",
      "Epoch 148/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.0796 - acc: 0.5694 - val_loss: 2.1707 - val_acc: 0.4815\n",
      "Epoch 149/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.0707 - acc: 0.5648 - val_loss: 2.1620 - val_acc: 0.4815\n",
      "Epoch 150/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.0625 - acc: 0.5741 - val_loss: 2.1538 - val_acc: 0.4815\n",
      "Epoch 151/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.0535 - acc: 0.5833 - val_loss: 2.1455 - val_acc: 0.4815\n",
      "Epoch 152/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.0455 - acc: 0.5926 - val_loss: 2.1370 - val_acc: 0.4815\n",
      "Epoch 153/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 2.0365 - acc: 0.5833 - val_loss: 2.1281 - val_acc: 0.4815\n",
      "Epoch 154/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 2.0280 - acc: 0.5787 - val_loss: 2.1194 - val_acc: 0.4815\n",
      "Epoch 155/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.0196 - acc: 0.5880 - val_loss: 2.1110 - val_acc: 0.4815\n",
      "Epoch 156/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.0111 - acc: 0.5880 - val_loss: 2.1034 - val_acc: 0.4815\n",
      "Epoch 157/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 2.0028 - acc: 0.5880 - val_loss: 2.0946 - val_acc: 0.4815\n",
      "Epoch 158/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.9942 - acc: 0.6019 - val_loss: 2.0851 - val_acc: 0.4815\n",
      "Epoch 159/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 1.9861 - acc: 0.6065 - val_loss: 2.0764 - val_acc: 0.4815\n",
      "Epoch 160/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9777 - acc: 0.6157 - val_loss: 2.0684 - val_acc: 0.5000\n",
      "Epoch 161/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.9689 - acc: 0.5972 - val_loss: 2.0603 - val_acc: 0.5000\n",
      "Epoch 162/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.9612 - acc: 0.5833 - val_loss: 2.0519 - val_acc: 0.5000\n",
      "Epoch 163/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.9529 - acc: 0.6111 - val_loss: 2.0441 - val_acc: 0.5000\n",
      "Epoch 164/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9451 - acc: 0.6111 - val_loss: 2.0358 - val_acc: 0.5000\n",
      "Epoch 165/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.9365 - acc: 0.6111 - val_loss: 2.0274 - val_acc: 0.5000\n",
      "Epoch 166/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9285 - acc: 0.6019 - val_loss: 2.0193 - val_acc: 0.5000\n",
      "Epoch 167/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.9203 - acc: 0.6111 - val_loss: 2.0113 - val_acc: 0.5000\n",
      "Epoch 168/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9127 - acc: 0.6019 - val_loss: 2.0033 - val_acc: 0.5000\n",
      "Epoch 169/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.9043 - acc: 0.5972 - val_loss: 1.9958 - val_acc: 0.5000\n",
      "Epoch 170/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.8967 - acc: 0.6111 - val_loss: 1.9878 - val_acc: 0.5000\n",
      "Epoch 171/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.8881 - acc: 0.6157 - val_loss: 1.9805 - val_acc: 0.5000\n",
      "Epoch 172/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.8813 - acc: 0.5972 - val_loss: 1.9728 - val_acc: 0.5000\n",
      "Epoch 173/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.8728 - acc: 0.6111 - val_loss: 1.9650 - val_acc: 0.5000\n",
      "Epoch 174/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.8651 - acc: 0.6019 - val_loss: 1.9564 - val_acc: 0.5000\n",
      "Epoch 175/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.8573 - acc: 0.6019 - val_loss: 1.9485 - val_acc: 0.5000\n",
      "Epoch 176/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.8494 - acc: 0.6019 - val_loss: 1.9410 - val_acc: 0.5000\n",
      "Epoch 177/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.8415 - acc: 0.6019 - val_loss: 1.9341 - val_acc: 0.5000\n",
      "Epoch 178/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.8338 - acc: 0.5926 - val_loss: 1.9270 - val_acc: 0.5000\n",
      "Epoch 179/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 1.8264 - acc: 0.6019 - val_loss: 1.9195 - val_acc: 0.5185\n",
      "Epoch 180/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 1.8185 - acc: 0.6019 - val_loss: 1.9116 - val_acc: 0.5000\n",
      "Epoch 181/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.8103 - acc: 0.6157 - val_loss: 1.9039 - val_acc: 0.5000\n",
      "Epoch 182/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 1.8035 - acc: 0.6157 - val_loss: 1.8972 - val_acc: 0.5000\n",
      "Epoch 183/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 1.7955 - acc: 0.6065 - val_loss: 1.8896 - val_acc: 0.5185\n",
      "Epoch 184/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 1.7881 - acc: 0.5972 - val_loss: 1.8824 - val_acc: 0.5185\n",
      "Epoch 185/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7807 - acc: 0.6157 - val_loss: 1.8751 - val_acc: 0.5185\n",
      "Epoch 186/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.7732 - acc: 0.5926 - val_loss: 1.8679 - val_acc: 0.5000\n",
      "Epoch 187/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.7657 - acc: 0.6065 - val_loss: 1.8606 - val_acc: 0.5185\n",
      "Epoch 188/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.7584 - acc: 0.6019 - val_loss: 1.8529 - val_acc: 0.5185\n",
      "Epoch 189/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7510 - acc: 0.6065 - val_loss: 1.8461 - val_acc: 0.5185\n",
      "Epoch 190/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.7432 - acc: 0.6019 - val_loss: 1.8383 - val_acc: 0.5000\n",
      "Epoch 191/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.7360 - acc: 0.6157 - val_loss: 1.8299 - val_acc: 0.5000\n",
      "Epoch 192/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.7292 - acc: 0.6111 - val_loss: 1.8224 - val_acc: 0.5000\n",
      "Epoch 193/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7213 - acc: 0.6157 - val_loss: 1.8152 - val_acc: 0.5185\n",
      "Epoch 194/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7142 - acc: 0.6111 - val_loss: 1.8081 - val_acc: 0.5185\n",
      "Epoch 195/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.7072 - acc: 0.6204 - val_loss: 1.8016 - val_acc: 0.5185\n",
      "Epoch 196/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7001 - acc: 0.6157 - val_loss: 1.7948 - val_acc: 0.5556\n",
      "Epoch 197/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.6932 - acc: 0.6204 - val_loss: 1.7876 - val_acc: 0.5556\n",
      "Epoch 198/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.6861 - acc: 0.6157 - val_loss: 1.7812 - val_acc: 0.5556\n",
      "Epoch 199/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.6789 - acc: 0.6204 - val_loss: 1.7752 - val_acc: 0.5556\n",
      "Epoch 200/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6723 - acc: 0.6204 - val_loss: 1.7686 - val_acc: 0.5741\n",
      "Epoch 201/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6650 - acc: 0.6296 - val_loss: 1.7618 - val_acc: 0.5741\n",
      "Epoch 202/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.6579 - acc: 0.6204 - val_loss: 1.7546 - val_acc: 0.5741\n",
      "Epoch 203/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.6513 - acc: 0.6204 - val_loss: 1.7478 - val_acc: 0.5741\n",
      "Epoch 204/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6448 - acc: 0.6204 - val_loss: 1.7403 - val_acc: 0.5741\n",
      "Epoch 205/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6379 - acc: 0.6296 - val_loss: 1.7342 - val_acc: 0.5741\n",
      "Epoch 206/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.6313 - acc: 0.6250 - val_loss: 1.7273 - val_acc: 0.5741\n",
      "Epoch 207/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6250 - acc: 0.6250 - val_loss: 1.7212 - val_acc: 0.5741\n",
      "Epoch 208/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6180 - acc: 0.6343 - val_loss: 1.7143 - val_acc: 0.5741\n",
      "Epoch 209/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6115 - acc: 0.6343 - val_loss: 1.7082 - val_acc: 0.5741\n",
      "Epoch 210/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.6057 - acc: 0.6389 - val_loss: 1.7018 - val_acc: 0.5741\n",
      "Epoch 211/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.5983 - acc: 0.6389 - val_loss: 1.6960 - val_acc: 0.5741\n",
      "Epoch 212/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5919 - acc: 0.6481 - val_loss: 1.6899 - val_acc: 0.5926\n",
      "Epoch 213/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5855 - acc: 0.6528 - val_loss: 1.6833 - val_acc: 0.5926\n",
      "Epoch 214/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.5794 - acc: 0.6435 - val_loss: 1.6782 - val_acc: 0.5926\n",
      "Epoch 215/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5726 - acc: 0.6528 - val_loss: 1.6721 - val_acc: 0.5926\n",
      "Epoch 216/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.5663 - acc: 0.6528 - val_loss: 1.6657 - val_acc: 0.5926\n",
      "Epoch 217/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5609 - acc: 0.6481 - val_loss: 1.6591 - val_acc: 0.5926\n",
      "Epoch 218/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.5532 - acc: 0.6574 - val_loss: 1.6536 - val_acc: 0.5926\n",
      "Epoch 219/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.5480 - acc: 0.6620 - val_loss: 1.6474 - val_acc: 0.5926\n",
      "Epoch 220/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5413 - acc: 0.6667 - val_loss: 1.6412 - val_acc: 0.5926\n",
      "Epoch 221/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5354 - acc: 0.6667 - val_loss: 1.6350 - val_acc: 0.5926\n",
      "Epoch 222/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.5293 - acc: 0.6574 - val_loss: 1.6292 - val_acc: 0.5926\n",
      "Epoch 223/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5230 - acc: 0.6667 - val_loss: 1.6237 - val_acc: 0.5926\n",
      "Epoch 224/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5175 - acc: 0.6620 - val_loss: 1.6178 - val_acc: 0.5926\n",
      "Epoch 225/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5109 - acc: 0.6620 - val_loss: 1.6125 - val_acc: 0.5926\n",
      "Epoch 226/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5054 - acc: 0.6713 - val_loss: 1.6063 - val_acc: 0.5926\n",
      "Epoch 227/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.4994 - acc: 0.6759 - val_loss: 1.6001 - val_acc: 0.5926\n",
      "Epoch 228/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4934 - acc: 0.6667 - val_loss: 1.5950 - val_acc: 0.5926\n",
      "Epoch 229/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.4880 - acc: 0.6806 - val_loss: 1.5893 - val_acc: 0.5926\n",
      "Epoch 230/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.4816 - acc: 0.6806 - val_loss: 1.5836 - val_acc: 0.5926\n",
      "Epoch 231/10000\n",
      "216/216 [==============================] - 0s 199us/step - loss: 1.4761 - acc: 0.6806 - val_loss: 1.5781 - val_acc: 0.5926\n",
      "Epoch 232/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 1.4706 - acc: 0.6713 - val_loss: 1.5728 - val_acc: 0.5926\n",
      "Epoch 233/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.4645 - acc: 0.6806 - val_loss: 1.5669 - val_acc: 0.5926\n",
      "Epoch 234/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.4586 - acc: 0.6944 - val_loss: 1.5614 - val_acc: 0.5926\n",
      "Epoch 235/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.4536 - acc: 0.6806 - val_loss: 1.5566 - val_acc: 0.5926\n",
      "Epoch 236/10000\n",
      "216/216 [==============================] - 0s 190us/step - loss: 1.4478 - acc: 0.6898 - val_loss: 1.5514 - val_acc: 0.5926\n",
      "Epoch 237/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 148us/step - loss: 1.4418 - acc: 0.6852 - val_loss: 1.5458 - val_acc: 0.5926\n",
      "Epoch 238/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.4369 - acc: 0.6852 - val_loss: 1.5405 - val_acc: 0.5926\n",
      "Epoch 239/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 1.4314 - acc: 0.6944 - val_loss: 1.5356 - val_acc: 0.5926\n",
      "Epoch 240/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 1.4260 - acc: 0.6898 - val_loss: 1.5303 - val_acc: 0.5926\n",
      "Epoch 241/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 1.4202 - acc: 0.6944 - val_loss: 1.5254 - val_acc: 0.5926\n",
      "Epoch 242/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.4150 - acc: 0.6991 - val_loss: 1.5200 - val_acc: 0.5926\n",
      "Epoch 243/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.4094 - acc: 0.6991 - val_loss: 1.5144 - val_acc: 0.5926\n",
      "Epoch 244/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.4038 - acc: 0.6991 - val_loss: 1.5095 - val_acc: 0.5926\n",
      "Epoch 245/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 1.3985 - acc: 0.7037 - val_loss: 1.5053 - val_acc: 0.5926\n",
      "Epoch 246/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 1.3934 - acc: 0.6944 - val_loss: 1.5000 - val_acc: 0.5926\n",
      "Epoch 247/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 1.3879 - acc: 0.6991 - val_loss: 1.4951 - val_acc: 0.5926\n",
      "Epoch 248/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 1.3825 - acc: 0.6991 - val_loss: 1.4892 - val_acc: 0.5926\n",
      "Epoch 249/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.3777 - acc: 0.6991 - val_loss: 1.4839 - val_acc: 0.5926\n",
      "Epoch 250/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.3724 - acc: 0.7037 - val_loss: 1.4798 - val_acc: 0.5926\n",
      "Epoch 251/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.3669 - acc: 0.7037 - val_loss: 1.4741 - val_acc: 0.5926\n",
      "Epoch 252/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.3623 - acc: 0.6991 - val_loss: 1.4699 - val_acc: 0.5926\n",
      "Epoch 253/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.3573 - acc: 0.7037 - val_loss: 1.4655 - val_acc: 0.5926\n",
      "Epoch 254/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3520 - acc: 0.7037 - val_loss: 1.4609 - val_acc: 0.5926\n",
      "Epoch 255/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 1.3468 - acc: 0.6944 - val_loss: 1.4553 - val_acc: 0.5926\n",
      "Epoch 256/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 1.3423 - acc: 0.7130 - val_loss: 1.4507 - val_acc: 0.5926\n",
      "Epoch 257/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 1.3379 - acc: 0.6898 - val_loss: 1.4459 - val_acc: 0.5926\n",
      "Epoch 258/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.3325 - acc: 0.7130 - val_loss: 1.4412 - val_acc: 0.5926\n",
      "Epoch 259/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3275 - acc: 0.7083 - val_loss: 1.4360 - val_acc: 0.5926\n",
      "Epoch 260/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.3233 - acc: 0.6991 - val_loss: 1.4306 - val_acc: 0.6111\n",
      "Epoch 261/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3184 - acc: 0.7083 - val_loss: 1.4262 - val_acc: 0.6111\n",
      "Epoch 262/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.3133 - acc: 0.7130 - val_loss: 1.4222 - val_acc: 0.6111\n",
      "Epoch 263/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3091 - acc: 0.7176 - val_loss: 1.4171 - val_acc: 0.6111\n",
      "Epoch 264/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3042 - acc: 0.7037 - val_loss: 1.4125 - val_acc: 0.6111\n",
      "Epoch 265/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3000 - acc: 0.7130 - val_loss: 1.4086 - val_acc: 0.6111\n",
      "Epoch 266/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2951 - acc: 0.7130 - val_loss: 1.4043 - val_acc: 0.6111\n",
      "Epoch 267/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2906 - acc: 0.7037 - val_loss: 1.3997 - val_acc: 0.6111\n",
      "Epoch 268/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.2863 - acc: 0.7176 - val_loss: 1.3952 - val_acc: 0.6111\n",
      "Epoch 269/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 1.2816 - acc: 0.7176 - val_loss: 1.3913 - val_acc: 0.6111\n",
      "Epoch 270/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.2773 - acc: 0.7083 - val_loss: 1.3876 - val_acc: 0.6111\n",
      "Epoch 271/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.2727 - acc: 0.7130 - val_loss: 1.3835 - val_acc: 0.6111\n",
      "Epoch 272/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.2677 - acc: 0.7176 - val_loss: 1.3797 - val_acc: 0.6111\n",
      "Epoch 273/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.2637 - acc: 0.7176 - val_loss: 1.3751 - val_acc: 0.6111\n",
      "Epoch 274/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 1.2599 - acc: 0.7222 - val_loss: 1.3715 - val_acc: 0.6111\n",
      "Epoch 275/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 1.2551 - acc: 0.7130 - val_loss: 1.3680 - val_acc: 0.6296\n",
      "Epoch 276/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 1.2511 - acc: 0.7176 - val_loss: 1.3636 - val_acc: 0.6296\n",
      "Epoch 277/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2467 - acc: 0.7176 - val_loss: 1.3591 - val_acc: 0.6296\n",
      "Epoch 278/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.2425 - acc: 0.7176 - val_loss: 1.3546 - val_acc: 0.6296\n",
      "Epoch 279/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2382 - acc: 0.7176 - val_loss: 1.3504 - val_acc: 0.6481\n",
      "Epoch 280/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2338 - acc: 0.7130 - val_loss: 1.3457 - val_acc: 0.6481\n",
      "Epoch 281/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2301 - acc: 0.7176 - val_loss: 1.3421 - val_acc: 0.6296\n",
      "Epoch 282/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2255 - acc: 0.7130 - val_loss: 1.3381 - val_acc: 0.6296\n",
      "Epoch 283/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.2213 - acc: 0.7269 - val_loss: 1.3347 - val_acc: 0.6296\n",
      "Epoch 284/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2173 - acc: 0.7176 - val_loss: 1.3312 - val_acc: 0.6296\n",
      "Epoch 285/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2134 - acc: 0.7222 - val_loss: 1.3265 - val_acc: 0.6481\n",
      "Epoch 286/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2086 - acc: 0.7315 - val_loss: 1.3226 - val_acc: 0.6481\n",
      "Epoch 287/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2049 - acc: 0.7176 - val_loss: 1.3184 - val_acc: 0.6481\n",
      "Epoch 288/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.2008 - acc: 0.7269 - val_loss: 1.3149 - val_acc: 0.6481\n",
      "Epoch 289/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1973 - acc: 0.7222 - val_loss: 1.3109 - val_acc: 0.6481\n",
      "Epoch 290/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1931 - acc: 0.7269 - val_loss: 1.3074 - val_acc: 0.6481\n",
      "Epoch 291/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1891 - acc: 0.7315 - val_loss: 1.3038 - val_acc: 0.6481\n",
      "Epoch 292/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1855 - acc: 0.7269 - val_loss: 1.3004 - val_acc: 0.6481\n",
      "Epoch 293/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1812 - acc: 0.7176 - val_loss: 1.2967 - val_acc: 0.6481\n",
      "Epoch 294/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1775 - acc: 0.7269 - val_loss: 1.2932 - val_acc: 0.6481\n",
      "Epoch 295/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1745 - acc: 0.7315 - val_loss: 1.2901 - val_acc: 0.6481\n",
      "Epoch 296/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1702 - acc: 0.7315 - val_loss: 1.2860 - val_acc: 0.6481\n",
      "Epoch 297/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1662 - acc: 0.7222 - val_loss: 1.2820 - val_acc: 0.6481\n",
      "Epoch 298/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1628 - acc: 0.7269 - val_loss: 1.2788 - val_acc: 0.6481\n",
      "Epoch 299/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.1591 - acc: 0.7222 - val_loss: 1.2757 - val_acc: 0.6481\n",
      "Epoch 300/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1557 - acc: 0.7315 - val_loss: 1.2719 - val_acc: 0.6481\n",
      "Epoch 301/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1516 - acc: 0.7407 - val_loss: 1.2687 - val_acc: 0.6481\n",
      "Epoch 302/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1475 - acc: 0.7222 - val_loss: 1.2655 - val_acc: 0.6481\n",
      "Epoch 303/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.1443 - acc: 0.7315 - val_loss: 1.2619 - val_acc: 0.6481\n",
      "Epoch 304/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1406 - acc: 0.7315 - val_loss: 1.2586 - val_acc: 0.6481\n",
      "Epoch 305/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1371 - acc: 0.7315 - val_loss: 1.2548 - val_acc: 0.6481\n",
      "Epoch 306/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1330 - acc: 0.7361 - val_loss: 1.2513 - val_acc: 0.6481\n",
      "Epoch 307/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.1298 - acc: 0.7361 - val_loss: 1.2479 - val_acc: 0.6481\n",
      "Epoch 308/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1260 - acc: 0.7269 - val_loss: 1.2446 - val_acc: 0.6481\n",
      "Epoch 309/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1228 - acc: 0.7361 - val_loss: 1.2409 - val_acc: 0.6481\n",
      "Epoch 310/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1191 - acc: 0.7407 - val_loss: 1.2380 - val_acc: 0.6481\n",
      "Epoch 311/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1161 - acc: 0.7361 - val_loss: 1.2347 - val_acc: 0.6481\n",
      "Epoch 312/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1121 - acc: 0.7361 - val_loss: 1.2318 - val_acc: 0.6481\n",
      "Epoch 313/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1085 - acc: 0.7407 - val_loss: 1.2285 - val_acc: 0.6481\n",
      "Epoch 314/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1049 - acc: 0.7361 - val_loss: 1.2252 - val_acc: 0.6481\n",
      "Epoch 315/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1017 - acc: 0.7361 - val_loss: 1.2220 - val_acc: 0.6481\n",
      "Epoch 316/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.0983 - acc: 0.7361 - val_loss: 1.2186 - val_acc: 0.6481\n",
      "Epoch 317/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0950 - acc: 0.7407 - val_loss: 1.2154 - val_acc: 0.6481\n",
      "Epoch 318/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0911 - acc: 0.7361 - val_loss: 1.2119 - val_acc: 0.6481\n",
      "Epoch 319/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.0877 - acc: 0.7407 - val_loss: 1.2091 - val_acc: 0.6481\n",
      "Epoch 320/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.0846 - acc: 0.7407 - val_loss: 1.2056 - val_acc: 0.6481\n",
      "Epoch 321/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0812 - acc: 0.7454 - val_loss: 1.2028 - val_acc: 0.6481\n",
      "Epoch 322/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.0779 - acc: 0.7407 - val_loss: 1.1989 - val_acc: 0.6481\n",
      "Epoch 323/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.0744 - acc: 0.7407 - val_loss: 1.1957 - val_acc: 0.6481\n",
      "Epoch 324/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0713 - acc: 0.7407 - val_loss: 1.1923 - val_acc: 0.6481\n",
      "Epoch 325/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.0681 - acc: 0.7407 - val_loss: 1.1890 - val_acc: 0.6481\n",
      "Epoch 326/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.0651 - acc: 0.7407 - val_loss: 1.1853 - val_acc: 0.6481\n",
      "Epoch 327/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0619 - acc: 0.7454 - val_loss: 1.1830 - val_acc: 0.6481\n",
      "Epoch 328/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0586 - acc: 0.7546 - val_loss: 1.1793 - val_acc: 0.6481\n",
      "Epoch 329/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.0550 - acc: 0.7454 - val_loss: 1.1764 - val_acc: 0.6481\n",
      "Epoch 330/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0527 - acc: 0.7500 - val_loss: 1.1732 - val_acc: 0.6481\n",
      "Epoch 331/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0492 - acc: 0.7407 - val_loss: 1.1694 - val_acc: 0.6481\n",
      "Epoch 332/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0467 - acc: 0.7407 - val_loss: 1.1668 - val_acc: 0.6481\n",
      "Epoch 333/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.0426 - acc: 0.7407 - val_loss: 1.1644 - val_acc: 0.6481\n",
      "Epoch 334/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.0399 - acc: 0.7500 - val_loss: 1.1621 - val_acc: 0.6481\n",
      "Epoch 335/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0365 - acc: 0.7407 - val_loss: 1.1592 - val_acc: 0.6481\n",
      "Epoch 336/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0342 - acc: 0.7407 - val_loss: 1.1554 - val_acc: 0.6481\n",
      "Epoch 337/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0307 - acc: 0.7454 - val_loss: 1.1518 - val_acc: 0.6481\n",
      "Epoch 338/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0274 - acc: 0.7454 - val_loss: 1.1489 - val_acc: 0.6296\n",
      "Epoch 339/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0250 - acc: 0.7454 - val_loss: 1.1461 - val_acc: 0.6481\n",
      "Epoch 340/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0216 - acc: 0.7454 - val_loss: 1.1442 - val_acc: 0.6481\n",
      "Epoch 341/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0188 - acc: 0.7454 - val_loss: 1.1412 - val_acc: 0.6481\n",
      "Epoch 342/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0154 - acc: 0.7454 - val_loss: 1.1391 - val_acc: 0.6481\n",
      "Epoch 343/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0126 - acc: 0.7454 - val_loss: 1.1364 - val_acc: 0.6481\n",
      "Epoch 344/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0096 - acc: 0.7454 - val_loss: 1.1333 - val_acc: 0.6481\n",
      "Epoch 345/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0066 - acc: 0.7454 - val_loss: 1.1299 - val_acc: 0.6481\n",
      "Epoch 346/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0035 - acc: 0.7454 - val_loss: 1.1267 - val_acc: 0.6481\n",
      "Epoch 347/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0004 - acc: 0.7454 - val_loss: 1.1237 - val_acc: 0.6296\n",
      "Epoch 348/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.9984 - acc: 0.7500 - val_loss: 1.1215 - val_acc: 0.6296\n",
      "Epoch 349/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.9947 - acc: 0.7500 - val_loss: 1.1184 - val_acc: 0.6481\n",
      "Epoch 350/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.9918 - acc: 0.7593 - val_loss: 1.1155 - val_acc: 0.6481\n",
      "Epoch 351/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.9888 - acc: 0.7546 - val_loss: 1.1128 - val_acc: 0.6481\n",
      "Epoch 352/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.9862 - acc: 0.7500 - val_loss: 1.1104 - val_acc: 0.6481\n",
      "Epoch 353/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.9831 - acc: 0.7500 - val_loss: 1.1072 - val_acc: 0.6296\n",
      "Epoch 354/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.9805 - acc: 0.7454 - val_loss: 1.1045 - val_acc: 0.6296\n",
      "Epoch 355/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 130us/step - loss: 0.9776 - acc: 0.7500 - val_loss: 1.1021 - val_acc: 0.6296\n",
      "Epoch 356/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.9748 - acc: 0.7454 - val_loss: 1.0991 - val_acc: 0.6296\n",
      "Epoch 357/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 0.9715 - acc: 0.7500 - val_loss: 1.0961 - val_acc: 0.6296\n",
      "Epoch 358/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.9692 - acc: 0.7546 - val_loss: 1.0944 - val_acc: 0.6296\n",
      "Epoch 359/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.9659 - acc: 0.7454 - val_loss: 1.0919 - val_acc: 0.6296\n",
      "Epoch 360/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.9636 - acc: 0.7454 - val_loss: 1.0890 - val_acc: 0.6296\n",
      "Epoch 361/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.9603 - acc: 0.7593 - val_loss: 1.0867 - val_acc: 0.6296\n",
      "Epoch 362/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.9577 - acc: 0.7546 - val_loss: 1.0837 - val_acc: 0.6296\n",
      "Epoch 363/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.9546 - acc: 0.7546 - val_loss: 1.0808 - val_acc: 0.6296\n",
      "Epoch 364/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.9525 - acc: 0.7639 - val_loss: 1.0779 - val_acc: 0.6296\n",
      "Epoch 365/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.9495 - acc: 0.7546 - val_loss: 1.0753 - val_acc: 0.6296\n",
      "Epoch 366/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.9468 - acc: 0.7593 - val_loss: 1.0728 - val_acc: 0.6296\n",
      "Epoch 367/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.9435 - acc: 0.7593 - val_loss: 1.0701 - val_acc: 0.6296\n",
      "Epoch 368/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.9415 - acc: 0.7546 - val_loss: 1.0673 - val_acc: 0.6481\n",
      "Epoch 369/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.9383 - acc: 0.7593 - val_loss: 1.0647 - val_acc: 0.6296\n",
      "Epoch 370/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.9353 - acc: 0.7500 - val_loss: 1.0621 - val_acc: 0.6481\n",
      "Epoch 371/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.9333 - acc: 0.7500 - val_loss: 1.0594 - val_acc: 0.6296\n",
      "Epoch 372/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.9302 - acc: 0.7546 - val_loss: 1.0565 - val_acc: 0.6481\n",
      "Epoch 373/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.9275 - acc: 0.7593 - val_loss: 1.0530 - val_acc: 0.6481\n",
      "Epoch 374/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.9254 - acc: 0.7546 - val_loss: 1.0503 - val_acc: 0.6481\n",
      "Epoch 375/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.9221 - acc: 0.7546 - val_loss: 1.0478 - val_acc: 0.6481\n",
      "Epoch 376/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.9195 - acc: 0.7593 - val_loss: 1.0458 - val_acc: 0.6481\n",
      "Epoch 377/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.9166 - acc: 0.7639 - val_loss: 1.0433 - val_acc: 0.6481\n",
      "Epoch 378/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.9142 - acc: 0.7546 - val_loss: 1.0404 - val_acc: 0.6481\n",
      "Epoch 379/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.9113 - acc: 0.7685 - val_loss: 1.0378 - val_acc: 0.6481\n",
      "Epoch 380/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.9086 - acc: 0.7593 - val_loss: 1.0344 - val_acc: 0.6481\n",
      "Epoch 381/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.9065 - acc: 0.7639 - val_loss: 1.0313 - val_acc: 0.6481\n",
      "Epoch 382/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.9039 - acc: 0.7685 - val_loss: 1.0288 - val_acc: 0.6481\n",
      "Epoch 383/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.9010 - acc: 0.7685 - val_loss: 1.0255 - val_acc: 0.6481\n",
      "Epoch 384/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.8980 - acc: 0.7593 - val_loss: 1.0232 - val_acc: 0.6481\n",
      "Epoch 385/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8955 - acc: 0.7778 - val_loss: 1.0201 - val_acc: 0.6481\n",
      "Epoch 386/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8929 - acc: 0.7824 - val_loss: 1.0180 - val_acc: 0.6481\n",
      "Epoch 387/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.8906 - acc: 0.7778 - val_loss: 1.0148 - val_acc: 0.6481\n",
      "Epoch 388/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8874 - acc: 0.7731 - val_loss: 1.0127 - val_acc: 0.6481\n",
      "Epoch 389/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.8851 - acc: 0.7685 - val_loss: 1.0108 - val_acc: 0.6481\n",
      "Epoch 390/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.8827 - acc: 0.7731 - val_loss: 1.0085 - val_acc: 0.6481\n",
      "Epoch 391/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.8803 - acc: 0.7870 - val_loss: 1.0064 - val_acc: 0.6481\n",
      "Epoch 392/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.8777 - acc: 0.7778 - val_loss: 1.0037 - val_acc: 0.6481\n",
      "Epoch 393/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8749 - acc: 0.7824 - val_loss: 1.0011 - val_acc: 0.6481\n",
      "Epoch 394/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.8725 - acc: 0.7778 - val_loss: 0.9980 - val_acc: 0.6481\n",
      "Epoch 395/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8701 - acc: 0.7824 - val_loss: 0.9960 - val_acc: 0.6481\n",
      "Epoch 396/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8672 - acc: 0.7870 - val_loss: 0.9937 - val_acc: 0.6481\n",
      "Epoch 397/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.8651 - acc: 0.7870 - val_loss: 0.9910 - val_acc: 0.6481\n",
      "Epoch 398/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.8623 - acc: 0.7917 - val_loss: 0.9881 - val_acc: 0.6481\n",
      "Epoch 399/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.8598 - acc: 0.7917 - val_loss: 0.9855 - val_acc: 0.6481\n",
      "Epoch 400/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8570 - acc: 0.7870 - val_loss: 0.9831 - val_acc: 0.6481\n",
      "Epoch 401/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.8553 - acc: 0.8009 - val_loss: 0.9814 - val_acc: 0.6481\n",
      "Epoch 402/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.8525 - acc: 0.7917 - val_loss: 0.9785 - val_acc: 0.6481\n",
      "Epoch 403/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.8501 - acc: 0.7917 - val_loss: 0.9760 - val_acc: 0.6481\n",
      "Epoch 404/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.8474 - acc: 0.7917 - val_loss: 0.9737 - val_acc: 0.6481\n",
      "Epoch 405/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8450 - acc: 0.8009 - val_loss: 0.9713 - val_acc: 0.6481\n",
      "Epoch 406/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8422 - acc: 0.8056 - val_loss: 0.9691 - val_acc: 0.6481\n",
      "Epoch 407/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.8401 - acc: 0.7963 - val_loss: 0.9665 - val_acc: 0.6481\n",
      "Epoch 408/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8374 - acc: 0.8102 - val_loss: 0.9641 - val_acc: 0.6481\n",
      "Epoch 409/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8355 - acc: 0.8009 - val_loss: 0.9611 - val_acc: 0.6481\n",
      "Epoch 410/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.8328 - acc: 0.8056 - val_loss: 0.9582 - val_acc: 0.6481\n",
      "Epoch 411/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8302 - acc: 0.8148 - val_loss: 0.9553 - val_acc: 0.6481\n",
      "Epoch 412/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8279 - acc: 0.8102 - val_loss: 0.9529 - val_acc: 0.6481\n",
      "Epoch 413/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8256 - acc: 0.8102 - val_loss: 0.9509 - val_acc: 0.6481\n",
      "Epoch 414/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.8233 - acc: 0.8148 - val_loss: 0.9486 - val_acc: 0.6481\n",
      "Epoch 415/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.8211 - acc: 0.8148 - val_loss: 0.9464 - val_acc: 0.6481\n",
      "Epoch 416/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.8181 - acc: 0.8102 - val_loss: 0.9448 - val_acc: 0.6481\n",
      "Epoch 417/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8161 - acc: 0.8148 - val_loss: 0.9427 - val_acc: 0.6481\n",
      "Epoch 418/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.8138 - acc: 0.8194 - val_loss: 0.9402 - val_acc: 0.6481\n",
      "Epoch 419/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.8115 - acc: 0.8148 - val_loss: 0.9381 - val_acc: 0.6481\n",
      "Epoch 420/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.8094 - acc: 0.8194 - val_loss: 0.9358 - val_acc: 0.6481\n",
      "Epoch 421/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.8063 - acc: 0.8148 - val_loss: 0.9337 - val_acc: 0.6481\n",
      "Epoch 422/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.8041 - acc: 0.8194 - val_loss: 0.9310 - val_acc: 0.6667\n",
      "Epoch 423/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.8027 - acc: 0.8194 - val_loss: 0.9279 - val_acc: 0.6667\n",
      "Epoch 424/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.7995 - acc: 0.8194 - val_loss: 0.9258 - val_acc: 0.6667\n",
      "Epoch 425/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7969 - acc: 0.8148 - val_loss: 0.9233 - val_acc: 0.6667\n",
      "Epoch 426/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.7953 - acc: 0.8148 - val_loss: 0.9210 - val_acc: 0.6667\n",
      "Epoch 427/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.7930 - acc: 0.8148 - val_loss: 0.9189 - val_acc: 0.6667\n",
      "Epoch 428/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7904 - acc: 0.8148 - val_loss: 0.9171 - val_acc: 0.6667\n",
      "Epoch 429/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.7879 - acc: 0.8194 - val_loss: 0.9151 - val_acc: 0.6667\n",
      "Epoch 430/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.7855 - acc: 0.8194 - val_loss: 0.9126 - val_acc: 0.6667\n",
      "Epoch 431/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7839 - acc: 0.8148 - val_loss: 0.9107 - val_acc: 0.6667\n",
      "Epoch 432/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.7812 - acc: 0.8148 - val_loss: 0.9086 - val_acc: 0.6667\n",
      "Epoch 433/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.7794 - acc: 0.8194 - val_loss: 0.9079 - val_acc: 0.6667\n",
      "Epoch 434/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.7769 - acc: 0.8194 - val_loss: 0.9051 - val_acc: 0.6667\n",
      "Epoch 435/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7745 - acc: 0.8194 - val_loss: 0.9025 - val_acc: 0.6667\n",
      "Epoch 436/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.7724 - acc: 0.8194 - val_loss: 0.8998 - val_acc: 0.6667\n",
      "Epoch 437/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.7697 - acc: 0.8148 - val_loss: 0.8973 - val_acc: 0.6667\n",
      "Epoch 438/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7677 - acc: 0.8194 - val_loss: 0.8948 - val_acc: 0.6667\n",
      "Epoch 439/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.7654 - acc: 0.8194 - val_loss: 0.8936 - val_acc: 0.6667\n",
      "Epoch 440/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.7633 - acc: 0.8194 - val_loss: 0.8913 - val_acc: 0.6667\n",
      "Epoch 441/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.7616 - acc: 0.8194 - val_loss: 0.8883 - val_acc: 0.6667\n",
      "Epoch 442/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7589 - acc: 0.8194 - val_loss: 0.8863 - val_acc: 0.6667\n",
      "Epoch 443/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7563 - acc: 0.8194 - val_loss: 0.8848 - val_acc: 0.6667\n",
      "Epoch 444/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.7542 - acc: 0.8194 - val_loss: 0.8823 - val_acc: 0.6667\n",
      "Epoch 445/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.7523 - acc: 0.8194 - val_loss: 0.8795 - val_acc: 0.6667\n",
      "Epoch 446/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.7504 - acc: 0.8194 - val_loss: 0.8771 - val_acc: 0.6667\n",
      "Epoch 447/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.7478 - acc: 0.8194 - val_loss: 0.8749 - val_acc: 0.6667\n",
      "Epoch 448/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.7458 - acc: 0.8194 - val_loss: 0.8732 - val_acc: 0.6667\n",
      "Epoch 449/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.7441 - acc: 0.8241 - val_loss: 0.8709 - val_acc: 0.6667\n",
      "Epoch 450/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.7414 - acc: 0.8194 - val_loss: 0.8686 - val_acc: 0.6667\n",
      "Epoch 451/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.7397 - acc: 0.8194 - val_loss: 0.8671 - val_acc: 0.6667\n",
      "Epoch 452/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.7377 - acc: 0.8148 - val_loss: 0.8653 - val_acc: 0.6667\n",
      "Epoch 453/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.7353 - acc: 0.8194 - val_loss: 0.8636 - val_acc: 0.6667\n",
      "Epoch 454/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.7331 - acc: 0.8194 - val_loss: 0.8615 - val_acc: 0.6667\n",
      "Epoch 455/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.7314 - acc: 0.8241 - val_loss: 0.8594 - val_acc: 0.6667\n",
      "Epoch 456/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.7292 - acc: 0.8194 - val_loss: 0.8577 - val_acc: 0.6667\n",
      "Epoch 457/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.7271 - acc: 0.8333 - val_loss: 0.8550 - val_acc: 0.6667\n",
      "Epoch 458/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.7248 - acc: 0.8287 - val_loss: 0.8528 - val_acc: 0.6667\n",
      "Epoch 459/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.7230 - acc: 0.8287 - val_loss: 0.8512 - val_acc: 0.6667\n",
      "Epoch 460/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.7207 - acc: 0.8333 - val_loss: 0.8492 - val_acc: 0.6667\n",
      "Epoch 461/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.7187 - acc: 0.8287 - val_loss: 0.8478 - val_acc: 0.6667\n",
      "Epoch 462/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.7162 - acc: 0.8287 - val_loss: 0.8454 - val_acc: 0.6667\n",
      "Epoch 463/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.7143 - acc: 0.8241 - val_loss: 0.8430 - val_acc: 0.6667\n",
      "Epoch 464/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.7125 - acc: 0.8287 - val_loss: 0.8409 - val_acc: 0.6667\n",
      "Epoch 465/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.7104 - acc: 0.8333 - val_loss: 0.8382 - val_acc: 0.6667\n",
      "Epoch 466/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.7083 - acc: 0.8287 - val_loss: 0.8363 - val_acc: 0.6667\n",
      "Epoch 467/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.7065 - acc: 0.8287 - val_loss: 0.8345 - val_acc: 0.6667\n",
      "Epoch 468/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.7038 - acc: 0.8287 - val_loss: 0.8330 - val_acc: 0.6667\n",
      "Epoch 469/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.7024 - acc: 0.8287 - val_loss: 0.8310 - val_acc: 0.6667\n",
      "Epoch 470/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.7000 - acc: 0.8333 - val_loss: 0.8287 - val_acc: 0.6667\n",
      "Epoch 471/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6982 - acc: 0.8333 - val_loss: 0.8266 - val_acc: 0.6667\n",
      "Epoch 472/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.6964 - acc: 0.8333 - val_loss: 0.8243 - val_acc: 0.6667\n",
      "Epoch 473/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 102us/step - loss: 0.6939 - acc: 0.8333 - val_loss: 0.8229 - val_acc: 0.6667\n",
      "Epoch 474/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6922 - acc: 0.8287 - val_loss: 0.8211 - val_acc: 0.6667\n",
      "Epoch 475/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6905 - acc: 0.8287 - val_loss: 0.8194 - val_acc: 0.6667\n",
      "Epoch 476/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6879 - acc: 0.8333 - val_loss: 0.8171 - val_acc: 0.6667\n",
      "Epoch 477/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6863 - acc: 0.8333 - val_loss: 0.8151 - val_acc: 0.6667\n",
      "Epoch 478/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6842 - acc: 0.8287 - val_loss: 0.8132 - val_acc: 0.6667\n",
      "Epoch 479/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.6823 - acc: 0.8333 - val_loss: 0.8113 - val_acc: 0.6667\n",
      "Epoch 480/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.6802 - acc: 0.8287 - val_loss: 0.8089 - val_acc: 0.6667\n",
      "Epoch 481/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6781 - acc: 0.8333 - val_loss: 0.8074 - val_acc: 0.6852\n",
      "Epoch 482/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6759 - acc: 0.8333 - val_loss: 0.8052 - val_acc: 0.6852\n",
      "Epoch 483/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.6748 - acc: 0.8333 - val_loss: 0.8034 - val_acc: 0.6852\n",
      "Epoch 484/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6723 - acc: 0.8333 - val_loss: 0.8011 - val_acc: 0.6852\n",
      "Epoch 485/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6704 - acc: 0.8333 - val_loss: 0.7997 - val_acc: 0.6852\n",
      "Epoch 486/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6685 - acc: 0.8333 - val_loss: 0.7973 - val_acc: 0.6852\n",
      "Epoch 487/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.6667 - acc: 0.8333 - val_loss: 0.7953 - val_acc: 0.6852\n",
      "Epoch 488/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6644 - acc: 0.8333 - val_loss: 0.7936 - val_acc: 0.6852\n",
      "Epoch 489/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6626 - acc: 0.8333 - val_loss: 0.7918 - val_acc: 0.6852\n",
      "Epoch 490/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6605 - acc: 0.8333 - val_loss: 0.7900 - val_acc: 0.6852\n",
      "Epoch 491/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.6588 - acc: 0.8333 - val_loss: 0.7883 - val_acc: 0.6852\n",
      "Epoch 492/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6568 - acc: 0.8333 - val_loss: 0.7865 - val_acc: 0.6852\n",
      "Epoch 493/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6550 - acc: 0.8333 - val_loss: 0.7832 - val_acc: 0.6852\n",
      "Epoch 494/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.6532 - acc: 0.8333 - val_loss: 0.7818 - val_acc: 0.7037\n",
      "Epoch 495/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.6516 - acc: 0.8333 - val_loss: 0.7802 - val_acc: 0.7037\n",
      "Epoch 496/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6496 - acc: 0.8333 - val_loss: 0.7783 - val_acc: 0.7037\n",
      "Epoch 497/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6475 - acc: 0.8426 - val_loss: 0.7762 - val_acc: 0.6852\n",
      "Epoch 498/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.6457 - acc: 0.8380 - val_loss: 0.7751 - val_acc: 0.6852\n",
      "Epoch 499/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6440 - acc: 0.8380 - val_loss: 0.7736 - val_acc: 0.6852\n",
      "Epoch 500/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.6423 - acc: 0.8380 - val_loss: 0.7713 - val_acc: 0.6852\n",
      "Epoch 501/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.6399 - acc: 0.8380 - val_loss: 0.7703 - val_acc: 0.7037\n",
      "Epoch 502/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.6384 - acc: 0.8380 - val_loss: 0.7688 - val_acc: 0.7037\n",
      "Epoch 503/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6363 - acc: 0.8380 - val_loss: 0.7662 - val_acc: 0.7222\n",
      "Epoch 504/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6346 - acc: 0.8426 - val_loss: 0.7643 - val_acc: 0.7037\n",
      "Epoch 505/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6330 - acc: 0.8380 - val_loss: 0.7633 - val_acc: 0.7222\n",
      "Epoch 506/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.6309 - acc: 0.8380 - val_loss: 0.7607 - val_acc: 0.7407\n",
      "Epoch 507/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6291 - acc: 0.8380 - val_loss: 0.7583 - val_acc: 0.7593\n",
      "Epoch 508/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6270 - acc: 0.8380 - val_loss: 0.7561 - val_acc: 0.7593\n",
      "Epoch 509/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6257 - acc: 0.8472 - val_loss: 0.7543 - val_acc: 0.7593\n",
      "Epoch 510/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.6232 - acc: 0.8380 - val_loss: 0.7529 - val_acc: 0.7593\n",
      "Epoch 511/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6220 - acc: 0.8426 - val_loss: 0.7503 - val_acc: 0.7593\n",
      "Epoch 512/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.6199 - acc: 0.8380 - val_loss: 0.7482 - val_acc: 0.7593\n",
      "Epoch 513/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6178 - acc: 0.8472 - val_loss: 0.7465 - val_acc: 0.7593\n",
      "Epoch 514/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.6166 - acc: 0.8380 - val_loss: 0.7452 - val_acc: 0.7593\n",
      "Epoch 515/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.6147 - acc: 0.8472 - val_loss: 0.7430 - val_acc: 0.7593\n",
      "Epoch 516/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.6130 - acc: 0.8472 - val_loss: 0.7418 - val_acc: 0.7593\n",
      "Epoch 517/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.6111 - acc: 0.8380 - val_loss: 0.7401 - val_acc: 0.7593\n",
      "Epoch 518/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.6096 - acc: 0.8426 - val_loss: 0.7383 - val_acc: 0.7593\n",
      "Epoch 519/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.6074 - acc: 0.8426 - val_loss: 0.7365 - val_acc: 0.7593\n",
      "Epoch 520/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.6062 - acc: 0.8472 - val_loss: 0.7347 - val_acc: 0.7593\n",
      "Epoch 521/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.6041 - acc: 0.8519 - val_loss: 0.7325 - val_acc: 0.7593\n",
      "Epoch 522/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.6026 - acc: 0.8519 - val_loss: 0.7309 - val_acc: 0.7593\n",
      "Epoch 523/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.6004 - acc: 0.8565 - val_loss: 0.7294 - val_acc: 0.7593\n",
      "Epoch 524/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5990 - acc: 0.8472 - val_loss: 0.7268 - val_acc: 0.7593\n",
      "Epoch 525/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5970 - acc: 0.8565 - val_loss: 0.7258 - val_acc: 0.7593\n",
      "Epoch 526/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.5955 - acc: 0.8519 - val_loss: 0.7238 - val_acc: 0.7593\n",
      "Epoch 527/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.5937 - acc: 0.8519 - val_loss: 0.7218 - val_acc: 0.7593\n",
      "Epoch 528/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.5916 - acc: 0.8611 - val_loss: 0.7200 - val_acc: 0.7593\n",
      "Epoch 529/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.5906 - acc: 0.8472 - val_loss: 0.7183 - val_acc: 0.7778\n",
      "Epoch 530/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.5890 - acc: 0.8565 - val_loss: 0.7164 - val_acc: 0.7778\n",
      "Epoch 531/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.5869 - acc: 0.8565 - val_loss: 0.7142 - val_acc: 0.7778\n",
      "Epoch 532/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.5854 - acc: 0.8565 - val_loss: 0.7127 - val_acc: 0.7778\n",
      "Epoch 533/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.5839 - acc: 0.8565 - val_loss: 0.7112 - val_acc: 0.7778\n",
      "Epoch 534/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.5819 - acc: 0.8611 - val_loss: 0.7100 - val_acc: 0.7778\n",
      "Epoch 535/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.5804 - acc: 0.8657 - val_loss: 0.7083 - val_acc: 0.7778\n",
      "Epoch 536/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.5787 - acc: 0.8657 - val_loss: 0.7075 - val_acc: 0.7778\n",
      "Epoch 537/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5771 - acc: 0.8657 - val_loss: 0.7058 - val_acc: 0.7778\n",
      "Epoch 538/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.5757 - acc: 0.8611 - val_loss: 0.7043 - val_acc: 0.7778\n",
      "Epoch 539/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.5740 - acc: 0.8657 - val_loss: 0.7030 - val_acc: 0.7778\n",
      "Epoch 540/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.5720 - acc: 0.8657 - val_loss: 0.7015 - val_acc: 0.7778\n",
      "Epoch 541/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.5706 - acc: 0.8657 - val_loss: 0.6992 - val_acc: 0.7778\n",
      "Epoch 542/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.5690 - acc: 0.8657 - val_loss: 0.6977 - val_acc: 0.7778\n",
      "Epoch 543/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.5674 - acc: 0.8657 - val_loss: 0.6961 - val_acc: 0.7963\n",
      "Epoch 544/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.5659 - acc: 0.8657 - val_loss: 0.6949 - val_acc: 0.7963\n",
      "Epoch 545/10000\n",
      "216/216 [==============================] - ETA: 0s - loss: 0.5626 - acc: 0.950 - 0s 167us/step - loss: 0.5640 - acc: 0.8657 - val_loss: 0.6939 - val_acc: 0.7963\n",
      "Epoch 546/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.5624 - acc: 0.8657 - val_loss: 0.6920 - val_acc: 0.7778\n",
      "Epoch 547/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.5609 - acc: 0.8657 - val_loss: 0.6903 - val_acc: 0.7963\n",
      "Epoch 548/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.5598 - acc: 0.8657 - val_loss: 0.6886 - val_acc: 0.7963\n",
      "Epoch 549/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.5581 - acc: 0.8657 - val_loss: 0.6864 - val_acc: 0.7963\n",
      "Epoch 550/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.5561 - acc: 0.8657 - val_loss: 0.6850 - val_acc: 0.7963\n",
      "Epoch 551/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.5548 - acc: 0.8657 - val_loss: 0.6840 - val_acc: 0.7963\n",
      "Epoch 552/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.5532 - acc: 0.8657 - val_loss: 0.6826 - val_acc: 0.7963\n",
      "Epoch 553/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.5517 - acc: 0.8657 - val_loss: 0.6805 - val_acc: 0.7963\n",
      "Epoch 554/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.5498 - acc: 0.8657 - val_loss: 0.6787 - val_acc: 0.7963\n",
      "Epoch 555/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.5482 - acc: 0.8657 - val_loss: 0.6777 - val_acc: 0.7963\n",
      "Epoch 556/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.5473 - acc: 0.8657 - val_loss: 0.6763 - val_acc: 0.7963\n",
      "Epoch 557/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5451 - acc: 0.8657 - val_loss: 0.6750 - val_acc: 0.7963\n",
      "Epoch 558/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.5439 - acc: 0.8657 - val_loss: 0.6738 - val_acc: 0.7963\n",
      "Epoch 559/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.5422 - acc: 0.8657 - val_loss: 0.6730 - val_acc: 0.7963\n",
      "Epoch 560/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.5404 - acc: 0.8657 - val_loss: 0.6710 - val_acc: 0.7963\n",
      "Epoch 561/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.5393 - acc: 0.8704 - val_loss: 0.6697 - val_acc: 0.7963\n",
      "Epoch 562/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.5377 - acc: 0.8750 - val_loss: 0.6673 - val_acc: 0.7963\n",
      "Epoch 563/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.5361 - acc: 0.8657 - val_loss: 0.6656 - val_acc: 0.7963\n",
      "Epoch 564/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.5345 - acc: 0.8704 - val_loss: 0.6645 - val_acc: 0.7963\n",
      "Epoch 565/10000\n",
      "216/216 [==============================] - 0s 236us/step - loss: 0.5332 - acc: 0.8704 - val_loss: 0.6632 - val_acc: 0.7963\n",
      "Epoch 566/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5320 - acc: 0.8704 - val_loss: 0.6622 - val_acc: 0.7963\n",
      "Epoch 567/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5302 - acc: 0.8796 - val_loss: 0.6611 - val_acc: 0.7963\n",
      "Epoch 568/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.5290 - acc: 0.8750 - val_loss: 0.6598 - val_acc: 0.7963\n",
      "Epoch 569/10000\n",
      "216/216 [==============================] - 0s 227us/step - loss: 0.5270 - acc: 0.8750 - val_loss: 0.6578 - val_acc: 0.7963\n",
      "Epoch 570/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.5255 - acc: 0.8750 - val_loss: 0.6567 - val_acc: 0.7963\n",
      "Epoch 571/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.5246 - acc: 0.8796 - val_loss: 0.6555 - val_acc: 0.7963\n",
      "Epoch 572/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.5225 - acc: 0.8750 - val_loss: 0.6544 - val_acc: 0.7963\n",
      "Epoch 573/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.5214 - acc: 0.8796 - val_loss: 0.6525 - val_acc: 0.7963\n",
      "Epoch 574/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.5198 - acc: 0.8796 - val_loss: 0.6517 - val_acc: 0.7963\n",
      "Epoch 575/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.5186 - acc: 0.8796 - val_loss: 0.6502 - val_acc: 0.7963\n",
      "Epoch 576/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.5170 - acc: 0.8796 - val_loss: 0.6486 - val_acc: 0.7963\n",
      "Epoch 577/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.5158 - acc: 0.8796 - val_loss: 0.6475 - val_acc: 0.7963\n",
      "Epoch 578/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.5142 - acc: 0.8843 - val_loss: 0.6472 - val_acc: 0.7963\n",
      "Epoch 579/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.5130 - acc: 0.8843 - val_loss: 0.6468 - val_acc: 0.7963\n",
      "Epoch 580/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.5113 - acc: 0.8796 - val_loss: 0.6453 - val_acc: 0.7963\n",
      "Epoch 581/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5095 - acc: 0.8843 - val_loss: 0.6440 - val_acc: 0.7963\n",
      "Epoch 582/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.5085 - acc: 0.8796 - val_loss: 0.6426 - val_acc: 0.7963\n",
      "Epoch 583/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.5073 - acc: 0.8843 - val_loss: 0.6414 - val_acc: 0.7963\n",
      "Epoch 584/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.5058 - acc: 0.8843 - val_loss: 0.6400 - val_acc: 0.7963\n",
      "Epoch 585/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5044 - acc: 0.8843 - val_loss: 0.6389 - val_acc: 0.7963\n",
      "Epoch 586/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.5029 - acc: 0.8843 - val_loss: 0.6376 - val_acc: 0.7963\n",
      "Epoch 587/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.5015 - acc: 0.8843 - val_loss: 0.6361 - val_acc: 0.8148\n",
      "Epoch 588/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.5004 - acc: 0.8843 - val_loss: 0.6342 - val_acc: 0.8148\n",
      "Epoch 589/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4986 - acc: 0.8843 - val_loss: 0.6327 - val_acc: 0.8148\n",
      "Epoch 590/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4970 - acc: 0.8843 - val_loss: 0.6310 - val_acc: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.4959 - acc: 0.8843 - val_loss: 0.6296 - val_acc: 0.8148\n",
      "Epoch 592/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4944 - acc: 0.8796 - val_loss: 0.6280 - val_acc: 0.8148\n",
      "Epoch 593/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4933 - acc: 0.8843 - val_loss: 0.6262 - val_acc: 0.8148\n",
      "Epoch 594/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4917 - acc: 0.8843 - val_loss: 0.6265 - val_acc: 0.8148\n",
      "Epoch 595/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 0.4905 - acc: 0.8843 - val_loss: 0.6249 - val_acc: 0.8148\n",
      "Epoch 596/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.4893 - acc: 0.8796 - val_loss: 0.6237 - val_acc: 0.8148\n",
      "Epoch 597/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.4878 - acc: 0.8796 - val_loss: 0.6226 - val_acc: 0.8148\n",
      "Epoch 598/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4866 - acc: 0.8796 - val_loss: 0.6212 - val_acc: 0.8148\n",
      "Epoch 599/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4852 - acc: 0.8796 - val_loss: 0.6206 - val_acc: 0.8148\n",
      "Epoch 600/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.4834 - acc: 0.8843 - val_loss: 0.6193 - val_acc: 0.8148\n",
      "Epoch 601/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4824 - acc: 0.8889 - val_loss: 0.6182 - val_acc: 0.8148\n",
      "Epoch 602/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4805 - acc: 0.8796 - val_loss: 0.6168 - val_acc: 0.8148\n",
      "Epoch 603/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.4803 - acc: 0.8796 - val_loss: 0.6156 - val_acc: 0.8148\n",
      "Epoch 604/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.4780 - acc: 0.8843 - val_loss: 0.6141 - val_acc: 0.8148\n",
      "Epoch 605/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4770 - acc: 0.8796 - val_loss: 0.6131 - val_acc: 0.8148\n",
      "Epoch 606/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.4756 - acc: 0.8796 - val_loss: 0.6119 - val_acc: 0.8148\n",
      "Epoch 607/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4745 - acc: 0.8843 - val_loss: 0.6105 - val_acc: 0.8148\n",
      "Epoch 608/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.4734 - acc: 0.8796 - val_loss: 0.6096 - val_acc: 0.8148\n",
      "Epoch 609/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4716 - acc: 0.8843 - val_loss: 0.6080 - val_acc: 0.8148\n",
      "Epoch 610/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4701 - acc: 0.8843 - val_loss: 0.6072 - val_acc: 0.8148\n",
      "Epoch 611/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.4692 - acc: 0.8889 - val_loss: 0.6059 - val_acc: 0.8148\n",
      "Epoch 612/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4681 - acc: 0.8843 - val_loss: 0.6043 - val_acc: 0.8148\n",
      "Epoch 613/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.4665 - acc: 0.8889 - val_loss: 0.6037 - val_acc: 0.8148\n",
      "Epoch 614/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4651 - acc: 0.8889 - val_loss: 0.6018 - val_acc: 0.8148\n",
      "Epoch 615/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4637 - acc: 0.8935 - val_loss: 0.6007 - val_acc: 0.8148\n",
      "Epoch 616/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4628 - acc: 0.8843 - val_loss: 0.5996 - val_acc: 0.8148\n",
      "Epoch 617/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4619 - acc: 0.8935 - val_loss: 0.5987 - val_acc: 0.8148\n",
      "Epoch 618/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4601 - acc: 0.8935 - val_loss: 0.5973 - val_acc: 0.8148\n",
      "Epoch 619/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.4586 - acc: 0.8935 - val_loss: 0.5955 - val_acc: 0.8333\n",
      "Epoch 620/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.4575 - acc: 0.8889 - val_loss: 0.5942 - val_acc: 0.8333\n",
      "Epoch 621/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.4565 - acc: 0.8889 - val_loss: 0.5927 - val_acc: 0.8333\n",
      "Epoch 622/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4559 - acc: 0.8889 - val_loss: 0.5920 - val_acc: 0.8333\n",
      "Epoch 623/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.4540 - acc: 0.8889 - val_loss: 0.5906 - val_acc: 0.8333\n",
      "Epoch 624/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4530 - acc: 0.8935 - val_loss: 0.5892 - val_acc: 0.8333\n",
      "Epoch 625/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4516 - acc: 0.8889 - val_loss: 0.5880 - val_acc: 0.8333\n",
      "Epoch 626/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4503 - acc: 0.8935 - val_loss: 0.5865 - val_acc: 0.8333\n",
      "Epoch 627/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 0.4495 - acc: 0.8889 - val_loss: 0.5856 - val_acc: 0.8333\n",
      "Epoch 628/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.4477 - acc: 0.8935 - val_loss: 0.5848 - val_acc: 0.8333\n",
      "Epoch 629/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.4470 - acc: 0.8935 - val_loss: 0.5839 - val_acc: 0.8333\n",
      "Epoch 630/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.4454 - acc: 0.8935 - val_loss: 0.5817 - val_acc: 0.8333\n",
      "Epoch 631/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4442 - acc: 0.8935 - val_loss: 0.5808 - val_acc: 0.8333\n",
      "Epoch 632/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.4429 - acc: 0.8935 - val_loss: 0.5797 - val_acc: 0.8333\n",
      "Epoch 633/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.4421 - acc: 0.8935 - val_loss: 0.5786 - val_acc: 0.8333\n",
      "Epoch 634/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4410 - acc: 0.8935 - val_loss: 0.5778 - val_acc: 0.8333\n",
      "Epoch 635/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4395 - acc: 0.8935 - val_loss: 0.5775 - val_acc: 0.8333\n",
      "Epoch 636/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.4381 - acc: 0.8935 - val_loss: 0.5767 - val_acc: 0.8333\n",
      "Epoch 637/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.4374 - acc: 0.8935 - val_loss: 0.5755 - val_acc: 0.8333\n",
      "Epoch 638/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 0.4362 - acc: 0.8935 - val_loss: 0.5741 - val_acc: 0.8333\n",
      "Epoch 639/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.4349 - acc: 0.8935 - val_loss: 0.5729 - val_acc: 0.8333\n",
      "Epoch 640/10000\n",
      "216/216 [==============================] - 0s 190us/step - loss: 0.4340 - acc: 0.8935 - val_loss: 0.5726 - val_acc: 0.8333\n",
      "Epoch 641/10000\n",
      "216/216 [==============================] - 0s 199us/step - loss: 0.4323 - acc: 0.8981 - val_loss: 0.5712 - val_acc: 0.8519\n",
      "Epoch 642/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.4319 - acc: 0.8935 - val_loss: 0.5706 - val_acc: 0.8519\n",
      "Epoch 643/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.4301 - acc: 0.8981 - val_loss: 0.5694 - val_acc: 0.8519\n",
      "Epoch 644/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.4292 - acc: 0.8935 - val_loss: 0.5681 - val_acc: 0.8519\n",
      "Epoch 645/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4282 - acc: 0.8981 - val_loss: 0.5662 - val_acc: 0.8519\n",
      "Epoch 646/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4265 - acc: 0.8935 - val_loss: 0.5655 - val_acc: 0.8519\n",
      "Epoch 647/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4258 - acc: 0.8981 - val_loss: 0.5643 - val_acc: 0.8519\n",
      "Epoch 648/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4243 - acc: 0.8981 - val_loss: 0.5636 - val_acc: 0.8519\n",
      "Epoch 649/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4233 - acc: 0.8981 - val_loss: 0.5627 - val_acc: 0.8519\n",
      "Epoch 650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 93us/step - loss: 0.4220 - acc: 0.8981 - val_loss: 0.5616 - val_acc: 0.8519\n",
      "Epoch 651/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.4212 - acc: 0.8981 - val_loss: 0.5603 - val_acc: 0.8519\n",
      "Epoch 652/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.4202 - acc: 0.8981 - val_loss: 0.5586 - val_acc: 0.8519\n",
      "Epoch 653/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.4183 - acc: 0.8981 - val_loss: 0.5576 - val_acc: 0.8519\n",
      "Epoch 654/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4178 - acc: 0.8981 - val_loss: 0.5572 - val_acc: 0.8519\n",
      "Epoch 655/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4162 - acc: 0.9074 - val_loss: 0.5564 - val_acc: 0.8519\n",
      "Epoch 656/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4156 - acc: 0.9028 - val_loss: 0.5544 - val_acc: 0.8519\n",
      "Epoch 657/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4146 - acc: 0.9074 - val_loss: 0.5532 - val_acc: 0.8519\n",
      "Epoch 658/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4131 - acc: 0.9074 - val_loss: 0.5522 - val_acc: 0.8519\n",
      "Epoch 659/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4119 - acc: 0.8981 - val_loss: 0.5515 - val_acc: 0.8519\n",
      "Epoch 660/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4108 - acc: 0.8981 - val_loss: 0.5499 - val_acc: 0.8519\n",
      "Epoch 661/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4099 - acc: 0.9028 - val_loss: 0.5489 - val_acc: 0.8519\n",
      "Epoch 662/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4088 - acc: 0.9074 - val_loss: 0.5484 - val_acc: 0.8519\n",
      "Epoch 663/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.4080 - acc: 0.9074 - val_loss: 0.5473 - val_acc: 0.8519\n",
      "Epoch 664/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.4068 - acc: 0.9028 - val_loss: 0.5466 - val_acc: 0.8519\n",
      "Epoch 665/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.4055 - acc: 0.9028 - val_loss: 0.5460 - val_acc: 0.8519\n",
      "Epoch 666/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.4042 - acc: 0.8981 - val_loss: 0.5453 - val_acc: 0.8519\n",
      "Epoch 667/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.4030 - acc: 0.9074 - val_loss: 0.5447 - val_acc: 0.8519\n",
      "Epoch 668/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.4025 - acc: 0.9074 - val_loss: 0.5434 - val_acc: 0.8519\n",
      "Epoch 669/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.4015 - acc: 0.9074 - val_loss: 0.5433 - val_acc: 0.8519\n",
      "Epoch 670/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3997 - acc: 0.9074 - val_loss: 0.5420 - val_acc: 0.8519\n",
      "Epoch 671/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3990 - acc: 0.9074 - val_loss: 0.5409 - val_acc: 0.8519\n",
      "Epoch 672/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3981 - acc: 0.9074 - val_loss: 0.5400 - val_acc: 0.8519\n",
      "Epoch 673/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3970 - acc: 0.9120 - val_loss: 0.5390 - val_acc: 0.8519\n",
      "Epoch 674/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3959 - acc: 0.9120 - val_loss: 0.5380 - val_acc: 0.8519\n",
      "Epoch 675/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3945 - acc: 0.9074 - val_loss: 0.5372 - val_acc: 0.8519\n",
      "Epoch 676/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3936 - acc: 0.9074 - val_loss: 0.5361 - val_acc: 0.8519\n",
      "Epoch 677/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3928 - acc: 0.9167 - val_loss: 0.5360 - val_acc: 0.8519\n",
      "Epoch 678/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3917 - acc: 0.9120 - val_loss: 0.5348 - val_acc: 0.8519\n",
      "Epoch 679/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3907 - acc: 0.9120 - val_loss: 0.5338 - val_acc: 0.8519\n",
      "Epoch 680/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3895 - acc: 0.9167 - val_loss: 0.5329 - val_acc: 0.8519\n",
      "Epoch 681/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.3890 - acc: 0.9167 - val_loss: 0.5320 - val_acc: 0.8519\n",
      "Epoch 682/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.3876 - acc: 0.9120 - val_loss: 0.5314 - val_acc: 0.8519\n",
      "Epoch 683/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3864 - acc: 0.9213 - val_loss: 0.5307 - val_acc: 0.8519\n",
      "Epoch 684/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3855 - acc: 0.9213 - val_loss: 0.5298 - val_acc: 0.8519\n",
      "Epoch 685/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3845 - acc: 0.9120 - val_loss: 0.5290 - val_acc: 0.8519\n",
      "Epoch 686/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3833 - acc: 0.9167 - val_loss: 0.5275 - val_acc: 0.8519\n",
      "Epoch 687/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3827 - acc: 0.9213 - val_loss: 0.5259 - val_acc: 0.8519\n",
      "Epoch 688/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3815 - acc: 0.9120 - val_loss: 0.5252 - val_acc: 0.8519\n",
      "Epoch 689/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3802 - acc: 0.9213 - val_loss: 0.5240 - val_acc: 0.8519\n",
      "Epoch 690/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3798 - acc: 0.9213 - val_loss: 0.5236 - val_acc: 0.8519\n",
      "Epoch 691/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3786 - acc: 0.9167 - val_loss: 0.5220 - val_acc: 0.8519\n",
      "Epoch 692/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3772 - acc: 0.9259 - val_loss: 0.5209 - val_acc: 0.8519\n",
      "Epoch 693/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3766 - acc: 0.9213 - val_loss: 0.5205 - val_acc: 0.8519\n",
      "Epoch 694/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3756 - acc: 0.9167 - val_loss: 0.5189 - val_acc: 0.8519\n",
      "Epoch 695/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3743 - acc: 0.9259 - val_loss: 0.5180 - val_acc: 0.8519\n",
      "Epoch 696/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3737 - acc: 0.9259 - val_loss: 0.5172 - val_acc: 0.8519\n",
      "Epoch 697/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3727 - acc: 0.9213 - val_loss: 0.5162 - val_acc: 0.8704\n",
      "Epoch 698/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3714 - acc: 0.9213 - val_loss: 0.5160 - val_acc: 0.8704\n",
      "Epoch 699/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3705 - acc: 0.9259 - val_loss: 0.5155 - val_acc: 0.8704\n",
      "Epoch 700/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3697 - acc: 0.9259 - val_loss: 0.5145 - val_acc: 0.8704\n",
      "Epoch 701/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3680 - acc: 0.9306 - val_loss: 0.5135 - val_acc: 0.8704\n",
      "Epoch 702/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3678 - acc: 0.9306 - val_loss: 0.5119 - val_acc: 0.8704\n",
      "Epoch 703/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.3666 - acc: 0.9259 - val_loss: 0.5109 - val_acc: 0.8704\n",
      "Epoch 704/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.3654 - acc: 0.9306 - val_loss: 0.5105 - val_acc: 0.8704\n",
      "Epoch 705/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3645 - acc: 0.9259 - val_loss: 0.5096 - val_acc: 0.8704\n",
      "Epoch 706/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3639 - acc: 0.9259 - val_loss: 0.5092 - val_acc: 0.8704\n",
      "Epoch 707/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.3628 - acc: 0.9306 - val_loss: 0.5089 - val_acc: 0.8704\n",
      "Epoch 708/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3614 - acc: 0.9306 - val_loss: 0.5080 - val_acc: 0.8704\n",
      "Epoch 709/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3609 - acc: 0.9259 - val_loss: 0.5077 - val_acc: 0.8704\n",
      "Epoch 710/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3599 - acc: 0.9398 - val_loss: 0.5076 - val_acc: 0.8704\n",
      "Epoch 711/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3590 - acc: 0.9352 - val_loss: 0.5065 - val_acc: 0.8704\n",
      "Epoch 712/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3580 - acc: 0.9398 - val_loss: 0.5054 - val_acc: 0.8704\n",
      "Epoch 713/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3572 - acc: 0.9352 - val_loss: 0.5043 - val_acc: 0.8704\n",
      "Epoch 714/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3557 - acc: 0.9398 - val_loss: 0.5036 - val_acc: 0.8704\n",
      "Epoch 715/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3549 - acc: 0.9398 - val_loss: 0.5025 - val_acc: 0.8704\n",
      "Epoch 716/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3542 - acc: 0.9398 - val_loss: 0.5021 - val_acc: 0.8704\n",
      "Epoch 717/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3529 - acc: 0.9352 - val_loss: 0.5007 - val_acc: 0.8704\n",
      "Epoch 718/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3527 - acc: 0.9398 - val_loss: 0.4991 - val_acc: 0.8704\n",
      "Epoch 719/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3508 - acc: 0.9398 - val_loss: 0.4990 - val_acc: 0.8704\n",
      "Epoch 720/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3506 - acc: 0.9352 - val_loss: 0.4982 - val_acc: 0.8704\n",
      "Epoch 721/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3493 - acc: 0.9398 - val_loss: 0.4972 - val_acc: 0.8704\n",
      "Epoch 722/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3482 - acc: 0.9352 - val_loss: 0.4974 - val_acc: 0.8704\n",
      "Epoch 723/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3474 - acc: 0.9398 - val_loss: 0.4966 - val_acc: 0.8704\n",
      "Epoch 724/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3463 - acc: 0.9352 - val_loss: 0.4962 - val_acc: 0.8704\n",
      "Epoch 725/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3458 - acc: 0.9398 - val_loss: 0.4953 - val_acc: 0.8704\n",
      "Epoch 726/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3445 - acc: 0.9352 - val_loss: 0.4944 - val_acc: 0.8704\n",
      "Epoch 727/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3438 - acc: 0.9398 - val_loss: 0.4939 - val_acc: 0.8704\n",
      "Epoch 728/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3432 - acc: 0.9398 - val_loss: 0.4938 - val_acc: 0.8704\n",
      "Epoch 729/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3417 - acc: 0.9306 - val_loss: 0.4921 - val_acc: 0.8704\n",
      "Epoch 730/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.3412 - acc: 0.9352 - val_loss: 0.4924 - val_acc: 0.8704\n",
      "Epoch 731/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3403 - acc: 0.9398 - val_loss: 0.4906 - val_acc: 0.8704\n",
      "Epoch 732/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3388 - acc: 0.9398 - val_loss: 0.4889 - val_acc: 0.8704\n",
      "Epoch 733/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.3381 - acc: 0.9398 - val_loss: 0.4883 - val_acc: 0.8704\n",
      "Epoch 734/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.3375 - acc: 0.9398 - val_loss: 0.4876 - val_acc: 0.8704\n",
      "Epoch 735/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3371 - acc: 0.9398 - val_loss: 0.4869 - val_acc: 0.8704\n",
      "Epoch 736/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3357 - acc: 0.9398 - val_loss: 0.4854 - val_acc: 0.8704\n",
      "Epoch 737/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3342 - acc: 0.9398 - val_loss: 0.4855 - val_acc: 0.8704\n",
      "Epoch 738/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3340 - acc: 0.9398 - val_loss: 0.4844 - val_acc: 0.8704\n",
      "Epoch 739/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3332 - acc: 0.9398 - val_loss: 0.4831 - val_acc: 0.8704\n",
      "Epoch 740/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3318 - acc: 0.9444 - val_loss: 0.4825 - val_acc: 0.8704\n",
      "Epoch 741/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3313 - acc: 0.9398 - val_loss: 0.4821 - val_acc: 0.8704\n",
      "Epoch 742/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3300 - acc: 0.9398 - val_loss: 0.4814 - val_acc: 0.8704\n",
      "Epoch 743/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3293 - acc: 0.9352 - val_loss: 0.4815 - val_acc: 0.8704\n",
      "Epoch 744/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.3281 - acc: 0.9398 - val_loss: 0.4800 - val_acc: 0.8704\n",
      "Epoch 745/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3277 - acc: 0.9398 - val_loss: 0.4786 - val_acc: 0.8704\n",
      "Epoch 746/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3266 - acc: 0.9398 - val_loss: 0.4774 - val_acc: 0.8704\n",
      "Epoch 747/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3256 - acc: 0.9398 - val_loss: 0.4765 - val_acc: 0.8704\n",
      "Epoch 748/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3251 - acc: 0.9398 - val_loss: 0.4768 - val_acc: 0.8704\n",
      "Epoch 749/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3235 - acc: 0.9398 - val_loss: 0.4773 - val_acc: 0.8704\n",
      "Epoch 750/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3231 - acc: 0.9398 - val_loss: 0.4778 - val_acc: 0.8704\n",
      "Epoch 751/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.3224 - acc: 0.9398 - val_loss: 0.4772 - val_acc: 0.8704\n",
      "Epoch 752/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3212 - acc: 0.9398 - val_loss: 0.4766 - val_acc: 0.8704\n",
      "Epoch 753/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3205 - acc: 0.9444 - val_loss: 0.4751 - val_acc: 0.8704\n",
      "Epoch 754/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3196 - acc: 0.9444 - val_loss: 0.4743 - val_acc: 0.8704\n",
      "Epoch 755/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3187 - acc: 0.9398 - val_loss: 0.4731 - val_acc: 0.8704\n",
      "Epoch 756/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3178 - acc: 0.9444 - val_loss: 0.4711 - val_acc: 0.8704\n",
      "Epoch 757/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3170 - acc: 0.9444 - val_loss: 0.4705 - val_acc: 0.8704\n",
      "Epoch 758/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3162 - acc: 0.9444 - val_loss: 0.4707 - val_acc: 0.8704\n",
      "Epoch 759/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3151 - acc: 0.9398 - val_loss: 0.4697 - val_acc: 0.8704\n",
      "Epoch 760/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3145 - acc: 0.9444 - val_loss: 0.4686 - val_acc: 0.8704\n",
      "Epoch 761/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3135 - acc: 0.9398 - val_loss: 0.4687 - val_acc: 0.8704\n",
      "Epoch 762/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3125 - acc: 0.9444 - val_loss: 0.4690 - val_acc: 0.8704\n",
      "Epoch 763/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3121 - acc: 0.9444 - val_loss: 0.4675 - val_acc: 0.8704\n",
      "Epoch 764/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3108 - acc: 0.9444 - val_loss: 0.4668 - val_acc: 0.8704\n",
      "Epoch 765/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3103 - acc: 0.9444 - val_loss: 0.4672 - val_acc: 0.8704\n",
      "Epoch 766/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.3094 - acc: 0.9444 - val_loss: 0.4659 - val_acc: 0.8704\n",
      "Epoch 767/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.3085 - acc: 0.9444 - val_loss: 0.4644 - val_acc: 0.8704\n",
      "Epoch 768/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 97us/step - loss: 0.3075 - acc: 0.9444 - val_loss: 0.4639 - val_acc: 0.8704\n",
      "Epoch 769/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3069 - acc: 0.9444 - val_loss: 0.4630 - val_acc: 0.8704\n",
      "Epoch 770/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3058 - acc: 0.9444 - val_loss: 0.4616 - val_acc: 0.8704\n",
      "Epoch 771/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.3049 - acc: 0.9444 - val_loss: 0.4617 - val_acc: 0.8704\n",
      "Epoch 772/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3040 - acc: 0.9398 - val_loss: 0.4624 - val_acc: 0.8704\n",
      "Epoch 773/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.3031 - acc: 0.9444 - val_loss: 0.4617 - val_acc: 0.8704\n",
      "Epoch 774/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.3026 - acc: 0.9444 - val_loss: 0.4602 - val_acc: 0.8704\n",
      "Epoch 775/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.3017 - acc: 0.9444 - val_loss: 0.4611 - val_acc: 0.8704\n",
      "Epoch 776/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.3010 - acc: 0.9491 - val_loss: 0.4598 - val_acc: 0.8704\n",
      "Epoch 777/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.3000 - acc: 0.9444 - val_loss: 0.4600 - val_acc: 0.8704\n",
      "Epoch 778/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2991 - acc: 0.9444 - val_loss: 0.4585 - val_acc: 0.8704\n",
      "Epoch 779/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2981 - acc: 0.9444 - val_loss: 0.4574 - val_acc: 0.8704\n",
      "Epoch 780/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2973 - acc: 0.9444 - val_loss: 0.4568 - val_acc: 0.8704\n",
      "Epoch 781/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2970 - acc: 0.9444 - val_loss: 0.4563 - val_acc: 0.8704\n",
      "Epoch 782/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2962 - acc: 0.9444 - val_loss: 0.4554 - val_acc: 0.8704\n",
      "Epoch 783/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2954 - acc: 0.9491 - val_loss: 0.4553 - val_acc: 0.8704\n",
      "Epoch 784/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2941 - acc: 0.9491 - val_loss: 0.4538 - val_acc: 0.8704\n",
      "Epoch 785/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2932 - acc: 0.9491 - val_loss: 0.4543 - val_acc: 0.8704\n",
      "Epoch 786/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2928 - acc: 0.9491 - val_loss: 0.4540 - val_acc: 0.8704\n",
      "Epoch 787/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2919 - acc: 0.9444 - val_loss: 0.4527 - val_acc: 0.8704\n",
      "Epoch 788/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2914 - acc: 0.9491 - val_loss: 0.4519 - val_acc: 0.8889\n",
      "Epoch 789/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2905 - acc: 0.9491 - val_loss: 0.4515 - val_acc: 0.8704\n",
      "Epoch 790/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2894 - acc: 0.9491 - val_loss: 0.4517 - val_acc: 0.8704\n",
      "Epoch 791/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2890 - acc: 0.9491 - val_loss: 0.4507 - val_acc: 0.8704\n",
      "Epoch 792/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2882 - acc: 0.9491 - val_loss: 0.4509 - val_acc: 0.8704\n",
      "Epoch 793/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2868 - acc: 0.9537 - val_loss: 0.4509 - val_acc: 0.8704\n",
      "Epoch 794/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2867 - acc: 0.9491 - val_loss: 0.4496 - val_acc: 0.8704\n",
      "Epoch 795/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2858 - acc: 0.9491 - val_loss: 0.4488 - val_acc: 0.8889\n",
      "Epoch 796/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2851 - acc: 0.9444 - val_loss: 0.4474 - val_acc: 0.8889\n",
      "Epoch 797/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2838 - acc: 0.9491 - val_loss: 0.4473 - val_acc: 0.8889\n",
      "Epoch 798/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2827 - acc: 0.9491 - val_loss: 0.4461 - val_acc: 0.8889\n",
      "Epoch 799/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2826 - acc: 0.9583 - val_loss: 0.4449 - val_acc: 0.8889\n",
      "Epoch 800/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2817 - acc: 0.9491 - val_loss: 0.4444 - val_acc: 0.8889\n",
      "Epoch 801/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2807 - acc: 0.9491 - val_loss: 0.4444 - val_acc: 0.8889\n",
      "Epoch 802/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2802 - acc: 0.9537 - val_loss: 0.4442 - val_acc: 0.8889\n",
      "Epoch 803/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2793 - acc: 0.9583 - val_loss: 0.4430 - val_acc: 0.8889\n",
      "Epoch 804/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2788 - acc: 0.9537 - val_loss: 0.4434 - val_acc: 0.8889\n",
      "Epoch 805/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2776 - acc: 0.9537 - val_loss: 0.4431 - val_acc: 0.8889\n",
      "Epoch 806/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2769 - acc: 0.9537 - val_loss: 0.4426 - val_acc: 0.8889\n",
      "Epoch 807/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2759 - acc: 0.9537 - val_loss: 0.4427 - val_acc: 0.8889\n",
      "Epoch 808/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2755 - acc: 0.9630 - val_loss: 0.4425 - val_acc: 0.8889\n",
      "Epoch 809/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2747 - acc: 0.9583 - val_loss: 0.4413 - val_acc: 0.8889\n",
      "Epoch 810/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2745 - acc: 0.9537 - val_loss: 0.4403 - val_acc: 0.8889\n",
      "Epoch 811/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2732 - acc: 0.9583 - val_loss: 0.4389 - val_acc: 0.8889\n",
      "Epoch 812/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2726 - acc: 0.9583 - val_loss: 0.4398 - val_acc: 0.8889\n",
      "Epoch 813/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2719 - acc: 0.9537 - val_loss: 0.4382 - val_acc: 0.8889\n",
      "Epoch 814/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.2712 - acc: 0.9630 - val_loss: 0.4379 - val_acc: 0.8889\n",
      "Epoch 815/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2701 - acc: 0.9630 - val_loss: 0.4367 - val_acc: 0.8889\n",
      "Epoch 816/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2697 - acc: 0.9630 - val_loss: 0.4365 - val_acc: 0.8889\n",
      "Epoch 817/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2686 - acc: 0.9630 - val_loss: 0.4354 - val_acc: 0.8889\n",
      "Epoch 818/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2682 - acc: 0.9583 - val_loss: 0.4342 - val_acc: 0.8889\n",
      "Epoch 819/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2678 - acc: 0.9583 - val_loss: 0.4345 - val_acc: 0.8889\n",
      "Epoch 820/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2667 - acc: 0.9630 - val_loss: 0.4349 - val_acc: 0.8889\n",
      "Epoch 821/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2653 - acc: 0.9630 - val_loss: 0.4347 - val_acc: 0.8889\n",
      "Epoch 822/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2652 - acc: 0.9630 - val_loss: 0.4337 - val_acc: 0.8889\n",
      "Epoch 823/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2644 - acc: 0.9583 - val_loss: 0.4335 - val_acc: 0.8889\n",
      "Epoch 824/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2635 - acc: 0.9583 - val_loss: 0.4328 - val_acc: 0.8889\n",
      "Epoch 825/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2627 - acc: 0.9630 - val_loss: 0.4319 - val_acc: 0.8889\n",
      "Epoch 826/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2622 - acc: 0.9630 - val_loss: 0.4312 - val_acc: 0.8889\n",
      "Epoch 827/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2615 - acc: 0.9583 - val_loss: 0.4307 - val_acc: 0.9074\n",
      "Epoch 828/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2607 - acc: 0.9630 - val_loss: 0.4298 - val_acc: 0.9074\n",
      "Epoch 829/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2597 - acc: 0.9630 - val_loss: 0.4290 - val_acc: 0.9074\n",
      "Epoch 830/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2594 - acc: 0.9630 - val_loss: 0.4276 - val_acc: 0.9074\n",
      "Epoch 831/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2584 - acc: 0.9630 - val_loss: 0.4279 - val_acc: 0.9074\n",
      "Epoch 832/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2577 - acc: 0.9630 - val_loss: 0.4275 - val_acc: 0.9074\n",
      "Epoch 833/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2568 - acc: 0.9630 - val_loss: 0.4276 - val_acc: 0.9074\n",
      "Epoch 834/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2561 - acc: 0.9630 - val_loss: 0.4280 - val_acc: 0.9074\n",
      "Epoch 835/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2553 - acc: 0.9630 - val_loss: 0.4267 - val_acc: 0.9074\n",
      "Epoch 836/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2551 - acc: 0.9630 - val_loss: 0.4257 - val_acc: 0.9074\n",
      "Epoch 837/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2543 - acc: 0.9583 - val_loss: 0.4256 - val_acc: 0.9074\n",
      "Epoch 838/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2533 - acc: 0.9630 - val_loss: 0.4251 - val_acc: 0.9074\n",
      "Epoch 839/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2523 - acc: 0.9676 - val_loss: 0.4250 - val_acc: 0.9074\n",
      "Epoch 840/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2520 - acc: 0.9630 - val_loss: 0.4246 - val_acc: 0.9074\n",
      "Epoch 841/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2515 - acc: 0.9630 - val_loss: 0.4240 - val_acc: 0.9074\n",
      "Epoch 842/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2505 - acc: 0.9676 - val_loss: 0.4220 - val_acc: 0.9074\n",
      "Epoch 843/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2498 - acc: 0.9676 - val_loss: 0.4226 - val_acc: 0.9074\n",
      "Epoch 844/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2489 - acc: 0.9676 - val_loss: 0.4216 - val_acc: 0.9074\n",
      "Epoch 845/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2487 - acc: 0.9630 - val_loss: 0.4202 - val_acc: 0.9074\n",
      "Epoch 846/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2476 - acc: 0.9676 - val_loss: 0.4198 - val_acc: 0.9074\n",
      "Epoch 847/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2477 - acc: 0.9676 - val_loss: 0.4195 - val_acc: 0.9074\n",
      "Epoch 848/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2462 - acc: 0.9676 - val_loss: 0.4199 - val_acc: 0.9259\n",
      "Epoch 849/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2456 - acc: 0.9676 - val_loss: 0.4199 - val_acc: 0.9074\n",
      "Epoch 850/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2449 - acc: 0.9676 - val_loss: 0.4195 - val_acc: 0.9074\n",
      "Epoch 851/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2445 - acc: 0.9676 - val_loss: 0.4182 - val_acc: 0.9074\n",
      "Epoch 852/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2438 - acc: 0.9676 - val_loss: 0.4171 - val_acc: 0.9074\n",
      "Epoch 853/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2432 - acc: 0.9676 - val_loss: 0.4170 - val_acc: 0.9074\n",
      "Epoch 854/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2421 - acc: 0.9676 - val_loss: 0.4175 - val_acc: 0.9074\n",
      "Epoch 855/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2416 - acc: 0.9676 - val_loss: 0.4177 - val_acc: 0.9259\n",
      "Epoch 856/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2407 - acc: 0.9676 - val_loss: 0.4176 - val_acc: 0.9259\n",
      "Epoch 857/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.2403 - acc: 0.9676 - val_loss: 0.4167 - val_acc: 0.9259\n",
      "Epoch 858/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2396 - acc: 0.9676 - val_loss: 0.4150 - val_acc: 0.9074\n",
      "Epoch 859/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2390 - acc: 0.9676 - val_loss: 0.4148 - val_acc: 0.9074\n",
      "Epoch 860/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2384 - acc: 0.9676 - val_loss: 0.4154 - val_acc: 0.9259\n",
      "Epoch 861/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2379 - acc: 0.9676 - val_loss: 0.4141 - val_acc: 0.9259\n",
      "Epoch 862/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2364 - acc: 0.9676 - val_loss: 0.4133 - val_acc: 0.9259\n",
      "Epoch 863/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2367 - acc: 0.9676 - val_loss: 0.4121 - val_acc: 0.9259\n",
      "Epoch 864/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2354 - acc: 0.9676 - val_loss: 0.4120 - val_acc: 0.9259\n",
      "Epoch 865/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2346 - acc: 0.9676 - val_loss: 0.4116 - val_acc: 0.9259\n",
      "Epoch 866/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2343 - acc: 0.9676 - val_loss: 0.4121 - val_acc: 0.9259\n",
      "Epoch 867/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2336 - acc: 0.9676 - val_loss: 0.4117 - val_acc: 0.9259\n",
      "Epoch 868/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.2330 - acc: 0.9676 - val_loss: 0.4116 - val_acc: 0.9259\n",
      "Epoch 869/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2320 - acc: 0.9676 - val_loss: 0.4105 - val_acc: 0.9259\n",
      "Epoch 870/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2314 - acc: 0.9676 - val_loss: 0.4103 - val_acc: 0.9259\n",
      "Epoch 871/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2309 - acc: 0.9676 - val_loss: 0.4104 - val_acc: 0.9259\n",
      "Epoch 872/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2301 - acc: 0.9676 - val_loss: 0.4090 - val_acc: 0.9259\n",
      "Epoch 873/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2293 - acc: 0.9676 - val_loss: 0.4086 - val_acc: 0.9259\n",
      "Epoch 874/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2291 - acc: 0.9676 - val_loss: 0.4083 - val_acc: 0.9259\n",
      "Epoch 875/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2282 - acc: 0.9676 - val_loss: 0.4087 - val_acc: 0.9259\n",
      "Epoch 876/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2276 - acc: 0.9676 - val_loss: 0.4087 - val_acc: 0.9259\n",
      "Epoch 877/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2269 - acc: 0.9676 - val_loss: 0.4087 - val_acc: 0.9259\n",
      "Epoch 878/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2264 - acc: 0.9676 - val_loss: 0.4090 - val_acc: 0.9259\n",
      "Epoch 879/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2253 - acc: 0.9676 - val_loss: 0.4091 - val_acc: 0.9259\n",
      "Epoch 880/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2249 - acc: 0.9676 - val_loss: 0.4090 - val_acc: 0.9259\n",
      "Epoch 881/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2243 - acc: 0.9676 - val_loss: 0.4082 - val_acc: 0.9259\n",
      "Epoch 882/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2237 - acc: 0.9676 - val_loss: 0.4076 - val_acc: 0.9259\n",
      "Epoch 883/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2232 - acc: 0.9676 - val_loss: 0.4059 - val_acc: 0.9259\n",
      "Epoch 884/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2223 - acc: 0.9676 - val_loss: 0.4058 - val_acc: 0.9259\n",
      "Epoch 885/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2219 - acc: 0.9676 - val_loss: 0.4041 - val_acc: 0.9259\n",
      "Epoch 886/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 97us/step - loss: 0.2211 - acc: 0.9676 - val_loss: 0.4042 - val_acc: 0.9259\n",
      "Epoch 887/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2204 - acc: 0.9676 - val_loss: 0.4027 - val_acc: 0.9259\n",
      "Epoch 888/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2201 - acc: 0.9676 - val_loss: 0.4026 - val_acc: 0.9259\n",
      "Epoch 889/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2190 - acc: 0.9676 - val_loss: 0.4027 - val_acc: 0.9259\n",
      "Epoch 890/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2187 - acc: 0.9676 - val_loss: 0.4030 - val_acc: 0.9259\n",
      "Epoch 891/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2184 - acc: 0.9676 - val_loss: 0.4014 - val_acc: 0.9259\n",
      "Epoch 892/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2172 - acc: 0.9676 - val_loss: 0.4015 - val_acc: 0.9259\n",
      "Epoch 893/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.2166 - acc: 0.9676 - val_loss: 0.4005 - val_acc: 0.9259\n",
      "Epoch 894/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2164 - acc: 0.9676 - val_loss: 0.4019 - val_acc: 0.9074\n",
      "Epoch 895/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2154 - acc: 0.9676 - val_loss: 0.4005 - val_acc: 0.9074\n",
      "Epoch 896/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2150 - acc: 0.9676 - val_loss: 0.3989 - val_acc: 0.9074\n",
      "Epoch 897/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2144 - acc: 0.9676 - val_loss: 0.4001 - val_acc: 0.9074\n",
      "Epoch 898/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.2135 - acc: 0.9676 - val_loss: 0.4008 - val_acc: 0.9074\n",
      "Epoch 899/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2127 - acc: 0.9676 - val_loss: 0.3993 - val_acc: 0.9074\n",
      "Epoch 900/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2125 - acc: 0.9676 - val_loss: 0.3989 - val_acc: 0.9074\n",
      "Epoch 901/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2117 - acc: 0.9676 - val_loss: 0.3998 - val_acc: 0.9074\n",
      "Epoch 902/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2113 - acc: 0.9676 - val_loss: 0.3987 - val_acc: 0.9074\n",
      "Epoch 903/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2102 - acc: 0.9676 - val_loss: 0.3967 - val_acc: 0.9074\n",
      "Epoch 904/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2098 - acc: 0.9676 - val_loss: 0.3957 - val_acc: 0.9074\n",
      "Epoch 905/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2095 - acc: 0.9676 - val_loss: 0.3938 - val_acc: 0.9074\n",
      "Epoch 906/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.2092 - acc: 0.9676 - val_loss: 0.3939 - val_acc: 0.9074\n",
      "Epoch 907/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2083 - acc: 0.9676 - val_loss: 0.3936 - val_acc: 0.9074\n",
      "Epoch 908/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2079 - acc: 0.9676 - val_loss: 0.3938 - val_acc: 0.9074\n",
      "Epoch 909/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2066 - acc: 0.9676 - val_loss: 0.3937 - val_acc: 0.9074\n",
      "Epoch 910/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2063 - acc: 0.9676 - val_loss: 0.3941 - val_acc: 0.9074\n",
      "Epoch 911/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.2057 - acc: 0.9676 - val_loss: 0.3939 - val_acc: 0.9074\n",
      "Epoch 912/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2051 - acc: 0.9676 - val_loss: 0.3943 - val_acc: 0.9074\n",
      "Epoch 913/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.2047 - acc: 0.9676 - val_loss: 0.3929 - val_acc: 0.9074\n",
      "Epoch 914/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.2039 - acc: 0.9676 - val_loss: 0.3939 - val_acc: 0.9074\n",
      "Epoch 915/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.2035 - acc: 0.9676 - val_loss: 0.3927 - val_acc: 0.9074\n",
      "Epoch 916/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2026 - acc: 0.9676 - val_loss: 0.3908 - val_acc: 0.9074\n",
      "Epoch 917/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2026 - acc: 0.9676 - val_loss: 0.3922 - val_acc: 0.9074\n",
      "Epoch 918/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.2013 - acc: 0.9676 - val_loss: 0.3922 - val_acc: 0.9074\n",
      "Epoch 919/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2012 - acc: 0.9676 - val_loss: 0.3898 - val_acc: 0.9074\n",
      "Epoch 920/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.2006 - acc: 0.9676 - val_loss: 0.3920 - val_acc: 0.9074\n",
      "Epoch 921/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1999 - acc: 0.9676 - val_loss: 0.3923 - val_acc: 0.9074\n",
      "Epoch 922/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1996 - acc: 0.9676 - val_loss: 0.3912 - val_acc: 0.9074\n",
      "Epoch 923/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1989 - acc: 0.9676 - val_loss: 0.3912 - val_acc: 0.9074\n",
      "Epoch 924/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1981 - acc: 0.9676 - val_loss: 0.3903 - val_acc: 0.9074\n",
      "Epoch 925/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1977 - acc: 0.9676 - val_loss: 0.3891 - val_acc: 0.9074\n",
      "Epoch 926/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1977 - acc: 0.9676 - val_loss: 0.3878 - val_acc: 0.9074\n",
      "Epoch 927/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1965 - acc: 0.9676 - val_loss: 0.3877 - val_acc: 0.9074\n",
      "Epoch 928/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1955 - acc: 0.9676 - val_loss: 0.3872 - val_acc: 0.9074\n",
      "Epoch 929/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1955 - acc: 0.9676 - val_loss: 0.3871 - val_acc: 0.9074\n",
      "Epoch 930/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1949 - acc: 0.9676 - val_loss: 0.3876 - val_acc: 0.9074\n",
      "Epoch 931/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1944 - acc: 0.9676 - val_loss: 0.3884 - val_acc: 0.9074\n",
      "Epoch 932/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1942 - acc: 0.9676 - val_loss: 0.3881 - val_acc: 0.9074\n",
      "Epoch 933/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1933 - acc: 0.9676 - val_loss: 0.3882 - val_acc: 0.9074\n",
      "Epoch 934/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1923 - acc: 0.9676 - val_loss: 0.3889 - val_acc: 0.9074\n",
      "Epoch 935/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1923 - acc: 0.9676 - val_loss: 0.3887 - val_acc: 0.9074\n",
      "Epoch 936/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1915 - acc: 0.9676 - val_loss: 0.3877 - val_acc: 0.9074\n",
      "Epoch 937/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1910 - acc: 0.9676 - val_loss: 0.3880 - val_acc: 0.9074\n",
      "Epoch 938/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1907 - acc: 0.9676 - val_loss: 0.3875 - val_acc: 0.9074\n",
      "Epoch 939/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1899 - acc: 0.9676 - val_loss: 0.3859 - val_acc: 0.9074\n",
      "Epoch 940/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1890 - acc: 0.9676 - val_loss: 0.3858 - val_acc: 0.9074\n",
      "Epoch 941/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1892 - acc: 0.9676 - val_loss: 0.3841 - val_acc: 0.9074\n",
      "Epoch 942/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1883 - acc: 0.9676 - val_loss: 0.3859 - val_acc: 0.9074\n",
      "Epoch 943/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1881 - acc: 0.9676 - val_loss: 0.3870 - val_acc: 0.9074\n",
      "Epoch 944/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.1870 - acc: 0.9676 - val_loss: 0.3870 - val_acc: 0.9074\n",
      "Epoch 945/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1864 - acc: 0.9676 - val_loss: 0.3843 - val_acc: 0.9074\n",
      "Epoch 946/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1862 - acc: 0.9676 - val_loss: 0.3850 - val_acc: 0.9074\n",
      "Epoch 947/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1856 - acc: 0.9676 - val_loss: 0.3853 - val_acc: 0.9074\n",
      "Epoch 948/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1857 - acc: 0.9676 - val_loss: 0.3853 - val_acc: 0.9074\n",
      "Epoch 949/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1841 - acc: 0.9676 - val_loss: 0.3853 - val_acc: 0.9074\n",
      "Epoch 950/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1846 - acc: 0.9676 - val_loss: 0.3846 - val_acc: 0.9074\n",
      "Epoch 951/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1833 - acc: 0.9676 - val_loss: 0.3848 - val_acc: 0.9074\n",
      "Epoch 952/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1829 - acc: 0.9676 - val_loss: 0.3843 - val_acc: 0.9074\n",
      "Epoch 953/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1825 - acc: 0.9722 - val_loss: 0.3840 - val_acc: 0.9074\n",
      "Epoch 954/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1819 - acc: 0.9676 - val_loss: 0.3836 - val_acc: 0.9074\n",
      "Epoch 955/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1815 - acc: 0.9676 - val_loss: 0.3840 - val_acc: 0.9074\n",
      "Epoch 956/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1809 - acc: 0.9676 - val_loss: 0.3824 - val_acc: 0.9074\n",
      "Epoch 957/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1806 - acc: 0.9676 - val_loss: 0.3821 - val_acc: 0.9074\n",
      "Epoch 958/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1798 - acc: 0.9676 - val_loss: 0.3820 - val_acc: 0.9074\n",
      "Epoch 959/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1793 - acc: 0.9676 - val_loss: 0.3822 - val_acc: 0.9074\n",
      "Epoch 960/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1793 - acc: 0.9676 - val_loss: 0.3819 - val_acc: 0.9074\n",
      "Epoch 961/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1784 - acc: 0.9676 - val_loss: 0.3803 - val_acc: 0.9074\n",
      "Epoch 962/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1783 - acc: 0.9676 - val_loss: 0.3798 - val_acc: 0.9074\n",
      "Epoch 963/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1774 - acc: 0.9676 - val_loss: 0.3796 - val_acc: 0.9074\n",
      "Epoch 964/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.1769 - acc: 0.9676 - val_loss: 0.3800 - val_acc: 0.9074\n",
      "Epoch 965/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1767 - acc: 0.9676 - val_loss: 0.3809 - val_acc: 0.9074\n",
      "Epoch 966/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1761 - acc: 0.9676 - val_loss: 0.3807 - val_acc: 0.9074\n",
      "Epoch 967/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1753 - acc: 0.9676 - val_loss: 0.3807 - val_acc: 0.9074\n",
      "Epoch 968/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1750 - acc: 0.9676 - val_loss: 0.3823 - val_acc: 0.9074\n",
      "Epoch 969/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1744 - acc: 0.9676 - val_loss: 0.3811 - val_acc: 0.9074\n",
      "Epoch 970/10000\n",
      "216/216 [==============================] - ETA: 0s - loss: 0.1534 - acc: 0.950 - 0s 93us/step - loss: 0.1737 - acc: 0.9676 - val_loss: 0.3809 - val_acc: 0.9074\n",
      "Epoch 971/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1734 - acc: 0.9676 - val_loss: 0.3805 - val_acc: 0.9074\n",
      "Epoch 972/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1731 - acc: 0.9676 - val_loss: 0.3795 - val_acc: 0.9074\n",
      "Epoch 973/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1724 - acc: 0.9676 - val_loss: 0.3795 - val_acc: 0.9074\n",
      "Epoch 974/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1720 - acc: 0.9676 - val_loss: 0.3769 - val_acc: 0.9074\n",
      "Epoch 975/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1719 - acc: 0.9676 - val_loss: 0.3773 - val_acc: 0.9074\n",
      "Epoch 976/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1709 - acc: 0.9676 - val_loss: 0.3775 - val_acc: 0.9074\n",
      "Epoch 977/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1705 - acc: 0.9676 - val_loss: 0.3778 - val_acc: 0.9074\n",
      "Epoch 978/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1697 - acc: 0.9676 - val_loss: 0.3752 - val_acc: 0.9259\n",
      "Epoch 979/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1693 - acc: 0.9676 - val_loss: 0.3759 - val_acc: 0.9259\n",
      "Epoch 980/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1696 - acc: 0.9676 - val_loss: 0.3782 - val_acc: 0.9074\n",
      "Epoch 981/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1685 - acc: 0.9676 - val_loss: 0.3773 - val_acc: 0.9074\n",
      "Epoch 982/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1681 - acc: 0.9676 - val_loss: 0.3766 - val_acc: 0.9074\n",
      "Epoch 983/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1679 - acc: 0.9676 - val_loss: 0.3772 - val_acc: 0.9074\n",
      "Epoch 984/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1673 - acc: 0.9676 - val_loss: 0.3785 - val_acc: 0.9074\n",
      "Epoch 985/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1672 - acc: 0.9676 - val_loss: 0.3792 - val_acc: 0.9074\n",
      "Epoch 986/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1661 - acc: 0.9676 - val_loss: 0.3773 - val_acc: 0.9074\n",
      "Epoch 987/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1659 - acc: 0.9676 - val_loss: 0.3764 - val_acc: 0.9074\n",
      "Epoch 988/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1653 - acc: 0.9676 - val_loss: 0.3764 - val_acc: 0.9074\n",
      "Epoch 989/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.1650 - acc: 0.9676 - val_loss: 0.3749 - val_acc: 0.9074\n",
      "Epoch 990/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1642 - acc: 0.9676 - val_loss: 0.3738 - val_acc: 0.9259\n",
      "Epoch 991/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1645 - acc: 0.9676 - val_loss: 0.3751 - val_acc: 0.9074\n",
      "Epoch 992/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1634 - acc: 0.9676 - val_loss: 0.3740 - val_acc: 0.9259\n",
      "Epoch 993/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1631 - acc: 0.9676 - val_loss: 0.3755 - val_acc: 0.9074\n",
      "Epoch 994/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1623 - acc: 0.9676 - val_loss: 0.3769 - val_acc: 0.9074\n",
      "Epoch 995/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1621 - acc: 0.9676 - val_loss: 0.3774 - val_acc: 0.9074\n",
      "Epoch 996/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1615 - acc: 0.9676 - val_loss: 0.3768 - val_acc: 0.9074\n",
      "Epoch 997/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1612 - acc: 0.9676 - val_loss: 0.3758 - val_acc: 0.9259\n",
      "Epoch 998/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1610 - acc: 0.9676 - val_loss: 0.3768 - val_acc: 0.9074\n",
      "Epoch 999/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1604 - acc: 0.9676 - val_loss: 0.3767 - val_acc: 0.9074\n",
      "Epoch 1000/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.1599 - acc: 0.9676 - val_loss: 0.3757 - val_acc: 0.9259\n",
      "Epoch 1001/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.1595 - acc: 0.9676 - val_loss: 0.3755 - val_acc: 0.9259\n",
      "Epoch 1002/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.1587 - acc: 0.9676 - val_loss: 0.3737 - val_acc: 0.9259\n",
      "Epoch 1003/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.1585 - acc: 0.9676 - val_loss: 0.3743 - val_acc: 0.9259\n",
      "Epoch 1004/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 130us/step - loss: 0.1579 - acc: 0.9676 - val_loss: 0.3745 - val_acc: 0.9259\n",
      "Epoch 1005/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.1575 - acc: 0.9676 - val_loss: 0.3742 - val_acc: 0.9259\n",
      "Epoch 1006/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.1575 - acc: 0.9676 - val_loss: 0.3753 - val_acc: 0.9259\n",
      "Epoch 1007/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.1568 - acc: 0.9676 - val_loss: 0.3749 - val_acc: 0.9259\n",
      "Epoch 1008/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.1561 - acc: 0.9676 - val_loss: 0.3756 - val_acc: 0.9259\n",
      "Epoch 1009/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1561 - acc: 0.9676 - val_loss: 0.3761 - val_acc: 0.9259\n",
      "Epoch 1010/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1557 - acc: 0.9676 - val_loss: 0.3746 - val_acc: 0.9259\n",
      "Epoch 1011/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.1549 - acc: 0.9676 - val_loss: 0.3731 - val_acc: 0.9259\n",
      "Epoch 1012/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.1547 - acc: 0.9676 - val_loss: 0.3729 - val_acc: 0.9259\n",
      "Epoch 1013/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.1539 - acc: 0.9676 - val_loss: 0.3738 - val_acc: 0.9259\n",
      "Epoch 1014/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1536 - acc: 0.9676 - val_loss: 0.3757 - val_acc: 0.9259\n",
      "Epoch 1015/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1532 - acc: 0.9676 - val_loss: 0.3752 - val_acc: 0.9259\n",
      "Epoch 1016/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1528 - acc: 0.9676 - val_loss: 0.3742 - val_acc: 0.9259\n",
      "Epoch 1017/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1526 - acc: 0.9676 - val_loss: 0.3747 - val_acc: 0.9259\n",
      "Epoch 1018/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.1521 - acc: 0.9676 - val_loss: 0.3746 - val_acc: 0.9259\n",
      "Epoch 1019/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1517 - acc: 0.9676 - val_loss: 0.3750 - val_acc: 0.9259\n",
      "Epoch 1020/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1512 - acc: 0.9676 - val_loss: 0.3742 - val_acc: 0.9259\n",
      "Epoch 1021/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.1511 - acc: 0.9676 - val_loss: 0.3750 - val_acc: 0.9259\n",
      "Epoch 1022/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1503 - acc: 0.9676 - val_loss: 0.3753 - val_acc: 0.9259\n",
      "Epoch 1023/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.1496 - acc: 0.9676 - val_loss: 0.3736 - val_acc: 0.9259\n",
      "Epoch 1024/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.1495 - acc: 0.9676 - val_loss: 0.3749 - val_acc: 0.9259\n",
      "Epoch 1025/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.1492 - acc: 0.9676 - val_loss: 0.3739 - val_acc: 0.9259\n",
      "Epoch 1026/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1491 - acc: 0.9676 - val_loss: 0.3740 - val_acc: 0.9259\n",
      "Epoch 1027/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1482 - acc: 0.9676 - val_loss: 0.3739 - val_acc: 0.9259\n",
      "Epoch 1028/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.1479 - acc: 0.9676 - val_loss: 0.3748 - val_acc: 0.9259\n",
      "Epoch 1029/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1471 - acc: 0.9676 - val_loss: 0.3765 - val_acc: 0.9259\n",
      "Epoch 1030/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1469 - acc: 0.9676 - val_loss: 0.3759 - val_acc: 0.9259\n",
      "Epoch 1031/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.1467 - acc: 0.9722 - val_loss: 0.3725 - val_acc: 0.9259\n",
      "Epoch 1032/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1461 - acc: 0.9722 - val_loss: 0.3727 - val_acc: 0.9259\n",
      "Epoch 1033/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1456 - acc: 0.9676 - val_loss: 0.3744 - val_acc: 0.9259\n",
      "Epoch 1034/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1457 - acc: 0.9676 - val_loss: 0.3744 - val_acc: 0.9259\n",
      "Epoch 1035/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1449 - acc: 0.9676 - val_loss: 0.3741 - val_acc: 0.9259\n",
      "Epoch 1036/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1447 - acc: 0.9676 - val_loss: 0.3738 - val_acc: 0.9259\n",
      "Epoch 1037/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1440 - acc: 0.9676 - val_loss: 0.3739 - val_acc: 0.9259\n",
      "Epoch 1038/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1440 - acc: 0.9676 - val_loss: 0.3748 - val_acc: 0.9259\n",
      "Epoch 1039/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1433 - acc: 0.9676 - val_loss: 0.3749 - val_acc: 0.9259\n",
      "Epoch 1040/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.1433 - acc: 0.9676 - val_loss: 0.3736 - val_acc: 0.9259\n",
      "Epoch 1041/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1427 - acc: 0.9676 - val_loss: 0.3730 - val_acc: 0.9259\n",
      "Epoch 1042/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1421 - acc: 0.9676 - val_loss: 0.3737 - val_acc: 0.9259\n",
      "Epoch 1043/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1421 - acc: 0.9676 - val_loss: 0.3736 - val_acc: 0.9259\n",
      "Epoch 1044/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1412 - acc: 0.9676 - val_loss: 0.3734 - val_acc: 0.9259\n",
      "Epoch 1045/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1408 - acc: 0.9722 - val_loss: 0.3718 - val_acc: 0.9259\n",
      "Epoch 1046/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1408 - acc: 0.9676 - val_loss: 0.3734 - val_acc: 0.9259\n",
      "Epoch 1047/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1405 - acc: 0.9722 - val_loss: 0.3734 - val_acc: 0.9259\n",
      "Epoch 1048/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1402 - acc: 0.9676 - val_loss: 0.3737 - val_acc: 0.9259\n",
      "Epoch 1049/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1397 - acc: 0.9676 - val_loss: 0.3743 - val_acc: 0.9259\n",
      "Epoch 1050/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.1388 - acc: 0.9676 - val_loss: 0.3749 - val_acc: 0.9259\n",
      "Epoch 1051/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1386 - acc: 0.9676 - val_loss: 0.3764 - val_acc: 0.9259\n",
      "Epoch 1052/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1385 - acc: 0.9676 - val_loss: 0.3748 - val_acc: 0.9259\n",
      "Epoch 1053/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1379 - acc: 0.9676 - val_loss: 0.3747 - val_acc: 0.9259\n",
      "Epoch 1054/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1376 - acc: 0.9722 - val_loss: 0.3732 - val_acc: 0.9259\n",
      "Epoch 1055/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1375 - acc: 0.9676 - val_loss: 0.3733 - val_acc: 0.9259\n",
      "Epoch 1056/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1370 - acc: 0.9722 - val_loss: 0.3728 - val_acc: 0.9259\n",
      "Epoch 1057/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1364 - acc: 0.9676 - val_loss: 0.3736 - val_acc: 0.9259\n",
      "Epoch 1058/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1361 - acc: 0.9722 - val_loss: 0.3725 - val_acc: 0.9259\n",
      "Epoch 1059/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1359 - acc: 0.9676 - val_loss: 0.3717 - val_acc: 0.9259\n",
      "Epoch 1060/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1357 - acc: 0.9676 - val_loss: 0.3735 - val_acc: 0.9259\n",
      "Epoch 1061/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1350 - acc: 0.9722 - val_loss: 0.3749 - val_acc: 0.9259\n",
      "Epoch 1062/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1345 - acc: 0.9676 - val_loss: 0.3752 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1063/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1343 - acc: 0.9676 - val_loss: 0.3753 - val_acc: 0.9259\n",
      "Epoch 1064/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1339 - acc: 0.9676 - val_loss: 0.3755 - val_acc: 0.9259\n",
      "Epoch 1065/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1339 - acc: 0.9676 - val_loss: 0.3756 - val_acc: 0.9074\n",
      "Epoch 1066/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1333 - acc: 0.9676 - val_loss: 0.3749 - val_acc: 0.9074\n",
      "Epoch 1067/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1330 - acc: 0.9676 - val_loss: 0.3737 - val_acc: 0.9074\n",
      "Epoch 1068/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1322 - acc: 0.9676 - val_loss: 0.3730 - val_acc: 0.9259\n",
      "Epoch 1069/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1327 - acc: 0.9722 - val_loss: 0.3740 - val_acc: 0.9259\n",
      "Epoch 1070/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1319 - acc: 0.9676 - val_loss: 0.3738 - val_acc: 0.9259\n",
      "Epoch 1071/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1314 - acc: 0.9676 - val_loss: 0.3727 - val_acc: 0.9259\n",
      "Epoch 1072/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1310 - acc: 0.9722 - val_loss: 0.3752 - val_acc: 0.9259\n",
      "Epoch 1073/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1305 - acc: 0.9676 - val_loss: 0.3738 - val_acc: 0.9074\n",
      "Epoch 1074/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1305 - acc: 0.9676 - val_loss: 0.3733 - val_acc: 0.9074\n",
      "Epoch 1075/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1298 - acc: 0.9722 - val_loss: 0.3745 - val_acc: 0.9074\n",
      "Epoch 1076/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1297 - acc: 0.9676 - val_loss: 0.3748 - val_acc: 0.9259\n",
      "Epoch 1077/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1297 - acc: 0.9676 - val_loss: 0.3732 - val_acc: 0.9259\n",
      "Epoch 1078/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1290 - acc: 0.9722 - val_loss: 0.3737 - val_acc: 0.9074\n",
      "Epoch 1079/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.1286 - acc: 0.9676 - val_loss: 0.3738 - val_acc: 0.9074\n",
      "Epoch 1080/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1283 - acc: 0.9722 - val_loss: 0.3735 - val_acc: 0.9074\n",
      "Epoch 1081/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1278 - acc: 0.9722 - val_loss: 0.3736 - val_acc: 0.9074\n",
      "Epoch 1082/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1276 - acc: 0.9722 - val_loss: 0.3728 - val_acc: 0.9259\n",
      "Epoch 1083/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1271 - acc: 0.9676 - val_loss: 0.3734 - val_acc: 0.9259\n",
      "Epoch 1084/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1268 - acc: 0.9722 - val_loss: 0.3714 - val_acc: 0.9259\n",
      "Epoch 1085/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1263 - acc: 0.9722 - val_loss: 0.3717 - val_acc: 0.9074\n",
      "Epoch 1086/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1261 - acc: 0.9722 - val_loss: 0.3730 - val_acc: 0.9074\n",
      "Epoch 1087/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1258 - acc: 0.9722 - val_loss: 0.3737 - val_acc: 0.9074\n",
      "Epoch 1088/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1254 - acc: 0.9722 - val_loss: 0.3733 - val_acc: 0.9074\n",
      "Epoch 1089/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.1252 - acc: 0.9722 - val_loss: 0.3746 - val_acc: 0.9074\n",
      "Epoch 1090/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.1246 - acc: 0.9722 - val_loss: 0.3755 - val_acc: 0.9074\n",
      "Epoch 1091/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1244 - acc: 0.9722 - val_loss: 0.3754 - val_acc: 0.9074\n",
      "Epoch 1092/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1238 - acc: 0.9722 - val_loss: 0.3762 - val_acc: 0.9074\n",
      "Epoch 1093/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1236 - acc: 0.9722 - val_loss: 0.3767 - val_acc: 0.9074\n",
      "Epoch 1094/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1231 - acc: 0.9722 - val_loss: 0.3778 - val_acc: 0.9074\n",
      "Epoch 1095/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1232 - acc: 0.9676 - val_loss: 0.3774 - val_acc: 0.9074\n",
      "Epoch 1096/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1229 - acc: 0.9722 - val_loss: 0.3770 - val_acc: 0.9074\n",
      "Epoch 1097/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1223 - acc: 0.9722 - val_loss: 0.3777 - val_acc: 0.9074\n",
      "Epoch 1098/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1222 - acc: 0.9676 - val_loss: 0.3767 - val_acc: 0.9074\n",
      "Epoch 1099/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1216 - acc: 0.9722 - val_loss: 0.3768 - val_acc: 0.9074\n",
      "Epoch 1100/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1216 - acc: 0.9722 - val_loss: 0.3756 - val_acc: 0.9074\n",
      "Epoch 1101/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1210 - acc: 0.9722 - val_loss: 0.3766 - val_acc: 0.9074\n",
      "Epoch 1102/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1206 - acc: 0.9722 - val_loss: 0.3761 - val_acc: 0.9074\n",
      "Epoch 1103/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1203 - acc: 0.9722 - val_loss: 0.3764 - val_acc: 0.9074\n",
      "Epoch 1104/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1201 - acc: 0.9722 - val_loss: 0.3781 - val_acc: 0.9074\n",
      "Epoch 1105/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1197 - acc: 0.9722 - val_loss: 0.3778 - val_acc: 0.9074\n",
      "Epoch 1106/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1193 - acc: 0.9722 - val_loss: 0.3779 - val_acc: 0.9074\n",
      "Epoch 1107/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1192 - acc: 0.9769 - val_loss: 0.3769 - val_acc: 0.9074\n",
      "Epoch 1108/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.1188 - acc: 0.9722 - val_loss: 0.3755 - val_acc: 0.9074\n",
      "Epoch 1109/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1182 - acc: 0.9722 - val_loss: 0.3778 - val_acc: 0.9074\n",
      "Epoch 1110/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.1183 - acc: 0.9676 - val_loss: 0.3775 - val_acc: 0.9074\n",
      "Epoch 1111/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1177 - acc: 0.9722 - val_loss: 0.3767 - val_acc: 0.9074\n",
      "Epoch 1112/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1176 - acc: 0.9722 - val_loss: 0.3777 - val_acc: 0.9074\n",
      "Epoch 1113/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1171 - acc: 0.9722 - val_loss: 0.3762 - val_acc: 0.9074\n",
      "Epoch 1114/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1171 - acc: 0.9722 - val_loss: 0.3769 - val_acc: 0.9074\n",
      "Epoch 1115/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1167 - acc: 0.9722 - val_loss: 0.3778 - val_acc: 0.9074\n",
      "Epoch 1116/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1161 - acc: 0.9722 - val_loss: 0.3776 - val_acc: 0.9074\n",
      "Epoch 1117/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1158 - acc: 0.9722 - val_loss: 0.3785 - val_acc: 0.8889\n",
      "Epoch 1118/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1154 - acc: 0.9769 - val_loss: 0.3765 - val_acc: 0.9074\n",
      "Epoch 1119/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1150 - acc: 0.9722 - val_loss: 0.3778 - val_acc: 0.8889\n",
      "Epoch 1120/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1149 - acc: 0.9769 - val_loss: 0.3789 - val_acc: 0.8889\n",
      "Epoch 1121/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1145 - acc: 0.9769 - val_loss: 0.3794 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1122/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1144 - acc: 0.9722 - val_loss: 0.3777 - val_acc: 0.8889\n",
      "Epoch 1123/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1139 - acc: 0.9769 - val_loss: 0.3785 - val_acc: 0.8889\n",
      "Epoch 1124/10000\n",
      "216/216 [==============================] - ETA: 0s - loss: 0.1310 - acc: 0.950 - 0s 93us/step - loss: 0.1137 - acc: 0.9722 - val_loss: 0.3793 - val_acc: 0.8889\n",
      "Epoch 1125/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1133 - acc: 0.9722 - val_loss: 0.3796 - val_acc: 0.8889\n",
      "Epoch 1126/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1129 - acc: 0.9722 - val_loss: 0.3795 - val_acc: 0.8889\n",
      "Epoch 1127/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.1129 - acc: 0.9722 - val_loss: 0.3802 - val_acc: 0.8889\n",
      "Epoch 1128/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1123 - acc: 0.9722 - val_loss: 0.3807 - val_acc: 0.8889\n",
      "Epoch 1129/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1119 - acc: 0.9815 - val_loss: 0.3797 - val_acc: 0.8889\n",
      "Epoch 1130/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1117 - acc: 0.9769 - val_loss: 0.3782 - val_acc: 0.8889\n",
      "Epoch 1131/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1116 - acc: 0.9722 - val_loss: 0.3786 - val_acc: 0.8889\n",
      "Epoch 1132/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.1111 - acc: 0.9769 - val_loss: 0.3806 - val_acc: 0.8889\n",
      "Epoch 1133/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1109 - acc: 0.9769 - val_loss: 0.3792 - val_acc: 0.8889\n",
      "Epoch 1134/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1104 - acc: 0.9722 - val_loss: 0.3799 - val_acc: 0.8889\n",
      "Epoch 1135/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1100 - acc: 0.9769 - val_loss: 0.3795 - val_acc: 0.8889\n",
      "Epoch 1136/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.1103 - acc: 0.9722 - val_loss: 0.3801 - val_acc: 0.8889\n",
      "Epoch 1137/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1099 - acc: 0.9722 - val_loss: 0.3802 - val_acc: 0.8889\n",
      "Epoch 1138/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1093 - acc: 0.9722 - val_loss: 0.3803 - val_acc: 0.8889\n",
      "Epoch 1139/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1093 - acc: 0.9722 - val_loss: 0.3789 - val_acc: 0.8889\n",
      "Epoch 1140/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1088 - acc: 0.9722 - val_loss: 0.3798 - val_acc: 0.8889\n",
      "Epoch 1141/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1082 - acc: 0.9722 - val_loss: 0.3820 - val_acc: 0.8889\n",
      "Epoch 1142/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1082 - acc: 0.9769 - val_loss: 0.3810 - val_acc: 0.8889\n",
      "Epoch 1143/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1079 - acc: 0.9769 - val_loss: 0.3812 - val_acc: 0.8889\n",
      "Epoch 1144/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1074 - acc: 0.9722 - val_loss: 0.3820 - val_acc: 0.8889\n",
      "Epoch 1145/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.1073 - acc: 0.9815 - val_loss: 0.3828 - val_acc: 0.8889\n",
      "Epoch 1146/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1069 - acc: 0.9769 - val_loss: 0.3829 - val_acc: 0.8889\n",
      "Epoch 1147/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1069 - acc: 0.9769 - val_loss: 0.3826 - val_acc: 0.8889\n",
      "Epoch 1148/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.1061 - acc: 0.9769 - val_loss: 0.3809 - val_acc: 0.8889\n",
      "Epoch 1149/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1062 - acc: 0.9722 - val_loss: 0.3832 - val_acc: 0.8889\n",
      "Epoch 1150/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1058 - acc: 0.9722 - val_loss: 0.3830 - val_acc: 0.8889\n",
      "Epoch 1151/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1051 - acc: 0.9815 - val_loss: 0.3833 - val_acc: 0.8889\n",
      "Epoch 1152/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1057 - acc: 0.9722 - val_loss: 0.3831 - val_acc: 0.8889\n",
      "Epoch 1153/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1049 - acc: 0.9769 - val_loss: 0.3849 - val_acc: 0.8889\n",
      "Epoch 1154/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1046 - acc: 0.9769 - val_loss: 0.3853 - val_acc: 0.8889\n",
      "Epoch 1155/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1040 - acc: 0.9815 - val_loss: 0.3817 - val_acc: 0.8889\n",
      "Epoch 1156/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1045 - acc: 0.9722 - val_loss: 0.3848 - val_acc: 0.8889\n",
      "Epoch 1157/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1037 - acc: 0.9815 - val_loss: 0.3843 - val_acc: 0.8889\n",
      "Epoch 1158/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1032 - acc: 0.9769 - val_loss: 0.3839 - val_acc: 0.8889\n",
      "Epoch 1159/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1035 - acc: 0.9815 - val_loss: 0.3833 - val_acc: 0.8889\n",
      "Epoch 1160/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1030 - acc: 0.9722 - val_loss: 0.3849 - val_acc: 0.8889\n",
      "Epoch 1161/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1026 - acc: 0.9815 - val_loss: 0.3836 - val_acc: 0.8889\n",
      "Epoch 1162/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1026 - acc: 0.9815 - val_loss: 0.3827 - val_acc: 0.8889\n",
      "Epoch 1163/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.1020 - acc: 0.9815 - val_loss: 0.3830 - val_acc: 0.8889\n",
      "Epoch 1164/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.1020 - acc: 0.9722 - val_loss: 0.3854 - val_acc: 0.8889\n",
      "Epoch 1165/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.1017 - acc: 0.9815 - val_loss: 0.3827 - val_acc: 0.8889\n",
      "Epoch 1166/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1012 - acc: 0.9815 - val_loss: 0.3821 - val_acc: 0.8889\n",
      "Epoch 1167/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.1009 - acc: 0.9769 - val_loss: 0.3843 - val_acc: 0.8889\n",
      "Epoch 1168/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.1005 - acc: 0.9815 - val_loss: 0.3860 - val_acc: 0.8889\n",
      "Epoch 1169/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.1006 - acc: 0.9815 - val_loss: 0.3853 - val_acc: 0.8889\n",
      "Epoch 1170/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.1005 - acc: 0.9769 - val_loss: 0.3845 - val_acc: 0.8889\n",
      "Epoch 1171/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0996 - acc: 0.9815 - val_loss: 0.3844 - val_acc: 0.8889\n",
      "Epoch 1172/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0997 - acc: 0.9769 - val_loss: 0.3867 - val_acc: 0.8889\n",
      "Epoch 1173/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0996 - acc: 0.9769 - val_loss: 0.3870 - val_acc: 0.8889\n",
      "Epoch 1174/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0990 - acc: 0.9815 - val_loss: 0.3854 - val_acc: 0.8889\n",
      "Epoch 1175/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0987 - acc: 0.9815 - val_loss: 0.3857 - val_acc: 0.8889\n",
      "Epoch 1176/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0985 - acc: 0.9815 - val_loss: 0.3839 - val_acc: 0.8889\n",
      "Epoch 1177/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0984 - acc: 0.9769 - val_loss: 0.3859 - val_acc: 0.8889\n",
      "Epoch 1178/10000\n",
      "216/216 [==============================] - 0s 194us/step - loss: 0.0979 - acc: 0.9815 - val_loss: 0.3860 - val_acc: 0.8889\n",
      "Epoch 1179/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0979 - acc: 0.9769 - val_loss: 0.3886 - val_acc: 0.8889\n",
      "Epoch 1180/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0976 - acc: 0.9815 - val_loss: 0.3888 - val_acc: 0.8889\n",
      "Epoch 1181/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0972 - acc: 0.9769 - val_loss: 0.3894 - val_acc: 0.8889\n",
      "Epoch 1182/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0968 - acc: 0.9815 - val_loss: 0.3906 - val_acc: 0.8889\n",
      "Epoch 1183/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0964 - acc: 0.9815 - val_loss: 0.3924 - val_acc: 0.8889\n",
      "Epoch 1184/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0962 - acc: 0.9815 - val_loss: 0.3893 - val_acc: 0.8889\n",
      "Epoch 1185/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0961 - acc: 0.9769 - val_loss: 0.3896 - val_acc: 0.8889\n",
      "Epoch 1186/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0958 - acc: 0.9815 - val_loss: 0.3884 - val_acc: 0.8889\n",
      "Epoch 1187/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0959 - acc: 0.9815 - val_loss: 0.3884 - val_acc: 0.8889\n",
      "Epoch 1188/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0952 - acc: 0.9815 - val_loss: 0.3890 - val_acc: 0.8889\n",
      "Epoch 1189/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0951 - acc: 0.9815 - val_loss: 0.3908 - val_acc: 0.8889\n",
      "Epoch 1190/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0950 - acc: 0.9815 - val_loss: 0.3913 - val_acc: 0.8889\n",
      "Epoch 1191/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0947 - acc: 0.9815 - val_loss: 0.3906 - val_acc: 0.8889\n",
      "Epoch 1192/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0946 - acc: 0.9769 - val_loss: 0.3903 - val_acc: 0.8889\n",
      "Epoch 1193/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0940 - acc: 0.9815 - val_loss: 0.3894 - val_acc: 0.8889\n",
      "Epoch 1194/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0937 - acc: 0.9815 - val_loss: 0.3893 - val_acc: 0.8889\n",
      "Epoch 1195/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0938 - acc: 0.9815 - val_loss: 0.3898 - val_acc: 0.8889\n",
      "Epoch 1196/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0933 - acc: 0.9769 - val_loss: 0.3891 - val_acc: 0.8889\n",
      "Epoch 1197/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0929 - acc: 0.9815 - val_loss: 0.3915 - val_acc: 0.8889\n",
      "Epoch 1198/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0929 - acc: 0.9815 - val_loss: 0.3905 - val_acc: 0.8889\n",
      "Epoch 1199/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0927 - acc: 0.9815 - val_loss: 0.3902 - val_acc: 0.8889\n",
      "Epoch 1200/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0923 - acc: 0.9815 - val_loss: 0.3910 - val_acc: 0.8889\n",
      "Epoch 1201/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0919 - acc: 0.9815 - val_loss: 0.3945 - val_acc: 0.8889\n",
      "Epoch 1202/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0918 - acc: 0.9815 - val_loss: 0.3933 - val_acc: 0.8889\n",
      "Epoch 1203/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0918 - acc: 0.9769 - val_loss: 0.3930 - val_acc: 0.8889\n",
      "Epoch 1204/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0913 - acc: 0.9815 - val_loss: 0.3952 - val_acc: 0.8889\n",
      "Epoch 1205/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0907 - acc: 0.9815 - val_loss: 0.3963 - val_acc: 0.8889\n",
      "Epoch 1206/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0908 - acc: 0.9815 - val_loss: 0.3954 - val_acc: 0.8889\n",
      "Epoch 1207/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0903 - acc: 0.9815 - val_loss: 0.3926 - val_acc: 0.8889\n",
      "Epoch 1208/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0904 - acc: 0.9769 - val_loss: 0.3929 - val_acc: 0.8889\n",
      "Epoch 1209/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0901 - acc: 0.9769 - val_loss: 0.3938 - val_acc: 0.8889\n",
      "Epoch 1210/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0894 - acc: 0.9815 - val_loss: 0.3952 - val_acc: 0.8889\n",
      "Epoch 1211/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0897 - acc: 0.9815 - val_loss: 0.3962 - val_acc: 0.8889\n",
      "Epoch 1212/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0892 - acc: 0.9815 - val_loss: 0.3974 - val_acc: 0.8889\n",
      "Epoch 1213/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0892 - acc: 0.9815 - val_loss: 0.3973 - val_acc: 0.8889\n",
      "Epoch 1214/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0888 - acc: 0.9815 - val_loss: 0.3966 - val_acc: 0.8889\n",
      "Epoch 1215/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0884 - acc: 0.9815 - val_loss: 0.3963 - val_acc: 0.8889\n",
      "Epoch 1216/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0883 - acc: 0.9815 - val_loss: 0.3969 - val_acc: 0.8889\n",
      "Epoch 1217/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0883 - acc: 0.9815 - val_loss: 0.3997 - val_acc: 0.8889\n",
      "Epoch 1218/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0878 - acc: 0.9815 - val_loss: 0.3972 - val_acc: 0.8889\n",
      "Epoch 1219/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0876 - acc: 0.9815 - val_loss: 0.3974 - val_acc: 0.8889\n",
      "Epoch 1220/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0872 - acc: 0.9815 - val_loss: 0.3961 - val_acc: 0.8889\n",
      "Epoch 1221/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0872 - acc: 0.9815 - val_loss: 0.3972 - val_acc: 0.8889\n",
      "Epoch 1222/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0869 - acc: 0.9815 - val_loss: 0.3973 - val_acc: 0.8889\n",
      "Epoch 1223/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0868 - acc: 0.9815 - val_loss: 0.3969 - val_acc: 0.8889\n",
      "Epoch 1224/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0863 - acc: 0.9815 - val_loss: 0.3992 - val_acc: 0.8889\n",
      "Epoch 1225/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0862 - acc: 0.9815 - val_loss: 0.3979 - val_acc: 0.8889\n",
      "Epoch 1226/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0862 - acc: 0.9815 - val_loss: 0.3998 - val_acc: 0.8889\n",
      "Epoch 1227/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0856 - acc: 0.9815 - val_loss: 0.4013 - val_acc: 0.8889\n",
      "Epoch 1228/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0855 - acc: 0.9815 - val_loss: 0.4029 - val_acc: 0.8889\n",
      "Epoch 1229/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0850 - acc: 0.9815 - val_loss: 0.4013 - val_acc: 0.8889\n",
      "Epoch 1230/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0850 - acc: 0.9815 - val_loss: 0.4017 - val_acc: 0.8889\n",
      "Epoch 1231/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0845 - acc: 0.9815 - val_loss: 0.4004 - val_acc: 0.8889\n",
      "Epoch 1232/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0848 - acc: 0.9815 - val_loss: 0.4020 - val_acc: 0.8889\n",
      "Epoch 1233/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0842 - acc: 0.9815 - val_loss: 0.4039 - val_acc: 0.8889\n",
      "Epoch 1234/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0842 - acc: 0.9815 - val_loss: 0.4017 - val_acc: 0.8889\n",
      "Epoch 1235/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0838 - acc: 0.9815 - val_loss: 0.4026 - val_acc: 0.8889\n",
      "Epoch 1236/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0833 - acc: 0.9815 - val_loss: 0.4027 - val_acc: 0.8889\n",
      "Epoch 1237/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0831 - acc: 0.9815 - val_loss: 0.4028 - val_acc: 0.8889\n",
      "Epoch 1238/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0833 - acc: 0.9815 - val_loss: 0.4051 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1239/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0831 - acc: 0.9815 - val_loss: 0.4061 - val_acc: 0.8889\n",
      "Epoch 1240/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0829 - acc: 0.9815 - val_loss: 0.4047 - val_acc: 0.8889\n",
      "Epoch 1241/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0823 - acc: 0.9815 - val_loss: 0.4028 - val_acc: 0.8889\n",
      "Epoch 1242/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0822 - acc: 0.9815 - val_loss: 0.4009 - val_acc: 0.8889\n",
      "Epoch 1243/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0820 - acc: 0.9815 - val_loss: 0.4020 - val_acc: 0.8889\n",
      "Epoch 1244/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0817 - acc: 0.9861 - val_loss: 0.4024 - val_acc: 0.8889\n",
      "Epoch 1245/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0815 - acc: 0.9815 - val_loss: 0.4031 - val_acc: 0.8889\n",
      "Epoch 1246/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0815 - acc: 0.9815 - val_loss: 0.4048 - val_acc: 0.8889\n",
      "Epoch 1247/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0814 - acc: 0.9815 - val_loss: 0.4061 - val_acc: 0.8889\n",
      "Epoch 1248/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0811 - acc: 0.9815 - val_loss: 0.4041 - val_acc: 0.8889\n",
      "Epoch 1249/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0801 - acc: 0.9861 - val_loss: 0.4020 - val_acc: 0.8889\n",
      "Epoch 1250/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0807 - acc: 0.9815 - val_loss: 0.4035 - val_acc: 0.8889\n",
      "Epoch 1251/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0802 - acc: 0.9815 - val_loss: 0.4043 - val_acc: 0.8889\n",
      "Epoch 1252/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0802 - acc: 0.9815 - val_loss: 0.4050 - val_acc: 0.8889\n",
      "Epoch 1253/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0798 - acc: 0.9815 - val_loss: 0.4061 - val_acc: 0.8889\n",
      "Epoch 1254/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0796 - acc: 0.9815 - val_loss: 0.4070 - val_acc: 0.8889\n",
      "Epoch 1255/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0791 - acc: 0.9861 - val_loss: 0.4082 - val_acc: 0.8889\n",
      "Epoch 1256/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0793 - acc: 0.9861 - val_loss: 0.4106 - val_acc: 0.8889\n",
      "Epoch 1257/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0791 - acc: 0.9815 - val_loss: 0.4066 - val_acc: 0.8889\n",
      "Epoch 1258/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0790 - acc: 0.9815 - val_loss: 0.4069 - val_acc: 0.8889\n",
      "Epoch 1259/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0785 - acc: 0.9815 - val_loss: 0.4065 - val_acc: 0.8889\n",
      "Epoch 1260/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0785 - acc: 0.9815 - val_loss: 0.4080 - val_acc: 0.8889\n",
      "Epoch 1261/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0782 - acc: 0.9861 - val_loss: 0.4095 - val_acc: 0.8889\n",
      "Epoch 1262/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0775 - acc: 0.9861 - val_loss: 0.4097 - val_acc: 0.8889\n",
      "Epoch 1263/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0775 - acc: 0.9815 - val_loss: 0.4097 - val_acc: 0.8889\n",
      "Epoch 1264/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0774 - acc: 0.9815 - val_loss: 0.4063 - val_acc: 0.8889\n",
      "Epoch 1265/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0771 - acc: 0.9861 - val_loss: 0.4058 - val_acc: 0.8889\n",
      "Epoch 1266/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0770 - acc: 0.9861 - val_loss: 0.4095 - val_acc: 0.8889\n",
      "Epoch 1267/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0769 - acc: 0.9861 - val_loss: 0.4098 - val_acc: 0.8889\n",
      "Epoch 1268/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0766 - acc: 0.9861 - val_loss: 0.4103 - val_acc: 0.8889\n",
      "Epoch 1269/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0764 - acc: 0.9815 - val_loss: 0.4088 - val_acc: 0.8889\n",
      "Epoch 1270/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0760 - acc: 0.9907 - val_loss: 0.4115 - val_acc: 0.8889\n",
      "Epoch 1271/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0761 - acc: 0.9861 - val_loss: 0.4126 - val_acc: 0.8889\n",
      "Epoch 1272/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0760 - acc: 0.9861 - val_loss: 0.4134 - val_acc: 0.8889\n",
      "Epoch 1273/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0756 - acc: 0.9861 - val_loss: 0.4126 - val_acc: 0.8889\n",
      "Epoch 1274/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0751 - acc: 0.9907 - val_loss: 0.4125 - val_acc: 0.8889\n",
      "Epoch 1275/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0750 - acc: 0.9907 - val_loss: 0.4112 - val_acc: 0.8889\n",
      "Epoch 1276/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0750 - acc: 0.9861 - val_loss: 0.4133 - val_acc: 0.8889\n",
      "Epoch 1277/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0747 - acc: 0.9861 - val_loss: 0.4129 - val_acc: 0.8889\n",
      "Epoch 1278/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0744 - acc: 0.9861 - val_loss: 0.4129 - val_acc: 0.8889\n",
      "Epoch 1279/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0741 - acc: 0.9907 - val_loss: 0.4159 - val_acc: 0.8889\n",
      "Epoch 1280/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0742 - acc: 0.9815 - val_loss: 0.4123 - val_acc: 0.8889\n",
      "Epoch 1281/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0737 - acc: 0.9861 - val_loss: 0.4111 - val_acc: 0.8889\n",
      "Epoch 1282/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0736 - acc: 0.9907 - val_loss: 0.4123 - val_acc: 0.8889\n",
      "Epoch 1283/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0735 - acc: 0.9907 - val_loss: 0.4141 - val_acc: 0.8889\n",
      "Epoch 1284/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0731 - acc: 0.9907 - val_loss: 0.4134 - val_acc: 0.8889\n",
      "Epoch 1285/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0729 - acc: 0.9907 - val_loss: 0.4153 - val_acc: 0.8889\n",
      "Epoch 1286/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0725 - acc: 0.9907 - val_loss: 0.4133 - val_acc: 0.8889\n",
      "Epoch 1287/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0727 - acc: 0.9907 - val_loss: 0.4153 - val_acc: 0.9074\n",
      "Epoch 1288/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0724 - acc: 0.9907 - val_loss: 0.4167 - val_acc: 0.8889\n",
      "Epoch 1289/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0720 - acc: 0.9907 - val_loss: 0.4214 - val_acc: 0.9074\n",
      "Epoch 1290/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0716 - acc: 0.9907 - val_loss: 0.4196 - val_acc: 0.8889\n",
      "Epoch 1291/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0717 - acc: 0.9861 - val_loss: 0.4214 - val_acc: 0.8889\n",
      "Epoch 1292/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0716 - acc: 0.9861 - val_loss: 0.4202 - val_acc: 0.8889\n",
      "Epoch 1293/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0709 - acc: 0.9907 - val_loss: 0.4199 - val_acc: 0.8889\n",
      "Epoch 1294/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0713 - acc: 0.9907 - val_loss: 0.4205 - val_acc: 0.9074\n",
      "Epoch 1295/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0706 - acc: 0.9907 - val_loss: 0.4200 - val_acc: 0.9074\n",
      "Epoch 1296/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0703 - acc: 0.9907 - val_loss: 0.4208 - val_acc: 0.9074\n",
      "Epoch 1297/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0705 - acc: 0.9907 - val_loss: 0.4192 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1298/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0703 - acc: 0.9907 - val_loss: 0.4184 - val_acc: 0.9074\n",
      "Epoch 1299/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0699 - acc: 0.9907 - val_loss: 0.4234 - val_acc: 0.9074\n",
      "Epoch 1300/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0695 - acc: 0.9907 - val_loss: 0.4220 - val_acc: 0.9074\n",
      "Epoch 1301/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0695 - acc: 0.9907 - val_loss: 0.4187 - val_acc: 0.9074\n",
      "Epoch 1302/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0692 - acc: 0.9907 - val_loss: 0.4182 - val_acc: 0.9074\n",
      "Epoch 1303/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0691 - acc: 0.9907 - val_loss: 0.4184 - val_acc: 0.9074\n",
      "Epoch 1304/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0691 - acc: 0.9907 - val_loss: 0.4199 - val_acc: 0.9074\n",
      "Epoch 1305/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0687 - acc: 0.9907 - val_loss: 0.4228 - val_acc: 0.9074\n",
      "Epoch 1306/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0683 - acc: 0.9907 - val_loss: 0.4195 - val_acc: 0.9074\n",
      "Epoch 1307/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0682 - acc: 0.9907 - val_loss: 0.4223 - val_acc: 0.9074\n",
      "Epoch 1308/10000\n",
      "216/216 [==============================] - ETA: 0s - loss: 0.0435 - acc: 1.000 - 0s 93us/step - loss: 0.0679 - acc: 0.9907 - val_loss: 0.4218 - val_acc: 0.9074\n",
      "Epoch 1309/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0678 - acc: 0.9907 - val_loss: 0.4243 - val_acc: 0.9074\n",
      "Epoch 1310/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0675 - acc: 0.9907 - val_loss: 0.4227 - val_acc: 0.9074\n",
      "Epoch 1311/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0676 - acc: 0.9907 - val_loss: 0.4229 - val_acc: 0.9074\n",
      "Epoch 1312/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0671 - acc: 0.9907 - val_loss: 0.4209 - val_acc: 0.9074\n",
      "Epoch 1313/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0668 - acc: 0.9907 - val_loss: 0.4226 - val_acc: 0.9074\n",
      "Epoch 1314/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0667 - acc: 0.9907 - val_loss: 0.4232 - val_acc: 0.9074\n",
      "Epoch 1315/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0666 - acc: 0.9907 - val_loss: 0.4237 - val_acc: 0.9074\n",
      "Epoch 1316/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0663 - acc: 0.9907 - val_loss: 0.4222 - val_acc: 0.9074\n",
      "Epoch 1317/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0659 - acc: 0.9907 - val_loss: 0.4233 - val_acc: 0.9074\n",
      "Epoch 1318/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0656 - acc: 0.9907 - val_loss: 0.4250 - val_acc: 0.9074\n",
      "Epoch 1319/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0657 - acc: 0.9907 - val_loss: 0.4234 - val_acc: 0.9074\n",
      "Epoch 1320/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0653 - acc: 0.9907 - val_loss: 0.4231 - val_acc: 0.9074\n",
      "Epoch 1321/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0652 - acc: 0.9907 - val_loss: 0.4261 - val_acc: 0.9074\n",
      "Epoch 1322/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0650 - acc: 0.9907 - val_loss: 0.4281 - val_acc: 0.9074\n",
      "Epoch 1323/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0647 - acc: 0.9907 - val_loss: 0.4271 - val_acc: 0.9074\n",
      "Epoch 1324/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0645 - acc: 0.9907 - val_loss: 0.4283 - val_acc: 0.9074\n",
      "Epoch 1325/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0642 - acc: 0.9907 - val_loss: 0.4278 - val_acc: 0.9074\n",
      "Epoch 1326/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0640 - acc: 0.9907 - val_loss: 0.4265 - val_acc: 0.9074\n",
      "Epoch 1327/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0636 - acc: 0.9907 - val_loss: 0.4279 - val_acc: 0.9074\n",
      "Epoch 1328/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0636 - acc: 0.9907 - val_loss: 0.4270 - val_acc: 0.9074\n",
      "Epoch 1329/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0631 - acc: 0.9907 - val_loss: 0.4277 - val_acc: 0.9074\n",
      "Epoch 1330/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0629 - acc: 0.9907 - val_loss: 0.4301 - val_acc: 0.9074\n",
      "Epoch 1331/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0630 - acc: 0.9907 - val_loss: 0.4298 - val_acc: 0.9074\n",
      "Epoch 1332/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0628 - acc: 0.9907 - val_loss: 0.4303 - val_acc: 0.9074\n",
      "Epoch 1333/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0623 - acc: 0.9907 - val_loss: 0.4307 - val_acc: 0.9074\n",
      "Epoch 1334/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0621 - acc: 0.9907 - val_loss: 0.4308 - val_acc: 0.9074\n",
      "Epoch 1335/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0618 - acc: 0.9907 - val_loss: 0.4297 - val_acc: 0.9074\n",
      "Epoch 1336/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0618 - acc: 0.9907 - val_loss: 0.4329 - val_acc: 0.9074\n",
      "Epoch 1337/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0614 - acc: 0.9907 - val_loss: 0.4332 - val_acc: 0.9074\n",
      "Epoch 1338/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.0612 - acc: 0.9907 - val_loss: 0.4341 - val_acc: 0.9074\n",
      "Epoch 1339/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0612 - acc: 0.9907 - val_loss: 0.4334 - val_acc: 0.9074\n",
      "Epoch 1340/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0608 - acc: 0.9907 - val_loss: 0.4341 - val_acc: 0.9074\n",
      "Epoch 1341/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0606 - acc: 0.9907 - val_loss: 0.4349 - val_acc: 0.9074\n",
      "Epoch 1342/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0604 - acc: 0.9907 - val_loss: 0.4361 - val_acc: 0.9074\n",
      "Epoch 1343/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0600 - acc: 0.9907 - val_loss: 0.4357 - val_acc: 0.9074\n",
      "Epoch 1344/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0599 - acc: 0.9907 - val_loss: 0.4361 - val_acc: 0.9074\n",
      "Epoch 1345/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0598 - acc: 0.9907 - val_loss: 0.4369 - val_acc: 0.9074\n",
      "Epoch 1346/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.0594 - acc: 0.9907 - val_loss: 0.4362 - val_acc: 0.9074\n",
      "Epoch 1347/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.0592 - acc: 0.9907 - val_loss: 0.4356 - val_acc: 0.9074\n",
      "Epoch 1348/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.0589 - acc: 0.9907 - val_loss: 0.4356 - val_acc: 0.9074\n",
      "Epoch 1349/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0590 - acc: 0.9907 - val_loss: 0.4358 - val_acc: 0.9074\n",
      "Epoch 1350/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0587 - acc: 0.9907 - val_loss: 0.4388 - val_acc: 0.9074\n",
      "Epoch 1351/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0582 - acc: 0.9907 - val_loss: 0.4387 - val_acc: 0.9074\n",
      "Epoch 1352/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.0581 - acc: 0.9907 - val_loss: 0.4384 - val_acc: 0.9074\n",
      "Epoch 1353/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0580 - acc: 0.9907 - val_loss: 0.4376 - val_acc: 0.9074\n",
      "Epoch 1354/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0578 - acc: 0.9907 - val_loss: 0.4395 - val_acc: 0.9074\n",
      "Epoch 1355/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0573 - acc: 0.9907 - val_loss: 0.4411 - val_acc: 0.9074\n",
      "Epoch 1356/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0570 - acc: 0.9907 - val_loss: 0.4437 - val_acc: 0.9074\n",
      "Epoch 1357/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0571 - acc: 0.9907 - val_loss: 0.4447 - val_acc: 0.9074\n",
      "Epoch 1358/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0570 - acc: 0.9907 - val_loss: 0.4442 - val_acc: 0.9074\n",
      "Epoch 1359/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0568 - acc: 0.9907 - val_loss: 0.4428 - val_acc: 0.9074\n",
      "Epoch 1360/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0565 - acc: 0.9907 - val_loss: 0.4419 - val_acc: 0.9074\n",
      "Epoch 1361/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0559 - acc: 0.9907 - val_loss: 0.4431 - val_acc: 0.9074\n",
      "Epoch 1362/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0563 - acc: 0.9907 - val_loss: 0.4445 - val_acc: 0.9074\n",
      "Epoch 1363/10000\n",
      "216/216 [==============================] - 0s 180us/step - loss: 0.0557 - acc: 0.9907 - val_loss: 0.4439 - val_acc: 0.9074\n",
      "Epoch 1364/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0556 - acc: 0.9907 - val_loss: 0.4485 - val_acc: 0.9074\n",
      "Epoch 1365/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0554 - acc: 0.9907 - val_loss: 0.4459 - val_acc: 0.9074\n",
      "Epoch 1366/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0555 - acc: 0.9907 - val_loss: 0.4448 - val_acc: 0.9074\n",
      "Epoch 1367/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0549 - acc: 0.9907 - val_loss: 0.4446 - val_acc: 0.9074\n",
      "Epoch 1368/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0549 - acc: 0.9907 - val_loss: 0.4450 - val_acc: 0.9074\n",
      "Epoch 1369/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0547 - acc: 0.9954 - val_loss: 0.4449 - val_acc: 0.9074\n",
      "Epoch 1370/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0543 - acc: 0.9907 - val_loss: 0.4476 - val_acc: 0.9074\n",
      "Epoch 1371/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0542 - acc: 0.9907 - val_loss: 0.4457 - val_acc: 0.9074\n",
      "Epoch 1372/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0539 - acc: 0.9954 - val_loss: 0.4437 - val_acc: 0.9074\n",
      "Epoch 1373/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0540 - acc: 0.9907 - val_loss: 0.4462 - val_acc: 0.9074\n",
      "Epoch 1374/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0535 - acc: 0.9954 - val_loss: 0.4482 - val_acc: 0.9074\n",
      "Epoch 1375/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0535 - acc: 0.9907 - val_loss: 0.4492 - val_acc: 0.9074\n",
      "Epoch 1376/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0532 - acc: 0.9954 - val_loss: 0.4495 - val_acc: 0.9074\n",
      "Epoch 1377/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0528 - acc: 0.9954 - val_loss: 0.4491 - val_acc: 0.9074\n",
      "Epoch 1378/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0531 - acc: 0.9954 - val_loss: 0.4502 - val_acc: 0.9074\n",
      "Epoch 1379/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0526 - acc: 0.9954 - val_loss: 0.4509 - val_acc: 0.9074\n",
      "Epoch 1380/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0523 - acc: 0.9954 - val_loss: 0.4514 - val_acc: 0.9074\n",
      "Epoch 1381/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0524 - acc: 0.9954 - val_loss: 0.4539 - val_acc: 0.9074\n",
      "Epoch 1382/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0520 - acc: 0.9954 - val_loss: 0.4546 - val_acc: 0.9074\n",
      "Epoch 1383/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0518 - acc: 0.9954 - val_loss: 0.4534 - val_acc: 0.9074\n",
      "Epoch 1384/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0517 - acc: 0.9954 - val_loss: 0.4583 - val_acc: 0.9074\n",
      "Epoch 1385/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0516 - acc: 0.9954 - val_loss: 0.4570 - val_acc: 0.9074\n",
      "Epoch 1386/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0514 - acc: 0.9954 - val_loss: 0.4550 - val_acc: 0.9074\n",
      "Epoch 1387/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0511 - acc: 0.9954 - val_loss: 0.4569 - val_acc: 0.9074\n",
      "Epoch 1388/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0508 - acc: 0.9954 - val_loss: 0.4570 - val_acc: 0.9074\n",
      "Epoch 1389/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0508 - acc: 0.9954 - val_loss: 0.4554 - val_acc: 0.9074\n",
      "Epoch 1390/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0505 - acc: 0.9954 - val_loss: 0.4585 - val_acc: 0.9074\n",
      "Epoch 1391/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0506 - acc: 0.9954 - val_loss: 0.4581 - val_acc: 0.9074\n",
      "Epoch 1392/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0502 - acc: 0.9954 - val_loss: 0.4611 - val_acc: 0.9074\n",
      "Epoch 1393/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0498 - acc: 0.9954 - val_loss: 0.4605 - val_acc: 0.9074\n",
      "Epoch 1394/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0497 - acc: 0.9954 - val_loss: 0.4602 - val_acc: 0.9074\n",
      "Epoch 1395/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0498 - acc: 0.9954 - val_loss: 0.4584 - val_acc: 0.9074\n",
      "Epoch 1396/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0495 - acc: 1.0000 - val_loss: 0.4632 - val_acc: 0.9074\n",
      "Epoch 1397/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0491 - acc: 0.9954 - val_loss: 0.4602 - val_acc: 0.9074\n",
      "Epoch 1398/10000\n",
      "216/216 [==============================] - 0s 79us/step - loss: 0.0493 - acc: 0.9954 - val_loss: 0.4621 - val_acc: 0.9074\n",
      "Epoch 1399/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0490 - acc: 0.9954 - val_loss: 0.4643 - val_acc: 0.9074\n",
      "Epoch 1400/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0487 - acc: 0.9954 - val_loss: 0.4614 - val_acc: 0.9074\n",
      "Epoch 1401/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0487 - acc: 1.0000 - val_loss: 0.4631 - val_acc: 0.9074\n",
      "Epoch 1402/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0485 - acc: 1.0000 - val_loss: 0.4635 - val_acc: 0.9074\n",
      "Epoch 1403/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0482 - acc: 0.9954 - val_loss: 0.4628 - val_acc: 0.9074\n",
      "Epoch 1404/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0482 - acc: 0.9954 - val_loss: 0.4623 - val_acc: 0.9074\n",
      "Epoch 1405/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.4634 - val_acc: 0.9074\n",
      "Epoch 1406/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.4632 - val_acc: 0.9074\n",
      "Epoch 1407/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0475 - acc: 1.0000 - val_loss: 0.4655 - val_acc: 0.9074\n",
      "Epoch 1408/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.4693 - val_acc: 0.9074\n",
      "Epoch 1409/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0471 - acc: 0.9954 - val_loss: 0.4669 - val_acc: 0.9074\n",
      "Epoch 1410/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0471 - acc: 1.0000 - val_loss: 0.4676 - val_acc: 0.9074\n",
      "Epoch 1411/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0470 - acc: 0.9954 - val_loss: 0.4637 - val_acc: 0.9074\n",
      "Epoch 1412/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.4663 - val_acc: 0.9074\n",
      "Epoch 1413/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0465 - acc: 1.0000 - val_loss: 0.4672 - val_acc: 0.9074\n",
      "Epoch 1414/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0465 - acc: 1.0000 - val_loss: 0.4656 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1415/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0464 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.9074\n",
      "Epoch 1416/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.4689 - val_acc: 0.9074\n",
      "Epoch 1417/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.4703 - val_acc: 0.9074\n",
      "Epoch 1418/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0459 - acc: 1.0000 - val_loss: 0.4708 - val_acc: 0.9074\n",
      "Epoch 1419/10000\n",
      "216/216 [==============================] - 0s 79us/step - loss: 0.0457 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.9074\n",
      "Epoch 1420/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0456 - acc: 1.0000 - val_loss: 0.4689 - val_acc: 0.9074\n",
      "Epoch 1421/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.4700 - val_acc: 0.9074\n",
      "Epoch 1422/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0451 - acc: 1.0000 - val_loss: 0.4687 - val_acc: 0.9074\n",
      "Epoch 1423/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0452 - acc: 1.0000 - val_loss: 0.4710 - val_acc: 0.9074\n",
      "Epoch 1424/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0448 - acc: 1.0000 - val_loss: 0.4724 - val_acc: 0.9074\n",
      "Epoch 1425/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0448 - acc: 1.0000 - val_loss: 0.4735 - val_acc: 0.9074\n",
      "Epoch 1426/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0447 - acc: 1.0000 - val_loss: 0.4754 - val_acc: 0.9074\n",
      "Epoch 1427/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0442 - acc: 1.0000 - val_loss: 0.4745 - val_acc: 0.9074\n",
      "Epoch 1428/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0444 - acc: 1.0000 - val_loss: 0.4766 - val_acc: 0.9074\n",
      "Epoch 1429/10000\n",
      "216/216 [==============================] - 0s 236us/step - loss: 0.0441 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.9074\n",
      "Epoch 1430/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.9074\n",
      "Epoch 1431/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.9074\n",
      "Epoch 1432/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0437 - acc: 1.0000 - val_loss: 0.4747 - val_acc: 0.9074\n",
      "Epoch 1433/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.9074\n",
      "Epoch 1434/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0433 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.9074\n",
      "Epoch 1435/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0432 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.9074\n",
      "Epoch 1436/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0430 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.9074\n",
      "Epoch 1437/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.9074\n",
      "Epoch 1438/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.9074\n",
      "Epoch 1439/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0426 - acc: 1.0000 - val_loss: 0.4781 - val_acc: 0.9074\n",
      "Epoch 1440/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0425 - acc: 1.0000 - val_loss: 0.4786 - val_acc: 0.9074\n",
      "Epoch 1441/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.4778 - val_acc: 0.9074\n",
      "Epoch 1442/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.4801 - val_acc: 0.9074\n",
      "Epoch 1443/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0419 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.9074\n",
      "Epoch 1444/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.4825 - val_acc: 0.9074\n",
      "Epoch 1445/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.9074\n",
      "Epoch 1446/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.4846 - val_acc: 0.9074\n",
      "Epoch 1447/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0414 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.9074\n",
      "Epoch 1448/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.9074\n",
      "Epoch 1449/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.9074\n",
      "Epoch 1450/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.9074\n",
      "Epoch 1451/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.9074\n",
      "Epoch 1452/10000\n",
      "216/216 [==============================] - 0s 79us/step - loss: 0.0408 - acc: 1.0000 - val_loss: 0.4853 - val_acc: 0.9074\n",
      "Epoch 1453/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.9074\n",
      "Epoch 1454/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0406 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.9074\n",
      "Epoch 1455/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.9074\n",
      "Epoch 1456/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0402 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.9074\n",
      "Epoch 1457/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.9074\n",
      "Epoch 1458/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.9074\n",
      "Epoch 1459/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0397 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.9074\n",
      "Epoch 1460/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0396 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.9074\n",
      "Epoch 1461/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.4923 - val_acc: 0.9074\n",
      "Epoch 1462/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.4939 - val_acc: 0.9074\n",
      "Epoch 1463/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.9074\n",
      "Epoch 1464/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0391 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.9074\n",
      "Epoch 1465/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.4921 - val_acc: 0.9074\n",
      "Epoch 1466/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.4939 - val_acc: 0.9074\n",
      "Epoch 1467/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0387 - acc: 1.0000 - val_loss: 0.4915 - val_acc: 0.9074\n",
      "Epoch 1468/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.9074\n",
      "Epoch 1469/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.4963 - val_acc: 0.9074\n",
      "Epoch 1470/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.4978 - val_acc: 0.9074\n",
      "Epoch 1471/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.4941 - val_acc: 0.9074\n",
      "Epoch 1472/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0380 - acc: 1.0000 - val_loss: 0.4919 - val_acc: 0.9074\n",
      "Epoch 1473/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0380 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1474/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.4933 - val_acc: 0.9074\n",
      "Epoch 1475/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0376 - acc: 1.0000 - val_loss: 0.4965 - val_acc: 0.9074\n",
      "Epoch 1476/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0374 - acc: 1.0000 - val_loss: 0.4977 - val_acc: 0.9074\n",
      "Epoch 1477/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0375 - acc: 1.0000 - val_loss: 0.4981 - val_acc: 0.9074\n",
      "Epoch 1478/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.4976 - val_acc: 0.9074\n",
      "Epoch 1479/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.4968 - val_acc: 0.9074\n",
      "Epoch 1480/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.4979 - val_acc: 0.9074\n",
      "Epoch 1481/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0369 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.9074\n",
      "Epoch 1482/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.4981 - val_acc: 0.9074\n",
      "Epoch 1483/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0366 - acc: 1.0000 - val_loss: 0.4994 - val_acc: 0.9074\n",
      "Epoch 1484/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0365 - acc: 1.0000 - val_loss: 0.4987 - val_acc: 0.9074\n",
      "Epoch 1485/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0365 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.9074\n",
      "Epoch 1486/10000\n",
      "216/216 [==============================] - 0s 79us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.5009 - val_acc: 0.9074\n",
      "Epoch 1487/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.9074\n",
      "Epoch 1488/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.5027 - val_acc: 0.9074\n",
      "Epoch 1489/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 0.5023 - val_acc: 0.9074\n",
      "Epoch 1490/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.5032 - val_acc: 0.9074\n",
      "Epoch 1491/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.9074\n",
      "Epoch 1492/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.5028 - val_acc: 0.9074\n",
      "Epoch 1493/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.5051 - val_acc: 0.9074\n",
      "Epoch 1494/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.5027 - val_acc: 0.9074\n",
      "Epoch 1495/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.5033 - val_acc: 0.9074\n",
      "Epoch 1496/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.5050 - val_acc: 0.9074\n",
      "Epoch 1497/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.5087 - val_acc: 0.9074\n",
      "Epoch 1498/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 0.5089 - val_acc: 0.9074\n",
      "Epoch 1499/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.5095 - val_acc: 0.9074\n",
      "Epoch 1500/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.5079 - val_acc: 0.9074\n",
      "Epoch 1501/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0345 - acc: 1.0000 - val_loss: 0.5074 - val_acc: 0.9074\n",
      "Epoch 1502/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0342 - acc: 1.0000 - val_loss: 0.5092 - val_acc: 0.9074\n",
      "Epoch 1503/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.5113 - val_acc: 0.9074\n",
      "Epoch 1504/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0342 - acc: 1.0000 - val_loss: 0.5083 - val_acc: 0.9074\n",
      "Epoch 1505/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.5101 - val_acc: 0.9074\n",
      "Epoch 1506/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.5102 - val_acc: 0.9074\n",
      "Epoch 1507/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.5091 - val_acc: 0.9074\n",
      "Epoch 1508/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.5111 - val_acc: 0.9074\n",
      "Epoch 1509/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.5098 - val_acc: 0.9074\n",
      "Epoch 1510/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.5119 - val_acc: 0.9074\n",
      "Epoch 1511/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.5113 - val_acc: 0.9074\n",
      "Epoch 1512/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.5164 - val_acc: 0.9074\n",
      "Epoch 1513/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.5146 - val_acc: 0.9074\n",
      "Epoch 1514/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0329 - acc: 1.0000 - val_loss: 0.5136 - val_acc: 0.9074\n",
      "Epoch 1515/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.5151 - val_acc: 0.9074\n",
      "Epoch 1516/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.5167 - val_acc: 0.9074\n",
      "Epoch 1517/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.5171 - val_acc: 0.9074\n",
      "Epoch 1518/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.5131 - val_acc: 0.9074\n",
      "Epoch 1519/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.5131 - val_acc: 0.9074\n",
      "Epoch 1520/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.5139 - val_acc: 0.9074\n",
      "Epoch 1521/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.5152 - val_acc: 0.9074\n",
      "Epoch 1522/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.5167 - val_acc: 0.9074\n",
      "Epoch 1523/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.5168 - val_acc: 0.9074\n",
      "Epoch 1524/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0318 - acc: 1.0000 - val_loss: 0.5137 - val_acc: 0.9074\n",
      "Epoch 1525/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.5128 - val_acc: 0.9074\n",
      "Epoch 1526/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.5170 - val_acc: 0.9074\n",
      "Epoch 1527/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.5174 - val_acc: 0.9074\n",
      "Epoch 1528/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 0.5193 - val_acc: 0.9074\n",
      "Epoch 1529/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.5184 - val_acc: 0.9074\n",
      "Epoch 1530/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.5182 - val_acc: 0.9074\n",
      "Epoch 1531/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.9074\n",
      "Epoch 1532/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.5166 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1533/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.5208 - val_acc: 0.9074\n",
      "Epoch 1534/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.5211 - val_acc: 0.9074\n",
      "Epoch 1535/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.5234 - val_acc: 0.9074\n",
      "Epoch 1536/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.5232 - val_acc: 0.9074\n",
      "Epoch 1537/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.5251 - val_acc: 0.9074\n",
      "Epoch 1538/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.5242 - val_acc: 0.9074\n",
      "Epoch 1539/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.5228 - val_acc: 0.9074\n",
      "Epoch 1540/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.5208 - val_acc: 0.9074\n",
      "Epoch 1541/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.5251 - val_acc: 0.9074\n",
      "Epoch 1542/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.5235 - val_acc: 0.9074\n",
      "Epoch 1543/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.5242 - val_acc: 0.9074\n",
      "Epoch 1544/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.5245 - val_acc: 0.9074\n",
      "Epoch 1545/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.5264 - val_acc: 0.9074\n",
      "Epoch 1546/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.5271 - val_acc: 0.9074\n",
      "Epoch 1547/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.5273 - val_acc: 0.9074\n",
      "Epoch 1548/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.9074\n",
      "Epoch 1549/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 0.5276 - val_acc: 0.9074\n",
      "Epoch 1550/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0290 - acc: 1.0000 - val_loss: 0.5282 - val_acc: 0.9074\n",
      "Epoch 1551/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.5269 - val_acc: 0.9074\n",
      "Epoch 1552/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.5275 - val_acc: 0.9074\n",
      "Epoch 1553/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.5314 - val_acc: 0.9074\n",
      "Epoch 1554/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.5278 - val_acc: 0.9074\n",
      "Epoch 1555/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.5319 - val_acc: 0.9074\n",
      "Epoch 1556/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.5288 - val_acc: 0.9074\n",
      "Epoch 1557/10000\n",
      "216/216 [==============================] - 0s 79us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.5287 - val_acc: 0.9074\n",
      "Epoch 1558/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.5301 - val_acc: 0.9074\n",
      "Epoch 1559/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.5325 - val_acc: 0.9074\n",
      "Epoch 1560/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.5326 - val_acc: 0.9074\n",
      "Epoch 1561/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.5340 - val_acc: 0.9074\n",
      "Epoch 1562/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.5325 - val_acc: 0.9074\n",
      "Epoch 1563/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.5352 - val_acc: 0.9074\n",
      "Epoch 1564/10000\n",
      "216/216 [==============================] - 0s 79us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.5362 - val_acc: 0.9074\n",
      "Epoch 1565/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.5352 - val_acc: 0.9074\n",
      "Epoch 1566/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.5312 - val_acc: 0.9074\n",
      "Epoch 1567/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.5314 - val_acc: 0.9074\n",
      "Epoch 1568/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.5337 - val_acc: 0.9074\n",
      "Epoch 1569/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.9074\n",
      "Epoch 1570/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.5362 - val_acc: 0.9074\n",
      "Epoch 1571/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.5349 - val_acc: 0.9074\n",
      "Epoch 1572/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.5363 - val_acc: 0.9074\n",
      "Epoch 1573/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.5368 - val_acc: 0.9074\n",
      "Epoch 1574/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.5387 - val_acc: 0.9074\n",
      "Epoch 1575/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.5421 - val_acc: 0.9074\n",
      "Epoch 1576/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.5386 - val_acc: 0.9074\n",
      "Epoch 1577/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.5400 - val_acc: 0.9074\n",
      "Epoch 1578/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.5404 - val_acc: 0.9074\n",
      "Epoch 1579/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.5424 - val_acc: 0.9074\n",
      "Epoch 1580/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.9074\n",
      "Epoch 1581/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.5450 - val_acc: 0.9074\n",
      "Epoch 1582/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 0.9074\n",
      "Epoch 1583/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.5434 - val_acc: 0.9074\n",
      "Epoch 1584/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.5428 - val_acc: 0.9074\n",
      "Epoch 1585/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.5461 - val_acc: 0.9074\n",
      "Epoch 1586/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.5437 - val_acc: 0.9074\n",
      "Epoch 1587/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.5410 - val_acc: 0.9074\n",
      "Epoch 1588/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.9074\n",
      "Epoch 1589/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.5448 - val_acc: 0.9074\n",
      "Epoch 1590/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.5429 - val_acc: 0.9074\n",
      "Epoch 1591/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.5463 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1592/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.9074\n",
      "Epoch 1593/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.5444 - val_acc: 0.9074\n",
      "Epoch 1594/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.5469 - val_acc: 0.9074\n",
      "Epoch 1595/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.5440 - val_acc: 0.9074\n",
      "Epoch 1596/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.5455 - val_acc: 0.9074\n",
      "Epoch 1597/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.5491 - val_acc: 0.9074\n",
      "Epoch 1598/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.9074\n",
      "Epoch 1599/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.5490 - val_acc: 0.9074\n",
      "Epoch 1600/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.5479 - val_acc: 0.9074\n",
      "Epoch 1601/10000\n",
      "216/216 [==============================] - 0s 92us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.5478 - val_acc: 0.9074\n",
      "Epoch 1602/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.5489 - val_acc: 0.9074\n",
      "Epoch 1603/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.9074\n",
      "Epoch 1604/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.9074\n",
      "Epoch 1605/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.5525 - val_acc: 0.9074\n",
      "Epoch 1606/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.5512 - val_acc: 0.9074\n",
      "Epoch 1607/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.5551 - val_acc: 0.9074\n",
      "Epoch 1608/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.5517 - val_acc: 0.9074\n",
      "Epoch 1609/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.5493 - val_acc: 0.9074\n",
      "Epoch 1610/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.9074\n",
      "Epoch 1611/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.5543 - val_acc: 0.9074\n",
      "Epoch 1612/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.5538 - val_acc: 0.9074\n",
      "Epoch 1613/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.5571 - val_acc: 0.9074\n",
      "Epoch 1614/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.9074\n",
      "Epoch 1615/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.5565 - val_acc: 0.9074\n",
      "Epoch 1616/10000\n",
      "216/216 [==============================] - 0s 208us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.5557 - val_acc: 0.9074\n",
      "Epoch 1617/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.5564 - val_acc: 0.9074\n",
      "Epoch 1618/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.5560 - val_acc: 0.9074\n",
      "Epoch 1619/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.5547 - val_acc: 0.9074\n",
      "Epoch 1620/10000\n",
      "216/216 [==============================] - 0s 180us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.5590 - val_acc: 0.9074\n",
      "Epoch 1621/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.5596 - val_acc: 0.9074\n",
      "Epoch 1622/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.5566 - val_acc: 0.9074\n",
      "Epoch 1623/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.5591 - val_acc: 0.9074\n",
      "Epoch 1624/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.5606 - val_acc: 0.9074\n",
      "Epoch 1625/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.9074\n",
      "Epoch 1626/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.5617 - val_acc: 0.9074\n",
      "Epoch 1627/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.9074\n",
      "Epoch 1628/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.5613 - val_acc: 0.9074\n",
      "Epoch 1629/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.9074\n",
      "Epoch 1630/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.9074\n",
      "Epoch 1631/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.5607 - val_acc: 0.9074\n",
      "Epoch 1632/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.5600 - val_acc: 0.9074\n",
      "Epoch 1633/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.9074\n",
      "Epoch 1634/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.5643 - val_acc: 0.9074\n",
      "Epoch 1635/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.5629 - val_acc: 0.9074\n",
      "Epoch 1636/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.5653 - val_acc: 0.9074\n",
      "Epoch 1637/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.5661 - val_acc: 0.9074\n",
      "Epoch 1638/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.5687 - val_acc: 0.9074\n",
      "Epoch 1639/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.5668 - val_acc: 0.9074\n",
      "Epoch 1640/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.9074\n",
      "Epoch 1641/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.5684 - val_acc: 0.9074\n",
      "Epoch 1642/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.5665 - val_acc: 0.9074\n",
      "Epoch 1643/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.5679 - val_acc: 0.9074\n",
      "Epoch 1644/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.5676 - val_acc: 0.9074\n",
      "Epoch 1645/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.5662 - val_acc: 0.9074\n",
      "Epoch 1646/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.5657 - val_acc: 0.9074\n",
      "Epoch 1647/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.9074\n",
      "Epoch 1648/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.5702 - val_acc: 0.9074\n",
      "Epoch 1649/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.5723 - val_acc: 0.9074\n",
      "Epoch 1650/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.5724 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1651/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.5743 - val_acc: 0.9074\n",
      "Epoch 1652/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.5761 - val_acc: 0.9074\n",
      "Epoch 1653/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.5706 - val_acc: 0.9074\n",
      "Epoch 1654/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.5705 - val_acc: 0.9074\n",
      "Epoch 1655/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.5710 - val_acc: 0.9074\n",
      "Epoch 1656/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.5706 - val_acc: 0.9074\n",
      "Epoch 1657/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.5741 - val_acc: 0.9074\n",
      "Epoch 1658/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.5770 - val_acc: 0.9074\n",
      "Epoch 1659/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.5782 - val_acc: 0.9074\n",
      "Epoch 1660/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.5787 - val_acc: 0.9074\n",
      "Epoch 1661/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.5779 - val_acc: 0.9074\n",
      "Epoch 1662/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.9074\n",
      "Epoch 1663/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.5806 - val_acc: 0.9074\n",
      "Epoch 1664/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.5787 - val_acc: 0.9074\n",
      "Epoch 1665/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.5744 - val_acc: 0.9074\n",
      "Epoch 1666/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.5783 - val_acc: 0.9074\n",
      "Epoch 1667/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.5807 - val_acc: 0.9074\n",
      "Epoch 1668/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.9074\n",
      "Epoch 1669/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.9074\n",
      "Epoch 1670/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.5827 - val_acc: 0.9074\n",
      "Epoch 1671/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.5830 - val_acc: 0.9074\n",
      "Epoch 1672/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.9074\n",
      "Epoch 1673/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.9074\n",
      "Epoch 1674/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.5828 - val_acc: 0.9074\n",
      "Epoch 1675/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.5833 - val_acc: 0.9074\n",
      "Epoch 1676/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.5854 - val_acc: 0.9074\n",
      "Epoch 1677/10000\n",
      "216/216 [==============================] - 0s 180us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.5860 - val_acc: 0.9074\n",
      "Epoch 1678/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.5866 - val_acc: 0.9074\n",
      "Epoch 1679/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.5856 - val_acc: 0.9074\n",
      "Epoch 1680/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.5849 - val_acc: 0.9074\n",
      "Epoch 1681/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.5891 - val_acc: 0.9074\n",
      "Epoch 1682/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.5897 - val_acc: 0.9074\n",
      "Epoch 1683/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.5920 - val_acc: 0.9074\n",
      "Epoch 1684/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.5886 - val_acc: 0.9074\n",
      "Epoch 1685/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.5846 - val_acc: 0.9074\n",
      "Epoch 1686/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.5870 - val_acc: 0.9074\n",
      "Epoch 1687/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.5883 - val_acc: 0.9074\n",
      "Epoch 1688/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.5905 - val_acc: 0.9074\n",
      "Epoch 1689/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.9074\n",
      "Epoch 1690/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.5910 - val_acc: 0.9074\n",
      "Epoch 1691/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.5882 - val_acc: 0.9074\n",
      "Epoch 1692/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.5903 - val_acc: 0.9074\n",
      "Epoch 1693/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.5884 - val_acc: 0.9074\n",
      "Epoch 1694/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.5894 - val_acc: 0.9074\n",
      "Epoch 1695/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.5928 - val_acc: 0.9074\n",
      "Epoch 1696/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.5919 - val_acc: 0.9074\n",
      "Epoch 1697/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.9074\n",
      "Epoch 1698/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.5915 - val_acc: 0.9074\n",
      "Epoch 1699/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.5925 - val_acc: 0.9074\n",
      "Epoch 1700/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.5946 - val_acc: 0.9074\n",
      "Epoch 1701/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.9074\n",
      "Epoch 1702/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.9074\n",
      "Epoch 1703/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.5990 - val_acc: 0.9074\n",
      "Epoch 1704/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6005 - val_acc: 0.9074\n",
      "Epoch 1705/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6004 - val_acc: 0.9074\n",
      "Epoch 1706/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6006 - val_acc: 0.9074\n",
      "Epoch 1707/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6041 - val_acc: 0.9074\n",
      "Epoch 1708/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6032 - val_acc: 0.9074\n",
      "Epoch 1709/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6002 - val_acc: 0.9074\n",
      "Epoch 1710/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6018 - val_acc: 0.9074\n",
      "Epoch 1711/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.5997 - val_acc: 0.9074\n",
      "Epoch 1712/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6004 - val_acc: 0.9074\n",
      "Epoch 1713/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6010 - val_acc: 0.9074\n",
      "Epoch 1714/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.9074\n",
      "Epoch 1715/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6037 - val_acc: 0.9074\n",
      "Epoch 1716/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6039 - val_acc: 0.9074\n",
      "Epoch 1717/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6101 - val_acc: 0.9074\n",
      "Epoch 1718/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.6059 - val_acc: 0.9074\n",
      "Epoch 1719/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.6072 - val_acc: 0.9074\n",
      "Epoch 1720/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6056 - val_acc: 0.9074\n",
      "Epoch 1721/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.9074\n",
      "Epoch 1722/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.9074\n",
      "Epoch 1723/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.6055 - val_acc: 0.9074\n",
      "Epoch 1724/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.6094 - val_acc: 0.9074\n",
      "Epoch 1725/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6066 - val_acc: 0.9074\n",
      "Epoch 1726/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6086 - val_acc: 0.9074\n",
      "Epoch 1727/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.6105 - val_acc: 0.9074\n",
      "Epoch 1728/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.6102 - val_acc: 0.9074\n",
      "Epoch 1729/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.6072 - val_acc: 0.9074\n",
      "Epoch 1730/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.6110 - val_acc: 0.9074\n",
      "Epoch 1731/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.6127 - val_acc: 0.9074\n",
      "Epoch 1732/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6131 - val_acc: 0.9074\n",
      "Epoch 1733/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.6130 - val_acc: 0.9074\n",
      "Epoch 1734/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.6113 - val_acc: 0.9074\n",
      "Epoch 1735/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.9074\n",
      "Epoch 1736/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.6136 - val_acc: 0.9074\n",
      "Epoch 1737/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.6188 - val_acc: 0.9074\n",
      "Epoch 1738/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.6188 - val_acc: 0.9074\n",
      "Epoch 1739/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.6168 - val_acc: 0.9074\n",
      "Epoch 1740/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.9074\n",
      "Epoch 1741/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.6156 - val_acc: 0.9074\n",
      "Epoch 1742/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.9074\n",
      "Epoch 1743/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.6181 - val_acc: 0.9074\n",
      "Epoch 1744/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.6163 - val_acc: 0.9074\n",
      "Epoch 1745/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.6176 - val_acc: 0.9074\n",
      "Epoch 1746/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.6215 - val_acc: 0.9074\n",
      "Epoch 1747/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 0.9074\n",
      "Epoch 1748/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.9074\n",
      "Epoch 1749/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.6219 - val_acc: 0.9074\n",
      "Epoch 1750/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.6210 - val_acc: 0.9074\n",
      "Epoch 1751/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.6199 - val_acc: 0.9074\n",
      "Epoch 1752/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6184 - val_acc: 0.9074\n",
      "Epoch 1753/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6222 - val_acc: 0.9074\n",
      "Epoch 1754/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6227 - val_acc: 0.9074\n",
      "Epoch 1755/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.6231 - val_acc: 0.9074\n",
      "Epoch 1756/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.6246 - val_acc: 0.9074\n",
      "Epoch 1757/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.6244 - val_acc: 0.9074\n",
      "Epoch 1758/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.9074\n",
      "Epoch 1759/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.6252 - val_acc: 0.9074\n",
      "Epoch 1760/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.6227 - val_acc: 0.9074\n",
      "Epoch 1761/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.6223 - val_acc: 0.9074\n",
      "Epoch 1762/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.6258 - val_acc: 0.9074\n",
      "Epoch 1763/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.6269 - val_acc: 0.9074\n",
      "Epoch 1764/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 0.9074\n",
      "Epoch 1765/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.9074\n",
      "Epoch 1766/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.6330 - val_acc: 0.9074\n",
      "Epoch 1767/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.6319 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1768/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.6319 - val_acc: 0.9074\n",
      "Epoch 1769/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.6290 - val_acc: 0.9074\n",
      "Epoch 1770/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.6295 - val_acc: 0.9074\n",
      "Epoch 1771/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 0.9074\n",
      "Epoch 1772/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.6335 - val_acc: 0.9074\n",
      "Epoch 1773/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.6347 - val_acc: 0.9074\n",
      "Epoch 1774/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.6323 - val_acc: 0.9074\n",
      "Epoch 1775/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.6311 - val_acc: 0.9074\n",
      "Epoch 1776/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.6359 - val_acc: 0.9074\n",
      "Epoch 1777/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 0.9074\n",
      "Epoch 1778/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.6371 - val_acc: 0.9074\n",
      "Epoch 1779/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.6357 - val_acc: 0.9074\n",
      "Epoch 1780/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 0.9074\n",
      "Epoch 1781/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.6339 - val_acc: 0.9074\n",
      "Epoch 1782/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.6357 - val_acc: 0.9074\n",
      "Epoch 1783/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 0.9074\n",
      "Epoch 1784/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.6397 - val_acc: 0.9074\n",
      "Epoch 1785/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.6426 - val_acc: 0.9074\n",
      "Epoch 1786/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 0.9074\n",
      "Epoch 1787/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 0.9074\n",
      "Epoch 1788/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.9074\n",
      "Epoch 1789/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.9074\n",
      "Epoch 1790/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.6446 - val_acc: 0.9074\n",
      "Epoch 1791/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.6455 - val_acc: 0.9074\n",
      "Epoch 1792/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 0.9074\n",
      "Epoch 1793/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.9074\n",
      "Epoch 1794/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.6476 - val_acc: 0.9074\n",
      "Epoch 1795/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.6484 - val_acc: 0.9074\n",
      "Epoch 1796/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.6500 - val_acc: 0.9074\n",
      "Epoch 1797/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.9074\n",
      "Epoch 1798/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.6508 - val_acc: 0.9074\n",
      "Epoch 1799/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.6462 - val_acc: 0.9074\n",
      "Epoch 1800/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.6498 - val_acc: 0.9074\n",
      "Epoch 1801/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.6510 - val_acc: 0.9074\n",
      "Epoch 1802/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.6495 - val_acc: 0.9074\n",
      "Epoch 1803/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.6509 - val_acc: 0.9074\n",
      "Epoch 1804/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.6513 - val_acc: 0.9074\n",
      "Epoch 1805/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.6515 - val_acc: 0.9074\n",
      "Epoch 1806/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6534 - val_acc: 0.9074\n",
      "Epoch 1807/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.9074\n",
      "Epoch 1808/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.9074\n",
      "Epoch 1809/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.6542 - val_acc: 0.9074\n",
      "Epoch 1810/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.9074\n",
      "Epoch 1811/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.6585 - val_acc: 0.9074\n",
      "Epoch 1812/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.9074\n",
      "Epoch 1813/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.6597 - val_acc: 0.9074\n",
      "Epoch 1814/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.6589 - val_acc: 0.9074\n",
      "Epoch 1815/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.6570 - val_acc: 0.9074\n",
      "Epoch 1816/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 0.9074\n",
      "Epoch 1817/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.6637 - val_acc: 0.9074\n",
      "Epoch 1818/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.6628 - val_acc: 0.9074\n",
      "Epoch 1819/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.6599 - val_acc: 0.9074\n",
      "Epoch 1820/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.6603 - val_acc: 0.9074\n",
      "Epoch 1821/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.6633 - val_acc: 0.9074\n",
      "Epoch 1822/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.6611 - val_acc: 0.9074\n",
      "Epoch 1823/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.6625 - val_acc: 0.9074\n",
      "Epoch 1824/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.9074\n",
      "Epoch 1825/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.6667 - val_acc: 0.9074\n",
      "Epoch 1826/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.6638 - val_acc: 0.9074\n",
      "Epoch 1827/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.6635 - val_acc: 0.9074\n",
      "Epoch 1828/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.6672 - val_acc: 0.9074\n",
      "Epoch 1829/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 0.9074\n",
      "Epoch 1830/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.6664 - val_acc: 0.9074\n",
      "Epoch 1831/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.6689 - val_acc: 0.9074\n",
      "Epoch 1832/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.9074\n",
      "Epoch 1833/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.6678 - val_acc: 0.9074\n",
      "Epoch 1834/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.6704 - val_acc: 0.9074\n",
      "Epoch 1835/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.6740 - val_acc: 0.9074\n",
      "Epoch 1836/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.6727 - val_acc: 0.9074\n",
      "Epoch 1837/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.9074\n",
      "Epoch 1838/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.6763 - val_acc: 0.9074\n",
      "Epoch 1839/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.6746 - val_acc: 0.9074\n",
      "Epoch 1840/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.6743 - val_acc: 0.9074\n",
      "Epoch 1841/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.6752 - val_acc: 0.9074\n",
      "Epoch 1842/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.9074\n",
      "Epoch 1843/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.6769 - val_acc: 0.9074\n",
      "Epoch 1844/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.6763 - val_acc: 0.9074\n",
      "Epoch 1845/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.6773 - val_acc: 0.9074\n",
      "Epoch 1846/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.6773 - val_acc: 0.9074\n",
      "Epoch 1847/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.6813 - val_acc: 0.9074\n",
      "Epoch 1848/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6810 - val_acc: 0.9074\n",
      "Epoch 1849/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.6810 - val_acc: 0.9074\n",
      "Epoch 1850/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6817 - val_acc: 0.9074\n",
      "Epoch 1851/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.9074\n",
      "Epoch 1852/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.6848 - val_acc: 0.9074\n",
      "Epoch 1853/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.6835 - val_acc: 0.9074\n",
      "Epoch 1854/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.6870 - val_acc: 0.9074\n",
      "Epoch 1855/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 0.9074\n",
      "Epoch 1856/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.6873 - val_acc: 0.9074\n",
      "Epoch 1857/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.6872 - val_acc: 0.9074\n",
      "Epoch 1858/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.6876 - val_acc: 0.9074\n",
      "Epoch 1859/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.6876 - val_acc: 0.9074\n",
      "Epoch 1860/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.6900 - val_acc: 0.9074\n",
      "Epoch 1861/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.6894 - val_acc: 0.9074\n",
      "Epoch 1862/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.6861 - val_acc: 0.9074\n",
      "Epoch 1863/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6894 - val_acc: 0.9074\n",
      "Epoch 1864/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6864 - val_acc: 0.9074\n",
      "Epoch 1865/10000\n",
      "216/216 [==============================] - 0s 213us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6873 - val_acc: 0.9074\n",
      "Epoch 1866/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6911 - val_acc: 0.9074\n",
      "Epoch 1867/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.6956 - val_acc: 0.9074\n",
      "Epoch 1868/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.6943 - val_acc: 0.9074\n",
      "Epoch 1869/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.6943 - val_acc: 0.9074\n",
      "Epoch 1870/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.6975 - val_acc: 0.9074\n",
      "Epoch 1871/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6969 - val_acc: 0.9074\n",
      "Epoch 1872/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.6943 - val_acc: 0.9074\n",
      "Epoch 1873/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6958 - val_acc: 0.9074\n",
      "Epoch 1874/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6947 - val_acc: 0.9074\n",
      "Epoch 1875/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.6964 - val_acc: 0.8889\n",
      "Epoch 1876/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.6954 - val_acc: 0.9074\n",
      "Epoch 1877/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.6993 - val_acc: 0.9074\n",
      "Epoch 1878/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.6990 - val_acc: 0.9074\n",
      "Epoch 1879/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.6996 - val_acc: 0.9074\n",
      "Epoch 1880/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7002 - val_acc: 0.9074\n",
      "Epoch 1881/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7014 - val_acc: 0.8889\n",
      "Epoch 1882/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7011 - val_acc: 0.8889\n",
      "Epoch 1883/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.6995 - val_acc: 0.8889\n",
      "Epoch 1884/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7002 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1885/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.8889\n",
      "Epoch 1886/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.8889\n",
      "Epoch 1887/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7066 - val_acc: 0.8889\n",
      "Epoch 1888/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7062 - val_acc: 0.8889\n",
      "Epoch 1889/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7074 - val_acc: 0.8889\n",
      "Epoch 1890/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.7055 - val_acc: 0.8889\n",
      "Epoch 1891/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.8889\n",
      "Epoch 1892/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7121 - val_acc: 0.8889\n",
      "Epoch 1893/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7108 - val_acc: 0.8889\n",
      "Epoch 1894/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.7093 - val_acc: 0.8889\n",
      "Epoch 1895/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7132 - val_acc: 0.8889\n",
      "Epoch 1896/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7180 - val_acc: 0.8889\n",
      "Epoch 1897/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.7129 - val_acc: 0.8889\n",
      "Epoch 1898/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7150 - val_acc: 0.8889\n",
      "Epoch 1899/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7172 - val_acc: 0.8889\n",
      "Epoch 1900/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7180 - val_acc: 0.8889\n",
      "Epoch 1901/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.7193 - val_acc: 0.8889\n",
      "Epoch 1902/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7182 - val_acc: 0.8889\n",
      "Epoch 1903/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.7192 - val_acc: 0.8889\n",
      "Epoch 1904/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7181 - val_acc: 0.8889\n",
      "Epoch 1905/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7166 - val_acc: 0.8889\n",
      "Epoch 1906/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.7151 - val_acc: 0.8889\n",
      "Epoch 1907/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7178 - val_acc: 0.8889\n",
      "Epoch 1908/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7207 - val_acc: 0.8889\n",
      "Epoch 1909/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.7212 - val_acc: 0.8889\n",
      "Epoch 1910/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 0.8889\n",
      "Epoch 1911/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7239 - val_acc: 0.8889\n",
      "Epoch 1912/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7247 - val_acc: 0.8889\n",
      "Epoch 1913/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 0.8889\n",
      "Epoch 1914/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7283 - val_acc: 0.8889\n",
      "Epoch 1915/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 0.8889\n",
      "Epoch 1916/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7277 - val_acc: 0.8889\n",
      "Epoch 1917/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 0.8889\n",
      "Epoch 1918/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.8889\n",
      "Epoch 1919/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7311 - val_acc: 0.8889\n",
      "Epoch 1920/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7317 - val_acc: 0.8889\n",
      "Epoch 1921/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7311 - val_acc: 0.8889\n",
      "Epoch 1922/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.8889\n",
      "Epoch 1923/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7326 - val_acc: 0.8889\n",
      "Epoch 1924/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.8889\n",
      "Epoch 1925/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7341 - val_acc: 0.8889\n",
      "Epoch 1926/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.8889\n",
      "Epoch 1927/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.7385 - val_acc: 0.8889\n",
      "Epoch 1928/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7376 - val_acc: 0.8889\n",
      "Epoch 1929/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.8889\n",
      "Epoch 1930/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7369 - val_acc: 0.8889\n",
      "Epoch 1931/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7379 - val_acc: 0.8889\n",
      "Epoch 1932/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 0.8889\n",
      "Epoch 1933/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.8889\n",
      "Epoch 1934/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.8889\n",
      "Epoch 1935/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7395 - val_acc: 0.8889\n",
      "Epoch 1936/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7441 - val_acc: 0.8889\n",
      "Epoch 1937/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7437 - val_acc: 0.8889\n",
      "Epoch 1938/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7425 - val_acc: 0.8889\n",
      "Epoch 1939/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7465 - val_acc: 0.8889\n",
      "Epoch 1940/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7481 - val_acc: 0.8889\n",
      "Epoch 1941/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7480 - val_acc: 0.8889\n",
      "Epoch 1942/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.7502 - val_acc: 0.8889\n",
      "Epoch 1943/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.7525 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1944/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.7535 - val_acc: 0.8889\n",
      "Epoch 1945/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 0.8889\n",
      "Epoch 1946/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7520 - val_acc: 0.8889\n",
      "Epoch 1947/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7529 - val_acc: 0.8889\n",
      "Epoch 1948/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.8889\n",
      "Epoch 1949/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.8889\n",
      "Epoch 1950/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.7552 - val_acc: 0.8889\n",
      "Epoch 1951/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.7531 - val_acc: 0.8889\n",
      "Epoch 1952/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.7581 - val_acc: 0.8889\n",
      "Epoch 1953/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.7585 - val_acc: 0.8889\n",
      "Epoch 1954/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.8889\n",
      "Epoch 1955/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.7582 - val_acc: 0.8889\n",
      "Epoch 1956/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.7606 - val_acc: 0.8889\n",
      "Epoch 1957/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.7611 - val_acc: 0.8889\n",
      "Epoch 1958/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.7641 - val_acc: 0.8889\n",
      "Epoch 1959/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.7657 - val_acc: 0.8889\n",
      "Epoch 1960/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.7657 - val_acc: 0.8889\n",
      "Epoch 1961/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.8889\n",
      "Epoch 1962/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.7649 - val_acc: 0.8889\n",
      "Epoch 1963/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.7665 - val_acc: 0.8889\n",
      "Epoch 1964/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.7679 - val_acc: 0.8889\n",
      "Epoch 1965/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.8889\n",
      "Epoch 1966/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.8889\n",
      "Epoch 1967/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.8889\n",
      "Epoch 1968/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.7701 - val_acc: 0.8889\n",
      "Epoch 1969/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.7758 - val_acc: 0.8889\n",
      "Epoch 1970/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7771 - val_acc: 0.8889\n",
      "Epoch 1971/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.8889\n",
      "Epoch 1972/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.8889\n",
      "Epoch 1973/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.7738 - val_acc: 0.8889\n",
      "Epoch 1974/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.7773 - val_acc: 0.8889\n",
      "Epoch 1975/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.7766 - val_acc: 0.8889\n",
      "Epoch 1976/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.7793 - val_acc: 0.8889\n",
      "Epoch 1977/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.7790 - val_acc: 0.8889\n",
      "Epoch 1978/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.7802 - val_acc: 0.8889\n",
      "Epoch 1979/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.7825 - val_acc: 0.8889\n",
      "Epoch 1980/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.8889\n",
      "Epoch 1981/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.7813 - val_acc: 0.8889\n",
      "Epoch 1982/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7861 - val_acc: 0.8889\n",
      "Epoch 1983/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7839 - val_acc: 0.8889\n",
      "Epoch 1984/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7848 - val_acc: 0.8889\n",
      "Epoch 1985/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7879 - val_acc: 0.8889\n",
      "Epoch 1986/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7881 - val_acc: 0.8889\n",
      "Epoch 1987/10000\n",
      "216/216 [==============================] - 0s 259us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.7880 - val_acc: 0.8889\n",
      "Epoch 1988/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.7887 - val_acc: 0.8889\n",
      "Epoch 1989/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.7908 - val_acc: 0.8889\n",
      "Epoch 1990/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.7900 - val_acc: 0.8889\n",
      "Epoch 1991/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.7920 - val_acc: 0.8889\n",
      "Epoch 1992/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.8889\n",
      "Epoch 1993/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.7929 - val_acc: 0.8889\n",
      "Epoch 1994/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.7950 - val_acc: 0.8889\n",
      "Epoch 1995/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.7982 - val_acc: 0.8889\n",
      "Epoch 1996/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.7973 - val_acc: 0.8889\n",
      "Epoch 1997/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8005 - val_acc: 0.8889\n",
      "Epoch 1998/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.7999 - val_acc: 0.8889\n",
      "Epoch 1999/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8038 - val_acc: 0.8889\n",
      "Epoch 2000/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.8011 - val_acc: 0.8889\n",
      "Epoch 2001/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.8039 - val_acc: 0.8889\n",
      "Epoch 2002/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.8035 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2003/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.8036 - val_acc: 0.8889\n",
      "Epoch 2004/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.8064 - val_acc: 0.8889\n",
      "Epoch 2005/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8069 - val_acc: 0.8889\n",
      "Epoch 2006/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8057 - val_acc: 0.8889\n",
      "Epoch 2007/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8049 - val_acc: 0.8889\n",
      "Epoch 2008/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8120 - val_acc: 0.8889\n",
      "Epoch 2009/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8110 - val_acc: 0.8889\n",
      "Epoch 2010/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.8091 - val_acc: 0.8889\n",
      "Epoch 2011/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.8088 - val_acc: 0.8889\n",
      "Epoch 2012/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.8131 - val_acc: 0.8889\n",
      "Epoch 2013/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.8164 - val_acc: 0.8889\n",
      "Epoch 2014/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.8183 - val_acc: 0.8889\n",
      "Epoch 2015/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.8153 - val_acc: 0.8889\n",
      "Epoch 2016/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.8156 - val_acc: 0.8889\n",
      "Epoch 2017/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.8183 - val_acc: 0.8889\n",
      "Epoch 2018/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.8170 - val_acc: 0.8889\n",
      "Epoch 2019/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.8185 - val_acc: 0.8889\n",
      "Epoch 2020/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.8229 - val_acc: 0.8889\n",
      "Epoch 2021/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.8218 - val_acc: 0.8889\n",
      "Epoch 2022/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.8222 - val_acc: 0.8889\n",
      "Epoch 2023/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.8241 - val_acc: 0.8889\n",
      "Epoch 2024/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.8248 - val_acc: 0.8889\n",
      "Epoch 2025/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.8248 - val_acc: 0.8889\n",
      "Epoch 2026/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.8266 - val_acc: 0.8889\n",
      "Epoch 2027/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.8889\n",
      "Epoch 2028/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.8278 - val_acc: 0.8889\n",
      "Epoch 2029/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.8287 - val_acc: 0.8889\n",
      "Epoch 2030/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.8275 - val_acc: 0.8889\n",
      "Epoch 2031/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.8292 - val_acc: 0.8889\n",
      "Epoch 2032/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.8309 - val_acc: 0.8889\n",
      "Epoch 2033/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.8328 - val_acc: 0.8889\n",
      "Epoch 2034/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.8337 - val_acc: 0.8889\n",
      "Epoch 2035/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.8385 - val_acc: 0.8889\n",
      "Epoch 2036/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.8367 - val_acc: 0.8889\n",
      "Epoch 2037/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.8369 - val_acc: 0.8889\n",
      "Epoch 2038/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.8380 - val_acc: 0.8889\n",
      "Epoch 2039/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.8414 - val_acc: 0.8889\n",
      "Epoch 2040/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.8434 - val_acc: 0.8889\n",
      "Epoch 2041/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8407 - val_acc: 0.8889\n",
      "Epoch 2042/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8447 - val_acc: 0.8889\n",
      "Epoch 2043/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8471 - val_acc: 0.8889\n",
      "Epoch 2044/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8491 - val_acc: 0.8889\n",
      "Epoch 2045/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8464 - val_acc: 0.8889\n",
      "Epoch 2046/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8474 - val_acc: 0.8889\n",
      "Epoch 2047/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8451 - val_acc: 0.8889\n",
      "Epoch 2048/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8504 - val_acc: 0.8889\n",
      "Epoch 2049/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8507 - val_acc: 0.8889\n",
      "Epoch 2050/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8490 - val_acc: 0.8889\n",
      "Epoch 2051/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8509 - val_acc: 0.8889\n",
      "Epoch 2052/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8484 - val_acc: 0.8889\n",
      "Epoch 2053/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8509 - val_acc: 0.8889\n",
      "Epoch 2054/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.8553 - val_acc: 0.8889\n",
      "Epoch 2055/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.8535 - val_acc: 0.8889\n",
      "Epoch 2056/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.8889\n",
      "Epoch 2057/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.8606 - val_acc: 0.8889\n",
      "Epoch 2058/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.8589 - val_acc: 0.8889\n",
      "Epoch 2059/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.8611 - val_acc: 0.8889\n",
      "Epoch 2060/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.8889\n",
      "Epoch 2061/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.8603 - val_acc: 0.8889\n",
      "Epoch 2062/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.8633 - val_acc: 0.8889\n",
      "Epoch 2063/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.8639 - val_acc: 0.8889\n",
      "Epoch 2064/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.8626 - val_acc: 0.8889\n",
      "Epoch 2065/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.8889\n",
      "Epoch 2066/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.8633 - val_acc: 0.8889\n",
      "Epoch 2067/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.8889\n",
      "Epoch 2068/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.8889\n",
      "Epoch 2069/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.8699 - val_acc: 0.8889\n",
      "Epoch 2070/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.8715 - val_acc: 0.8889\n",
      "Epoch 2071/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.8703 - val_acc: 0.8889\n",
      "Epoch 2072/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8712 - val_acc: 0.8889\n",
      "Epoch 2073/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.8889\n",
      "Epoch 2074/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8782 - val_acc: 0.8889\n",
      "Epoch 2075/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8773 - val_acc: 0.8889\n",
      "Epoch 2076/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8803 - val_acc: 0.8889\n",
      "Epoch 2077/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8829 - val_acc: 0.8889\n",
      "Epoch 2078/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8839 - val_acc: 0.8889\n",
      "Epoch 2079/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 0.8889\n",
      "Epoch 2080/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8794 - val_acc: 0.8889\n",
      "Epoch 2081/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8829 - val_acc: 0.8889\n",
      "Epoch 2082/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8822 - val_acc: 0.8889\n",
      "Epoch 2083/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8863 - val_acc: 0.8889\n",
      "Epoch 2084/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8857 - val_acc: 0.8889\n",
      "Epoch 2085/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8886 - val_acc: 0.8889\n",
      "Epoch 2086/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8879 - val_acc: 0.8889\n",
      "Epoch 2087/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8896 - val_acc: 0.8889\n",
      "Epoch 2088/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8930 - val_acc: 0.8889\n",
      "Epoch 2089/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8906 - val_acc: 0.8889\n",
      "Epoch 2090/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8953 - val_acc: 0.8889\n",
      "Epoch 2091/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8944 - val_acc: 0.8889\n",
      "Epoch 2092/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8958 - val_acc: 0.8889\n",
      "Epoch 2093/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8941 - val_acc: 0.8889\n",
      "Epoch 2094/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8976 - val_acc: 0.8889\n",
      "Epoch 2095/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8967 - val_acc: 0.8889\n",
      "Epoch 2096/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8983 - val_acc: 0.8889\n",
      "Epoch 2097/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.9004 - val_acc: 0.8889\n",
      "Epoch 2098/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.9002 - val_acc: 0.8889\n",
      "Epoch 2099/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.9056 - val_acc: 0.8889\n",
      "Epoch 2100/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9013 - val_acc: 0.8889\n",
      "Epoch 2101/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9008 - val_acc: 0.8889\n",
      "Epoch 2102/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9077 - val_acc: 0.8889\n",
      "Epoch 2103/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9116 - val_acc: 0.8889\n",
      "Epoch 2104/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9126 - val_acc: 0.8889\n",
      "Epoch 2105/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9126 - val_acc: 0.8889\n",
      "Epoch 2106/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9102 - val_acc: 0.8889\n",
      "Epoch 2107/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9120 - val_acc: 0.8889\n",
      "Epoch 2108/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9128 - val_acc: 0.8889\n",
      "Epoch 2109/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9104 - val_acc: 0.8889\n",
      "Epoch 2110/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9119 - val_acc: 0.8889\n",
      "Epoch 2111/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9183 - val_acc: 0.8889\n",
      "Epoch 2112/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9173 - val_acc: 0.8889\n",
      "Epoch 2113/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9160 - val_acc: 0.8889\n",
      "Epoch 2114/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9191 - val_acc: 0.8889\n",
      "Epoch 2115/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.8889\n",
      "Epoch 2116/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9188 - val_acc: 0.8889\n",
      "Epoch 2117/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9241 - val_acc: 0.8889\n",
      "Epoch 2118/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.8889\n",
      "Epoch 2119/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9247 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2120/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9237 - val_acc: 0.8889\n",
      "Epoch 2121/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9223 - val_acc: 0.8889\n",
      "Epoch 2122/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9273 - val_acc: 0.8889\n",
      "Epoch 2123/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9275 - val_acc: 0.8889\n",
      "Epoch 2124/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9247 - val_acc: 0.8889\n",
      "Epoch 2125/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9290 - val_acc: 0.8889\n",
      "Epoch 2126/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9323 - val_acc: 0.8889\n",
      "Epoch 2127/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9337 - val_acc: 0.8889\n",
      "Epoch 2128/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9326 - val_acc: 0.8889\n",
      "Epoch 2129/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9359 - val_acc: 0.8889\n",
      "Epoch 2130/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9341 - val_acc: 0.8889\n",
      "Epoch 2131/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.8889\n",
      "Epoch 2132/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9322 - val_acc: 0.8889\n",
      "Epoch 2133/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9375 - val_acc: 0.8889\n",
      "Epoch 2134/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9403 - val_acc: 0.8889\n",
      "Epoch 2135/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9372 - val_acc: 0.8889\n",
      "Epoch 2136/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9391 - val_acc: 0.8889\n",
      "Epoch 2137/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9423 - val_acc: 0.8889\n",
      "Epoch 2138/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9430 - val_acc: 0.8889\n",
      "Epoch 2139/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9457 - val_acc: 0.8889\n",
      "Epoch 2140/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9447 - val_acc: 0.8889\n",
      "Epoch 2141/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9443 - val_acc: 0.8889\n",
      "Epoch 2142/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9451 - val_acc: 0.8889\n",
      "Epoch 2143/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9480 - val_acc: 0.8889\n",
      "Epoch 2144/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9492 - val_acc: 0.8889\n",
      "Epoch 2145/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9488 - val_acc: 0.8889\n",
      "Epoch 2146/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9542 - val_acc: 0.8889\n",
      "Epoch 2147/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9552 - val_acc: 0.8889\n",
      "Epoch 2148/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9560 - val_acc: 0.8889\n",
      "Epoch 2149/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9504 - val_acc: 0.8889\n",
      "Epoch 2150/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9525 - val_acc: 0.8889\n",
      "Epoch 2151/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9573 - val_acc: 0.8889\n",
      "Epoch 2152/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9581 - val_acc: 0.8889\n",
      "Epoch 2153/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9564 - val_acc: 0.8889\n",
      "Epoch 2154/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9583 - val_acc: 0.8889\n",
      "Epoch 2155/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9586 - val_acc: 0.8889\n",
      "Epoch 2156/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9544 - val_acc: 0.8889\n",
      "Epoch 2157/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9586 - val_acc: 0.8889\n",
      "Epoch 2158/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9617 - val_acc: 0.8889\n",
      "Epoch 2159/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9608 - val_acc: 0.8889\n",
      "Epoch 2160/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9653 - val_acc: 0.8889\n",
      "Epoch 2161/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9640 - val_acc: 0.8889\n",
      "Epoch 2162/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9670 - val_acc: 0.8889\n",
      "Epoch 2163/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9692 - val_acc: 0.8889\n",
      "Epoch 2164/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9662 - val_acc: 0.8889\n",
      "Epoch 2165/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9721 - val_acc: 0.8889\n",
      "Epoch 2166/10000\n",
      "216/216 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9713 - val_acc: 0.8889\n",
      "Epoch 2167/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9704 - val_acc: 0.8889\n",
      "Epoch 2168/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9739 - val_acc: 0.8889\n",
      "Epoch 2169/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.8889\n",
      "Epoch 2170/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9758 - val_acc: 0.8889\n",
      "Epoch 2171/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9775 - val_acc: 0.8889\n",
      "Epoch 2172/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9788 - val_acc: 0.8889\n",
      "Epoch 2173/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9774 - val_acc: 0.8889\n",
      "Epoch 2174/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9794 - val_acc: 0.8889\n",
      "Epoch 2175/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9804 - val_acc: 0.8889\n",
      "Epoch 2176/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9785 - val_acc: 0.8889\n",
      "Epoch 2177/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9802 - val_acc: 0.8889\n",
      "Epoch 2178/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9870 - val_acc: 0.8889\n",
      "Epoch 2179/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9860 - val_acc: 0.8889\n",
      "Epoch 2180/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9882 - val_acc: 0.8889\n",
      "Epoch 2181/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9860 - val_acc: 0.8889\n",
      "Epoch 2182/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9893 - val_acc: 0.8889\n",
      "Epoch 2183/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9909 - val_acc: 0.8889\n",
      "Epoch 2184/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.8889\n",
      "Epoch 2185/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9858 - val_acc: 0.8889\n",
      "Epoch 2186/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9866 - val_acc: 0.8889\n",
      "Epoch 2187/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.8889\n",
      "Epoch 2188/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9898 - val_acc: 0.8889\n",
      "Epoch 2189/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.8889\n",
      "Epoch 2190/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9927 - val_acc: 0.8889\n",
      "Epoch 2191/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9958 - val_acc: 0.8889\n",
      "Epoch 2192/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9919 - val_acc: 0.8889\n",
      "Epoch 2193/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.8889\n",
      "Epoch 2194/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.8889\n",
      "Epoch 2195/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9990 - val_acc: 0.8889\n",
      "Epoch 2196/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0002 - val_acc: 0.8889\n",
      "Epoch 2197/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9987 - val_acc: 0.8889\n",
      "Epoch 2198/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0022 - val_acc: 0.8889\n",
      "Epoch 2199/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0032 - val_acc: 0.8889\n",
      "Epoch 2200/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0027 - val_acc: 0.8889\n",
      "Epoch 2201/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0065 - val_acc: 0.8889\n",
      "Epoch 2202/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0095 - val_acc: 0.8889\n",
      "Epoch 2203/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0090 - val_acc: 0.8889\n",
      "Epoch 2204/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0119 - val_acc: 0.8889\n",
      "Epoch 2205/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0081 - val_acc: 0.8889\n",
      "Epoch 2206/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0095 - val_acc: 0.8889\n",
      "Epoch 2207/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0107 - val_acc: 0.8889\n",
      "Epoch 2208/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0145 - val_acc: 0.8889\n",
      "Epoch 2209/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0158 - val_acc: 0.8889\n",
      "Epoch 2210/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0177 - val_acc: 0.8889\n",
      "Epoch 2211/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0183 - val_acc: 0.8889\n",
      "Epoch 2212/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0161 - val_acc: 0.8889\n",
      "Epoch 2213/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0198 - val_acc: 0.8889\n",
      "Epoch 2214/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0189 - val_acc: 0.8889\n",
      "Epoch 2215/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0175 - val_acc: 0.8889\n",
      "Epoch 2216/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0217 - val_acc: 0.8889\n",
      "Epoch 2217/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0225 - val_acc: 0.8889\n",
      "Epoch 2218/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0208 - val_acc: 0.8889\n",
      "Epoch 2219/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0213 - val_acc: 0.8889\n",
      "Epoch 2220/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0205 - val_acc: 0.8889\n",
      "Epoch 2221/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0225 - val_acc: 0.8889\n",
      "Epoch 2222/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0237 - val_acc: 0.8889\n",
      "Epoch 2223/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0245 - val_acc: 0.8889\n",
      "Epoch 2224/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0265 - val_acc: 0.8889\n",
      "Epoch 2225/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0274 - val_acc: 0.8889\n",
      "Epoch 2226/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0259 - val_acc: 0.8889\n",
      "Epoch 2227/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0260 - val_acc: 0.8889\n",
      "Epoch 2228/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0317 - val_acc: 0.8889\n",
      "Epoch 2229/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0310 - val_acc: 0.8889\n",
      "Epoch 2230/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0350 - val_acc: 0.8889\n",
      "Epoch 2231/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0308 - val_acc: 0.8889\n",
      "Epoch 2232/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0365 - val_acc: 0.8889\n",
      "Epoch 2233/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0384 - val_acc: 0.8889\n",
      "Epoch 2234/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0365 - val_acc: 0.8889\n",
      "Epoch 2235/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0354 - val_acc: 0.8889\n",
      "Epoch 2236/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0402 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2237/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0384 - val_acc: 0.8889\n",
      "Epoch 2238/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0401 - val_acc: 0.8889\n",
      "Epoch 2239/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0433 - val_acc: 0.8889\n",
      "Epoch 2240/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0371 - val_acc: 0.8889\n",
      "Epoch 2241/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0433 - val_acc: 0.8889\n",
      "Epoch 2242/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0425 - val_acc: 0.8889\n",
      "Epoch 2243/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0444 - val_acc: 0.8889\n",
      "Epoch 2244/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0434 - val_acc: 0.8889\n",
      "Epoch 2245/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0479 - val_acc: 0.8889\n",
      "Epoch 2246/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.8889\n",
      "Epoch 2247/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.8889\n",
      "Epoch 2248/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.8889\n",
      "Epoch 2249/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0472 - val_acc: 0.8889\n",
      "Epoch 2250/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0524 - val_acc: 0.8889\n",
      "Epoch 2251/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0559 - val_acc: 0.8889\n",
      "Epoch 2252/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0520 - val_acc: 0.8889\n",
      "Epoch 2253/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0533 - val_acc: 0.8889\n",
      "Epoch 2254/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0555 - val_acc: 0.8889\n",
      "Epoch 2255/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0565 - val_acc: 0.8889\n",
      "Epoch 2256/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0597 - val_acc: 0.8889\n",
      "Epoch 2257/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0568 - val_acc: 0.8889\n",
      "Epoch 2258/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0623 - val_acc: 0.8889\n",
      "Epoch 2259/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0604 - val_acc: 0.8889\n",
      "Epoch 2260/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0609 - val_acc: 0.8889\n",
      "Epoch 2261/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0603 - val_acc: 0.8889\n",
      "Epoch 2262/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0593 - val_acc: 0.8889\n",
      "Epoch 2263/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0632 - val_acc: 0.8889\n",
      "Epoch 2264/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0622 - val_acc: 0.8889\n",
      "Epoch 2265/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0666 - val_acc: 0.8889\n",
      "Epoch 2266/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0640 - val_acc: 0.8889\n",
      "Epoch 2267/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0648 - val_acc: 0.8889\n",
      "Epoch 2268/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0657 - val_acc: 0.8889\n",
      "Epoch 2269/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0683 - val_acc: 0.8889\n",
      "Epoch 2270/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0657 - val_acc: 0.8889\n",
      "Epoch 2271/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0671 - val_acc: 0.8889\n",
      "Epoch 2272/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0702 - val_acc: 0.8889\n",
      "Epoch 2273/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0752 - val_acc: 0.8889\n",
      "Epoch 2274/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0739 - val_acc: 0.8889\n",
      "Epoch 2275/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0754 - val_acc: 0.8889\n",
      "Epoch 2276/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0726 - val_acc: 0.8889\n",
      "Epoch 2277/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0706 - val_acc: 0.8889\n",
      "Epoch 2278/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0768 - val_acc: 0.8889\n",
      "Epoch 2279/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0728 - val_acc: 0.8889\n",
      "Epoch 2280/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0768 - val_acc: 0.8889\n",
      "Epoch 2281/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0775 - val_acc: 0.8889\n",
      "Epoch 2282/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0788 - val_acc: 0.8889\n",
      "Epoch 2283/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0801 - val_acc: 0.8889\n",
      "Epoch 2284/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0822 - val_acc: 0.8889\n",
      "Epoch 2285/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0833 - val_acc: 0.8889\n",
      "Epoch 2286/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0805 - val_acc: 0.8889\n",
      "Epoch 2287/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0818 - val_acc: 0.8889\n",
      "Epoch 2288/10000\n",
      "216/216 [==============================] - 0s 213us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0874 - val_acc: 0.8889\n",
      "Epoch 2289/10000\n",
      "216/216 [==============================] - 0s 222us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0863 - val_acc: 0.8889\n",
      "Epoch 2290/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0889 - val_acc: 0.8889\n",
      "Epoch 2291/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0903 - val_acc: 0.8889\n",
      "Epoch 2292/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0871 - val_acc: 0.8889\n",
      "Epoch 2293/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0872 - val_acc: 0.8889\n",
      "Epoch 2294/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0898 - val_acc: 0.8889\n",
      "Epoch 2295/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0890 - val_acc: 0.8889\n",
      "Epoch 2296/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0944 - val_acc: 0.8889\n",
      "Epoch 2297/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0898 - val_acc: 0.8889\n",
      "Epoch 2298/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0912 - val_acc: 0.8889\n",
      "Epoch 2299/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0937 - val_acc: 0.8889\n",
      "Epoch 2300/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0901 - val_acc: 0.8889\n",
      "Epoch 2301/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0983 - val_acc: 0.8889\n",
      "Epoch 2302/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0985 - val_acc: 0.8889\n",
      "Epoch 2303/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0927 - val_acc: 0.8889\n",
      "Epoch 2304/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0924 - val_acc: 0.8889\n",
      "Epoch 2305/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0968 - val_acc: 0.8889\n",
      "Epoch 2306/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.0967 - val_acc: 0.8889\n",
      "Epoch 2307/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.0996 - val_acc: 0.8889\n",
      "Epoch 2308/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1058 - val_acc: 0.8889\n",
      "Epoch 2309/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1007 - val_acc: 0.8889\n",
      "Epoch 2310/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1039 - val_acc: 0.8889\n",
      "Epoch 2311/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1018 - val_acc: 0.8889\n",
      "Epoch 2312/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1013 - val_acc: 0.8889\n",
      "Epoch 2313/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1029 - val_acc: 0.8889\n",
      "Epoch 2314/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1083 - val_acc: 0.8889\n",
      "Epoch 2315/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1103 - val_acc: 0.8889\n",
      "Epoch 2316/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.9922e-04 - acc: 1.0000 - val_loss: 1.1096 - val_acc: 0.8889\n",
      "Epoch 2317/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.9453e-04 - acc: 1.0000 - val_loss: 1.1122 - val_acc: 0.8889\n",
      "Epoch 2318/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.8992e-04 - acc: 1.0000 - val_loss: 1.1079 - val_acc: 0.8889\n",
      "Epoch 2319/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.8498e-04 - acc: 1.0000 - val_loss: 1.1098 - val_acc: 0.8889\n",
      "Epoch 2320/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 9.7858e-04 - acc: 1.0000 - val_loss: 1.1115 - val_acc: 0.8889\n",
      "Epoch 2321/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 9.7323e-04 - acc: 1.0000 - val_loss: 1.1130 - val_acc: 0.8889\n",
      "Epoch 2322/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.6885e-04 - acc: 1.0000 - val_loss: 1.1117 - val_acc: 0.8889\n",
      "Epoch 2323/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.6320e-04 - acc: 1.0000 - val_loss: 1.1102 - val_acc: 0.8889\n",
      "Epoch 2324/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.6745e-04 - acc: 1.0000 - val_loss: 1.1175 - val_acc: 0.8889\n",
      "Epoch 2325/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.5461e-04 - acc: 1.0000 - val_loss: 1.1188 - val_acc: 0.8889\n",
      "Epoch 2326/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.5201e-04 - acc: 1.0000 - val_loss: 1.1165 - val_acc: 0.8889\n",
      "Epoch 2327/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.4845e-04 - acc: 1.0000 - val_loss: 1.1170 - val_acc: 0.8889\n",
      "Epoch 2328/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.4258e-04 - acc: 1.0000 - val_loss: 1.1162 - val_acc: 0.8889\n",
      "Epoch 2329/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 9.3830e-04 - acc: 1.0000 - val_loss: 1.1204 - val_acc: 0.8889\n",
      "Epoch 2330/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.3317e-04 - acc: 1.0000 - val_loss: 1.1239 - val_acc: 0.8889\n",
      "Epoch 2331/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.2891e-04 - acc: 1.0000 - val_loss: 1.1196 - val_acc: 0.8889\n",
      "Epoch 2332/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.1963e-04 - acc: 1.0000 - val_loss: 1.1212 - val_acc: 0.8889\n",
      "Epoch 2333/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 9.1819e-04 - acc: 1.0000 - val_loss: 1.1213 - val_acc: 0.8889\n",
      "Epoch 2334/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.1313e-04 - acc: 1.0000 - val_loss: 1.1219 - val_acc: 0.8889\n",
      "Epoch 2335/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.0547e-04 - acc: 1.0000 - val_loss: 1.1209 - val_acc: 0.8889\n",
      "Epoch 2336/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.0131e-04 - acc: 1.0000 - val_loss: 1.1202 - val_acc: 0.8889\n",
      "Epoch 2337/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.0135e-04 - acc: 1.0000 - val_loss: 1.1218 - val_acc: 0.8889\n",
      "Epoch 2338/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 8.9408e-04 - acc: 1.0000 - val_loss: 1.1257 - val_acc: 0.8889\n",
      "Epoch 2339/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.9073e-04 - acc: 1.0000 - val_loss: 1.1242 - val_acc: 0.8889\n",
      "Epoch 2340/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.8562e-04 - acc: 1.0000 - val_loss: 1.1235 - val_acc: 0.8889\n",
      "Epoch 2341/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.7991e-04 - acc: 1.0000 - val_loss: 1.1236 - val_acc: 0.8889\n",
      "Epoch 2342/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 8.7695e-04 - acc: 1.0000 - val_loss: 1.1259 - val_acc: 0.8889\n",
      "Epoch 2343/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.7095e-04 - acc: 1.0000 - val_loss: 1.1289 - val_acc: 0.8889\n",
      "Epoch 2344/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.6851e-04 - acc: 1.0000 - val_loss: 1.1285 - val_acc: 0.8889\n",
      "Epoch 2345/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.6209e-04 - acc: 1.0000 - val_loss: 1.1275 - val_acc: 0.8889\n",
      "Epoch 2346/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 8.6203e-04 - acc: 1.0000 - val_loss: 1.1285 - val_acc: 0.8889\n",
      "Epoch 2347/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 8.5483e-04 - acc: 1.0000 - val_loss: 1.1295 - val_acc: 0.8889\n",
      "Epoch 2348/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 8.4999e-04 - acc: 1.0000 - val_loss: 1.1301 - val_acc: 0.8889\n",
      "Epoch 2349/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 8.4564e-04 - acc: 1.0000 - val_loss: 1.1265 - val_acc: 0.8889\n",
      "Epoch 2350/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 8.4006e-04 - acc: 1.0000 - val_loss: 1.1336 - val_acc: 0.8889\n",
      "Epoch 2351/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.3838e-04 - acc: 1.0000 - val_loss: 1.1361 - val_acc: 0.8889\n",
      "Epoch 2352/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 8.3168e-04 - acc: 1.0000 - val_loss: 1.1316 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2353/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.3371e-04 - acc: 1.0000 - val_loss: 1.1320 - val_acc: 0.8889\n",
      "Epoch 2354/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 8.2315e-04 - acc: 1.0000 - val_loss: 1.1344 - val_acc: 0.8889\n",
      "Epoch 2355/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 8.2017e-04 - acc: 1.0000 - val_loss: 1.1379 - val_acc: 0.8889\n",
      "Epoch 2356/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 8.1601e-04 - acc: 1.0000 - val_loss: 1.1381 - val_acc: 0.8889\n",
      "Epoch 2357/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 8.1100e-04 - acc: 1.0000 - val_loss: 1.1368 - val_acc: 0.8889\n",
      "Epoch 2358/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 8.0914e-04 - acc: 1.0000 - val_loss: 1.1355 - val_acc: 0.8889\n",
      "Epoch 2359/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 8.0324e-04 - acc: 1.0000 - val_loss: 1.1317 - val_acc: 0.8889\n",
      "Epoch 2360/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.0003e-04 - acc: 1.0000 - val_loss: 1.1341 - val_acc: 0.8889\n",
      "Epoch 2361/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.9788e-04 - acc: 1.0000 - val_loss: 1.1403 - val_acc: 0.8889\n",
      "Epoch 2362/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.9163e-04 - acc: 1.0000 - val_loss: 1.1402 - val_acc: 0.8889\n",
      "Epoch 2363/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 7.8856e-04 - acc: 1.0000 - val_loss: 1.1413 - val_acc: 0.8889\n",
      "Epoch 2364/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 7.8445e-04 - acc: 1.0000 - val_loss: 1.1427 - val_acc: 0.8889\n",
      "Epoch 2365/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.8232e-04 - acc: 1.0000 - val_loss: 1.1408 - val_acc: 0.8889\n",
      "Epoch 2366/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.7470e-04 - acc: 1.0000 - val_loss: 1.1417 - val_acc: 0.8889\n",
      "Epoch 2367/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.7147e-04 - acc: 1.0000 - val_loss: 1.1425 - val_acc: 0.8889\n",
      "Epoch 2368/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.6652e-04 - acc: 1.0000 - val_loss: 1.1462 - val_acc: 0.8889\n",
      "Epoch 2369/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 7.6388e-04 - acc: 1.0000 - val_loss: 1.1408 - val_acc: 0.8889\n",
      "Epoch 2370/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 7.5763e-04 - acc: 1.0000 - val_loss: 1.1434 - val_acc: 0.8889\n",
      "Epoch 2371/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 7.5618e-04 - acc: 1.0000 - val_loss: 1.1473 - val_acc: 0.8889\n",
      "Epoch 2372/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.5022e-04 - acc: 1.0000 - val_loss: 1.1474 - val_acc: 0.8889\n",
      "Epoch 2373/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.4848e-04 - acc: 1.0000 - val_loss: 1.1510 - val_acc: 0.8889\n",
      "Epoch 2374/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.4162e-04 - acc: 1.0000 - val_loss: 1.1456 - val_acc: 0.8889\n",
      "Epoch 2375/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 7.4246e-04 - acc: 1.0000 - val_loss: 1.1528 - val_acc: 0.8889\n",
      "Epoch 2376/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 7.3648e-04 - acc: 1.0000 - val_loss: 1.1538 - val_acc: 0.8889\n",
      "Epoch 2377/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.3344e-04 - acc: 1.0000 - val_loss: 1.1530 - val_acc: 0.8889\n",
      "Epoch 2378/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.2859e-04 - acc: 1.0000 - val_loss: 1.1546 - val_acc: 0.8889\n",
      "Epoch 2379/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.2487e-04 - acc: 1.0000 - val_loss: 1.1543 - val_acc: 0.8889\n",
      "Epoch 2380/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 7.2383e-04 - acc: 1.0000 - val_loss: 1.1554 - val_acc: 0.8889\n",
      "Epoch 2381/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.1925e-04 - acc: 1.0000 - val_loss: 1.1542 - val_acc: 0.8889\n",
      "Epoch 2382/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.1428e-04 - acc: 1.0000 - val_loss: 1.1535 - val_acc: 0.8889\n",
      "Epoch 2383/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.0992e-04 - acc: 1.0000 - val_loss: 1.1519 - val_acc: 0.8889\n",
      "Epoch 2384/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 7.0903e-04 - acc: 1.0000 - val_loss: 1.1588 - val_acc: 0.8889\n",
      "Epoch 2385/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 7.0217e-04 - acc: 1.0000 - val_loss: 1.1580 - val_acc: 0.8889\n",
      "Epoch 2386/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.9966e-04 - acc: 1.0000 - val_loss: 1.1574 - val_acc: 0.8889\n",
      "Epoch 2387/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.9909e-04 - acc: 1.0000 - val_loss: 1.1618 - val_acc: 0.8889\n",
      "Epoch 2388/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.9192e-04 - acc: 1.0000 - val_loss: 1.1628 - val_acc: 0.8889\n",
      "Epoch 2389/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.8978e-04 - acc: 1.0000 - val_loss: 1.1631 - val_acc: 0.8889\n",
      "Epoch 2390/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.8524e-04 - acc: 1.0000 - val_loss: 1.1606 - val_acc: 0.8889\n",
      "Epoch 2391/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.8261e-04 - acc: 1.0000 - val_loss: 1.1614 - val_acc: 0.8889\n",
      "Epoch 2392/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.7894e-04 - acc: 1.0000 - val_loss: 1.1658 - val_acc: 0.8889\n",
      "Epoch 2393/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 6.7332e-04 - acc: 1.0000 - val_loss: 1.1650 - val_acc: 0.8889\n",
      "Epoch 2394/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.6837e-04 - acc: 1.0000 - val_loss: 1.1604 - val_acc: 0.8889\n",
      "Epoch 2395/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 6.6761e-04 - acc: 1.0000 - val_loss: 1.1631 - val_acc: 0.8889\n",
      "Epoch 2396/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.6183e-04 - acc: 1.0000 - val_loss: 1.1591 - val_acc: 0.8889\n",
      "Epoch 2397/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.5982e-04 - acc: 1.0000 - val_loss: 1.1633 - val_acc: 0.8889\n",
      "Epoch 2398/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.5660e-04 - acc: 1.0000 - val_loss: 1.1665 - val_acc: 0.8889\n",
      "Epoch 2399/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.5383e-04 - acc: 1.0000 - val_loss: 1.1709 - val_acc: 0.8889\n",
      "Epoch 2400/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.4946e-04 - acc: 1.0000 - val_loss: 1.1696 - val_acc: 0.8889\n",
      "Epoch 2401/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.4491e-04 - acc: 1.0000 - val_loss: 1.1754 - val_acc: 0.8889\n",
      "Epoch 2402/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.4135e-04 - acc: 1.0000 - val_loss: 1.1691 - val_acc: 0.8889\n",
      "Epoch 2403/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.4076e-04 - acc: 1.0000 - val_loss: 1.1691 - val_acc: 0.8889\n",
      "Epoch 2404/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 6.3481e-04 - acc: 1.0000 - val_loss: 1.1735 - val_acc: 0.8889\n",
      "Epoch 2405/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 6.3016e-04 - acc: 1.0000 - val_loss: 1.1722 - val_acc: 0.8889\n",
      "Epoch 2406/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.3023e-04 - acc: 1.0000 - val_loss: 1.1716 - val_acc: 0.8889\n",
      "Epoch 2407/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 6.2511e-04 - acc: 1.0000 - val_loss: 1.1760 - val_acc: 0.8889\n",
      "Epoch 2408/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 6.2237e-04 - acc: 1.0000 - val_loss: 1.1744 - val_acc: 0.8889\n",
      "Epoch 2409/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 6.1868e-04 - acc: 1.0000 - val_loss: 1.1753 - val_acc: 0.8889\n",
      "Epoch 2410/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 157us/step - loss: 6.1494e-04 - acc: 1.0000 - val_loss: 1.1767 - val_acc: 0.8889\n",
      "Epoch 2411/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 6.1355e-04 - acc: 1.0000 - val_loss: 1.1785 - val_acc: 0.8889\n",
      "Epoch 2412/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 6.0736e-04 - acc: 1.0000 - val_loss: 1.1766 - val_acc: 0.8889\n",
      "Epoch 2413/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.0584e-04 - acc: 1.0000 - val_loss: 1.1743 - val_acc: 0.8889\n",
      "Epoch 2414/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 6.0241e-04 - acc: 1.0000 - val_loss: 1.1737 - val_acc: 0.8889\n",
      "Epoch 2415/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 5.9822e-04 - acc: 1.0000 - val_loss: 1.1761 - val_acc: 0.8889\n",
      "Epoch 2416/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 5.9544e-04 - acc: 1.0000 - val_loss: 1.1754 - val_acc: 0.8889\n",
      "Epoch 2417/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 5.9190e-04 - acc: 1.0000 - val_loss: 1.1797 - val_acc: 0.8889\n",
      "Epoch 2418/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 5.8901e-04 - acc: 1.0000 - val_loss: 1.1797 - val_acc: 0.8889\n",
      "Epoch 2419/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 5.8561e-04 - acc: 1.0000 - val_loss: 1.1789 - val_acc: 0.8889\n",
      "Epoch 2420/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.8290e-04 - acc: 1.0000 - val_loss: 1.1852 - val_acc: 0.8889\n",
      "Epoch 2421/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 5.7959e-04 - acc: 1.0000 - val_loss: 1.1799 - val_acc: 0.8889\n",
      "Epoch 2422/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.7909e-04 - acc: 1.0000 - val_loss: 1.1799 - val_acc: 0.8889\n",
      "Epoch 2423/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.7284e-04 - acc: 1.0000 - val_loss: 1.1780 - val_acc: 0.8889\n",
      "Epoch 2424/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.6997e-04 - acc: 1.0000 - val_loss: 1.1834 - val_acc: 0.8889\n",
      "Epoch 2425/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.6795e-04 - acc: 1.0000 - val_loss: 1.1855 - val_acc: 0.8889\n",
      "Epoch 2426/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.6340e-04 - acc: 1.0000 - val_loss: 1.1898 - val_acc: 0.8889\n",
      "Epoch 2427/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.6085e-04 - acc: 1.0000 - val_loss: 1.1855 - val_acc: 0.8889\n",
      "Epoch 2428/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.5798e-04 - acc: 1.0000 - val_loss: 1.1871 - val_acc: 0.8889\n",
      "Epoch 2429/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.5424e-04 - acc: 1.0000 - val_loss: 1.1839 - val_acc: 0.8889\n",
      "Epoch 2430/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.5537e-04 - acc: 1.0000 - val_loss: 1.1901 - val_acc: 0.8889\n",
      "Epoch 2431/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 5.4848e-04 - acc: 1.0000 - val_loss: 1.1926 - val_acc: 0.8889\n",
      "Epoch 2432/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 5.4669e-04 - acc: 1.0000 - val_loss: 1.1902 - val_acc: 0.8889\n",
      "Epoch 2433/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.4195e-04 - acc: 1.0000 - val_loss: 1.1883 - val_acc: 0.8889\n",
      "Epoch 2434/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.3914e-04 - acc: 1.0000 - val_loss: 1.1925 - val_acc: 0.8889\n",
      "Epoch 2435/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.3778e-04 - acc: 1.0000 - val_loss: 1.1965 - val_acc: 0.8889\n",
      "Epoch 2436/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 5.3316e-04 - acc: 1.0000 - val_loss: 1.1981 - val_acc: 0.8889\n",
      "Epoch 2437/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.3182e-04 - acc: 1.0000 - val_loss: 1.1922 - val_acc: 0.8889\n",
      "Epoch 2438/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 5.2875e-04 - acc: 1.0000 - val_loss: 1.1908 - val_acc: 0.8889\n",
      "Epoch 2439/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.2517e-04 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.8889\n",
      "Epoch 2440/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 5.2158e-04 - acc: 1.0000 - val_loss: 1.1967 - val_acc: 0.8889\n",
      "Epoch 2441/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.1954e-04 - acc: 1.0000 - val_loss: 1.1953 - val_acc: 0.8889\n",
      "Epoch 2442/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.1703e-04 - acc: 1.0000 - val_loss: 1.1947 - val_acc: 0.8889\n",
      "Epoch 2443/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.1392e-04 - acc: 1.0000 - val_loss: 1.2007 - val_acc: 0.8889\n",
      "Epoch 2444/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.1143e-04 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.8889\n",
      "Epoch 2445/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 5.0982e-04 - acc: 1.0000 - val_loss: 1.1996 - val_acc: 0.8889\n",
      "Epoch 2446/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 5.0592e-04 - acc: 1.0000 - val_loss: 1.1975 - val_acc: 0.8889\n",
      "Epoch 2447/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 5.0218e-04 - acc: 1.0000 - val_loss: 1.2038 - val_acc: 0.8889\n",
      "Epoch 2448/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.0103e-04 - acc: 1.0000 - val_loss: 1.1964 - val_acc: 0.8889\n",
      "Epoch 2449/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 4.9835e-04 - acc: 1.0000 - val_loss: 1.1978 - val_acc: 0.8889\n",
      "Epoch 2450/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 4.9459e-04 - acc: 1.0000 - val_loss: 1.2029 - val_acc: 0.8889\n",
      "Epoch 2451/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.9424e-04 - acc: 1.0000 - val_loss: 1.2006 - val_acc: 0.8889\n",
      "Epoch 2452/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.8878e-04 - acc: 1.0000 - val_loss: 1.2032 - val_acc: 0.8889\n",
      "Epoch 2453/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.8675e-04 - acc: 1.0000 - val_loss: 1.1999 - val_acc: 0.8889\n",
      "Epoch 2454/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 4.8542e-04 - acc: 1.0000 - val_loss: 1.2032 - val_acc: 0.8889\n",
      "Epoch 2455/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 4.8241e-04 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.8889\n",
      "Epoch 2456/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.7903e-04 - acc: 1.0000 - val_loss: 1.2047 - val_acc: 0.8889\n",
      "Epoch 2457/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.7772e-04 - acc: 1.0000 - val_loss: 1.2120 - val_acc: 0.8889\n",
      "Epoch 2458/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.7466e-04 - acc: 1.0000 - val_loss: 1.2081 - val_acc: 0.8889\n",
      "Epoch 2459/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.7181e-04 - acc: 1.0000 - val_loss: 1.2125 - val_acc: 0.8889\n",
      "Epoch 2460/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.7026e-04 - acc: 1.0000 - val_loss: 1.2098 - val_acc: 0.8889\n",
      "Epoch 2461/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.6622e-04 - acc: 1.0000 - val_loss: 1.2134 - val_acc: 0.8889\n",
      "Epoch 2462/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.6464e-04 - acc: 1.0000 - val_loss: 1.2112 - val_acc: 0.8889\n",
      "Epoch 2463/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.6309e-04 - acc: 1.0000 - val_loss: 1.2087 - val_acc: 0.8889\n",
      "Epoch 2464/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.5910e-04 - acc: 1.0000 - val_loss: 1.2122 - val_acc: 0.8889\n",
      "Epoch 2465/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 4.5762e-04 - acc: 1.0000 - val_loss: 1.2157 - val_acc: 0.8889\n",
      "Epoch 2466/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.5524e-04 - acc: 1.0000 - val_loss: 1.2149 - val_acc: 0.8889\n",
      "Epoch 2467/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 97us/step - loss: 4.5179e-04 - acc: 1.0000 - val_loss: 1.2149 - val_acc: 0.8889\n",
      "Epoch 2468/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.4959e-04 - acc: 1.0000 - val_loss: 1.2119 - val_acc: 0.8889\n",
      "Epoch 2469/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 4.4686e-04 - acc: 1.0000 - val_loss: 1.2174 - val_acc: 0.8889\n",
      "Epoch 2470/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.4366e-04 - acc: 1.0000 - val_loss: 1.2182 - val_acc: 0.8889\n",
      "Epoch 2471/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.4220e-04 - acc: 1.0000 - val_loss: 1.2185 - val_acc: 0.8889\n",
      "Epoch 2472/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 4.3996e-04 - acc: 1.0000 - val_loss: 1.2151 - val_acc: 0.8889\n",
      "Epoch 2473/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.3687e-04 - acc: 1.0000 - val_loss: 1.2215 - val_acc: 0.8889\n",
      "Epoch 2474/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 4.3556e-04 - acc: 1.0000 - val_loss: 1.2206 - val_acc: 0.8889\n",
      "Epoch 2475/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.3259e-04 - acc: 1.0000 - val_loss: 1.2217 - val_acc: 0.8889\n",
      "Epoch 2476/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.2997e-04 - acc: 1.0000 - val_loss: 1.2164 - val_acc: 0.8889\n",
      "Epoch 2477/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.2781e-04 - acc: 1.0000 - val_loss: 1.2245 - val_acc: 0.8889\n",
      "Epoch 2478/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.2474e-04 - acc: 1.0000 - val_loss: 1.2232 - val_acc: 0.8889\n",
      "Epoch 2479/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.2339e-04 - acc: 1.0000 - val_loss: 1.2237 - val_acc: 0.8889\n",
      "Epoch 2480/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.2208e-04 - acc: 1.0000 - val_loss: 1.2218 - val_acc: 0.8889\n",
      "Epoch 2481/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.1877e-04 - acc: 1.0000 - val_loss: 1.2261 - val_acc: 0.8889\n",
      "Epoch 2482/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.1645e-04 - acc: 1.0000 - val_loss: 1.2252 - val_acc: 0.8889\n",
      "Epoch 2483/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.1457e-04 - acc: 1.0000 - val_loss: 1.2237 - val_acc: 0.8889\n",
      "Epoch 2484/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.1177e-04 - acc: 1.0000 - val_loss: 1.2230 - val_acc: 0.8889\n",
      "Epoch 2485/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.1048e-04 - acc: 1.0000 - val_loss: 1.2262 - val_acc: 0.8889\n",
      "Epoch 2486/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.0711e-04 - acc: 1.0000 - val_loss: 1.2286 - val_acc: 0.8889\n",
      "Epoch 2487/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.0588e-04 - acc: 1.0000 - val_loss: 1.2284 - val_acc: 0.8889\n",
      "Epoch 2488/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 4.0430e-04 - acc: 1.0000 - val_loss: 1.2287 - val_acc: 0.8889\n",
      "Epoch 2489/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.0091e-04 - acc: 1.0000 - val_loss: 1.2308 - val_acc: 0.8889\n",
      "Epoch 2490/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.9993e-04 - acc: 1.0000 - val_loss: 1.2310 - val_acc: 0.8889\n",
      "Epoch 2491/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.9699e-04 - acc: 1.0000 - val_loss: 1.2310 - val_acc: 0.8889\n",
      "Epoch 2492/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.9518e-04 - acc: 1.0000 - val_loss: 1.2261 - val_acc: 0.8889\n",
      "Epoch 2493/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.9291e-04 - acc: 1.0000 - val_loss: 1.2279 - val_acc: 0.8889\n",
      "Epoch 2494/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.9131e-04 - acc: 1.0000 - val_loss: 1.2322 - val_acc: 0.8889\n",
      "Epoch 2495/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.8874e-04 - acc: 1.0000 - val_loss: 1.2300 - val_acc: 0.8889\n",
      "Epoch 2496/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.8666e-04 - acc: 1.0000 - val_loss: 1.2305 - val_acc: 0.8889\n",
      "Epoch 2497/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.8424e-04 - acc: 1.0000 - val_loss: 1.2352 - val_acc: 0.8889\n",
      "Epoch 2498/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.8217e-04 - acc: 1.0000 - val_loss: 1.2301 - val_acc: 0.8889\n",
      "Epoch 2499/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.7957e-04 - acc: 1.0000 - val_loss: 1.2346 - val_acc: 0.8889\n",
      "Epoch 2500/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.7844e-04 - acc: 1.0000 - val_loss: 1.2375 - val_acc: 0.8889\n",
      "Epoch 2501/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.7577e-04 - acc: 1.0000 - val_loss: 1.2344 - val_acc: 0.8889\n",
      "Epoch 2502/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.7452e-04 - acc: 1.0000 - val_loss: 1.2359 - val_acc: 0.8889\n",
      "Epoch 2503/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.7401e-04 - acc: 1.0000 - val_loss: 1.2367 - val_acc: 0.8889\n",
      "Epoch 2504/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.6978e-04 - acc: 1.0000 - val_loss: 1.2371 - val_acc: 0.8889\n",
      "Epoch 2505/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.6745e-04 - acc: 1.0000 - val_loss: 1.2339 - val_acc: 0.8889\n",
      "Epoch 2506/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6682e-04 - acc: 1.0000 - val_loss: 1.2406 - val_acc: 0.8889\n",
      "Epoch 2507/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.6401e-04 - acc: 1.0000 - val_loss: 1.2405 - val_acc: 0.8889\n",
      "Epoch 2508/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6242e-04 - acc: 1.0000 - val_loss: 1.2399 - val_acc: 0.8889\n",
      "Epoch 2509/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6079e-04 - acc: 1.0000 - val_loss: 1.2384 - val_acc: 0.8889\n",
      "Epoch 2510/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.5873e-04 - acc: 1.0000 - val_loss: 1.2397 - val_acc: 0.8889\n",
      "Epoch 2511/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.5678e-04 - acc: 1.0000 - val_loss: 1.2356 - val_acc: 0.8889\n",
      "Epoch 2512/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.5496e-04 - acc: 1.0000 - val_loss: 1.2402 - val_acc: 0.8889\n",
      "Epoch 2513/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.5300e-04 - acc: 1.0000 - val_loss: 1.2446 - val_acc: 0.8889\n",
      "Epoch 2514/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.5087e-04 - acc: 1.0000 - val_loss: 1.2418 - val_acc: 0.8889\n",
      "Epoch 2515/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.4887e-04 - acc: 1.0000 - val_loss: 1.2429 - val_acc: 0.8889\n",
      "Epoch 2516/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.4767e-04 - acc: 1.0000 - val_loss: 1.2459 - val_acc: 0.8889\n",
      "Epoch 2517/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.4531e-04 - acc: 1.0000 - val_loss: 1.2460 - val_acc: 0.8889\n",
      "Epoch 2518/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.4380e-04 - acc: 1.0000 - val_loss: 1.2471 - val_acc: 0.8889\n",
      "Epoch 2519/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.4172e-04 - acc: 1.0000 - val_loss: 1.2462 - val_acc: 0.8889\n",
      "Epoch 2520/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.3988e-04 - acc: 1.0000 - val_loss: 1.2468 - val_acc: 0.8889\n",
      "Epoch 2521/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.3851e-04 - acc: 1.0000 - val_loss: 1.2463 - val_acc: 0.8889\n",
      "Epoch 2522/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.3593e-04 - acc: 1.0000 - val_loss: 1.2477 - val_acc: 0.8889\n",
      "Epoch 2523/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.3409e-04 - acc: 1.0000 - val_loss: 1.2501 - val_acc: 0.8889\n",
      "Epoch 2524/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.3226e-04 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.8889\n",
      "Epoch 2525/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 3.2997e-04 - acc: 1.0000 - val_loss: 1.2473 - val_acc: 0.8889\n",
      "Epoch 2526/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.2962e-04 - acc: 1.0000 - val_loss: 1.2484 - val_acc: 0.8889\n",
      "Epoch 2527/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.2625e-04 - acc: 1.0000 - val_loss: 1.2507 - val_acc: 0.8889\n",
      "Epoch 2528/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.2604e-04 - acc: 1.0000 - val_loss: 1.2497 - val_acc: 0.8889\n",
      "Epoch 2529/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 3.2347e-04 - acc: 1.0000 - val_loss: 1.2482 - val_acc: 0.8889\n",
      "Epoch 2530/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.2143e-04 - acc: 1.0000 - val_loss: 1.2490 - val_acc: 0.8889\n",
      "Epoch 2531/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2041e-04 - acc: 1.0000 - val_loss: 1.2497 - val_acc: 0.8889\n",
      "Epoch 2532/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.1949e-04 - acc: 1.0000 - val_loss: 1.2509 - val_acc: 0.8889\n",
      "Epoch 2533/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.1643e-04 - acc: 1.0000 - val_loss: 1.2514 - val_acc: 0.8889\n",
      "Epoch 2534/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1513e-04 - acc: 1.0000 - val_loss: 1.2496 - val_acc: 0.8889\n",
      "Epoch 2535/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1361e-04 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.8889\n",
      "Epoch 2536/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.1208e-04 - acc: 1.0000 - val_loss: 1.2483 - val_acc: 0.8889\n",
      "Epoch 2537/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.1009e-04 - acc: 1.0000 - val_loss: 1.2510 - val_acc: 0.8889\n",
      "Epoch 2538/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.0918e-04 - acc: 1.0000 - val_loss: 1.2521 - val_acc: 0.8889\n",
      "Epoch 2539/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.0767e-04 - acc: 1.0000 - val_loss: 1.2529 - val_acc: 0.8889\n",
      "Epoch 2540/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.0561e-04 - acc: 1.0000 - val_loss: 1.2546 - val_acc: 0.8889\n",
      "Epoch 2541/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.0378e-04 - acc: 1.0000 - val_loss: 1.2554 - val_acc: 0.8889\n",
      "Epoch 2542/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.0196e-04 - acc: 1.0000 - val_loss: 1.2566 - val_acc: 0.8889\n",
      "Epoch 2543/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.0072e-04 - acc: 1.0000 - val_loss: 1.2544 - val_acc: 0.8889\n",
      "Epoch 2544/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 2.9951e-04 - acc: 1.0000 - val_loss: 1.2561 - val_acc: 0.8889\n",
      "Epoch 2545/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 2.9775e-04 - acc: 1.0000 - val_loss: 1.2560 - val_acc: 0.8889\n",
      "Epoch 2546/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 2.9610e-04 - acc: 1.0000 - val_loss: 1.2582 - val_acc: 0.8889\n",
      "Epoch 2547/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 2.9459e-04 - acc: 1.0000 - val_loss: 1.2601 - val_acc: 0.8889\n",
      "Epoch 2548/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 2.9288e-04 - acc: 1.0000 - val_loss: 1.2580 - val_acc: 0.8889\n",
      "Epoch 2549/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.9180e-04 - acc: 1.0000 - val_loss: 1.2582 - val_acc: 0.8889\n",
      "Epoch 2550/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.8973e-04 - acc: 1.0000 - val_loss: 1.2591 - val_acc: 0.8889\n",
      "Epoch 2551/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.8807e-04 - acc: 1.0000 - val_loss: 1.2632 - val_acc: 0.8889\n",
      "Epoch 2552/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 2.8610e-04 - acc: 1.0000 - val_loss: 1.2633 - val_acc: 0.8889\n",
      "Epoch 2553/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.8498e-04 - acc: 1.0000 - val_loss: 1.2589 - val_acc: 0.8889\n",
      "Epoch 2554/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 2.8383e-04 - acc: 1.0000 - val_loss: 1.2607 - val_acc: 0.8889\n",
      "Epoch 2555/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.8120e-04 - acc: 1.0000 - val_loss: 1.2613 - val_acc: 0.8889\n",
      "Epoch 2556/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 2.8100e-04 - acc: 1.0000 - val_loss: 1.2648 - val_acc: 0.8889\n",
      "Epoch 2557/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.7905e-04 - acc: 1.0000 - val_loss: 1.2616 - val_acc: 0.8889\n",
      "Epoch 2558/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.7797e-04 - acc: 1.0000 - val_loss: 1.2637 - val_acc: 0.8889\n",
      "Epoch 2559/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.7727e-04 - acc: 1.0000 - val_loss: 1.2636 - val_acc: 0.8889\n",
      "Epoch 2560/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.7465e-04 - acc: 1.0000 - val_loss: 1.2625 - val_acc: 0.8889\n",
      "Epoch 2561/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 2.7364e-04 - acc: 1.0000 - val_loss: 1.2625 - val_acc: 0.8889\n",
      "Epoch 2562/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.7157e-04 - acc: 1.0000 - val_loss: 1.2611 - val_acc: 0.8889\n",
      "Epoch 2563/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.7065e-04 - acc: 1.0000 - val_loss: 1.2627 - val_acc: 0.8889\n",
      "Epoch 2564/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.6862e-04 - acc: 1.0000 - val_loss: 1.2615 - val_acc: 0.8889\n",
      "Epoch 2565/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.6746e-04 - acc: 1.0000 - val_loss: 1.2628 - val_acc: 0.8889\n",
      "Epoch 2566/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.6679e-04 - acc: 1.0000 - val_loss: 1.2633 - val_acc: 0.8889\n",
      "Epoch 2567/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.6473e-04 - acc: 1.0000 - val_loss: 1.2640 - val_acc: 0.8889\n",
      "Epoch 2568/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.6342e-04 - acc: 1.0000 - val_loss: 1.2644 - val_acc: 0.8889\n",
      "Epoch 2569/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.6188e-04 - acc: 1.0000 - val_loss: 1.2674 - val_acc: 0.8889\n",
      "Epoch 2570/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.6109e-04 - acc: 1.0000 - val_loss: 1.2675 - val_acc: 0.8889\n",
      "Epoch 2571/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5939e-04 - acc: 1.0000 - val_loss: 1.2663 - val_acc: 0.8889\n",
      "Epoch 2572/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5790e-04 - acc: 1.0000 - val_loss: 1.2680 - val_acc: 0.8889\n",
      "Epoch 2573/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.5663e-04 - acc: 1.0000 - val_loss: 1.2665 - val_acc: 0.8889\n",
      "Epoch 2574/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.5497e-04 - acc: 1.0000 - val_loss: 1.2719 - val_acc: 0.8889\n",
      "Epoch 2575/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.5419e-04 - acc: 1.0000 - val_loss: 1.2695 - val_acc: 0.8889\n",
      "Epoch 2576/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5306e-04 - acc: 1.0000 - val_loss: 1.2683 - val_acc: 0.8889\n",
      "Epoch 2577/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5163e-04 - acc: 1.0000 - val_loss: 1.2697 - val_acc: 0.8889\n",
      "Epoch 2578/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.4962e-04 - acc: 1.0000 - val_loss: 1.2736 - val_acc: 0.8889\n",
      "Epoch 2579/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4890e-04 - acc: 1.0000 - val_loss: 1.2722 - val_acc: 0.8889\n",
      "Epoch 2580/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4701e-04 - acc: 1.0000 - val_loss: 1.2718 - val_acc: 0.8889\n",
      "Epoch 2581/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 97us/step - loss: 2.4633e-04 - acc: 1.0000 - val_loss: 1.2708 - val_acc: 0.8889\n",
      "Epoch 2582/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.4485e-04 - acc: 1.0000 - val_loss: 1.2723 - val_acc: 0.8889\n",
      "Epoch 2583/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.4278e-04 - acc: 1.0000 - val_loss: 1.2705 - val_acc: 0.8889\n",
      "Epoch 2584/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4214e-04 - acc: 1.0000 - val_loss: 1.2729 - val_acc: 0.8889\n",
      "Epoch 2585/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.4133e-04 - acc: 1.0000 - val_loss: 1.2745 - val_acc: 0.8889\n",
      "Epoch 2586/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.4006e-04 - acc: 1.0000 - val_loss: 1.2732 - val_acc: 0.8889\n",
      "Epoch 2587/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.3857e-04 - acc: 1.0000 - val_loss: 1.2746 - val_acc: 0.8889\n",
      "Epoch 2588/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3703e-04 - acc: 1.0000 - val_loss: 1.2746 - val_acc: 0.8889\n",
      "Epoch 2589/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3607e-04 - acc: 1.0000 - val_loss: 1.2747 - val_acc: 0.8889\n",
      "Epoch 2590/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3397e-04 - acc: 1.0000 - val_loss: 1.2765 - val_acc: 0.8889\n",
      "Epoch 2591/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.3302e-04 - acc: 1.0000 - val_loss: 1.2769 - val_acc: 0.8889\n",
      "Epoch 2592/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.3250e-04 - acc: 1.0000 - val_loss: 1.2782 - val_acc: 0.8889\n",
      "Epoch 2593/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.3067e-04 - acc: 1.0000 - val_loss: 1.2751 - val_acc: 0.8889\n",
      "Epoch 2594/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3056e-04 - acc: 1.0000 - val_loss: 1.2771 - val_acc: 0.8889\n",
      "Epoch 2595/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.2822e-04 - acc: 1.0000 - val_loss: 1.2748 - val_acc: 0.8889\n",
      "Epoch 2596/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.2780e-04 - acc: 1.0000 - val_loss: 1.2762 - val_acc: 0.8889\n",
      "Epoch 2597/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.2686e-04 - acc: 1.0000 - val_loss: 1.2796 - val_acc: 0.8889\n",
      "Epoch 2598/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.2501e-04 - acc: 1.0000 - val_loss: 1.2775 - val_acc: 0.8889\n",
      "Epoch 2599/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2357e-04 - acc: 1.0000 - val_loss: 1.2794 - val_acc: 0.8889\n",
      "Epoch 2600/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2311e-04 - acc: 1.0000 - val_loss: 1.2802 - val_acc: 0.8889\n",
      "Epoch 2601/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2154e-04 - acc: 1.0000 - val_loss: 1.2813 - val_acc: 0.8889\n",
      "Epoch 2602/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2002e-04 - acc: 1.0000 - val_loss: 1.2774 - val_acc: 0.8889\n",
      "Epoch 2603/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2035e-04 - acc: 1.0000 - val_loss: 1.2818 - val_acc: 0.8889\n",
      "Epoch 2604/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.1821e-04 - acc: 1.0000 - val_loss: 1.2835 - val_acc: 0.8889\n",
      "Epoch 2605/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.1722e-04 - acc: 1.0000 - val_loss: 1.2793 - val_acc: 0.8889\n",
      "Epoch 2606/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.1564e-04 - acc: 1.0000 - val_loss: 1.2801 - val_acc: 0.8889\n",
      "Epoch 2607/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.1485e-04 - acc: 1.0000 - val_loss: 1.2812 - val_acc: 0.8889\n",
      "Epoch 2608/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.1421e-04 - acc: 1.0000 - val_loss: 1.2809 - val_acc: 0.8889\n",
      "Epoch 2609/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.1311e-04 - acc: 1.0000 - val_loss: 1.2812 - val_acc: 0.8889\n",
      "Epoch 2610/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.1219e-04 - acc: 1.0000 - val_loss: 1.2818 - val_acc: 0.8889\n",
      "Epoch 2611/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.1116e-04 - acc: 1.0000 - val_loss: 1.2820 - val_acc: 0.8889\n",
      "Epoch 2612/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.0972e-04 - acc: 1.0000 - val_loss: 1.2807 - val_acc: 0.8889\n",
      "Epoch 2613/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.0881e-04 - acc: 1.0000 - val_loss: 1.2810 - val_acc: 0.8889\n",
      "Epoch 2614/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.0758e-04 - acc: 1.0000 - val_loss: 1.2847 - val_acc: 0.8889\n",
      "Epoch 2615/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.0734e-04 - acc: 1.0000 - val_loss: 1.2836 - val_acc: 0.8889\n",
      "Epoch 2616/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.0553e-04 - acc: 1.0000 - val_loss: 1.2853 - val_acc: 0.8889\n",
      "Epoch 2617/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0446e-04 - acc: 1.0000 - val_loss: 1.2858 - val_acc: 0.8889\n",
      "Epoch 2618/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.0372e-04 - acc: 1.0000 - val_loss: 1.2864 - val_acc: 0.8889\n",
      "Epoch 2619/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0213e-04 - acc: 1.0000 - val_loss: 1.2816 - val_acc: 0.8889\n",
      "Epoch 2620/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.0111e-04 - acc: 1.0000 - val_loss: 1.2830 - val_acc: 0.8889\n",
      "Epoch 2621/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0060e-04 - acc: 1.0000 - val_loss: 1.2849 - val_acc: 0.8889\n",
      "Epoch 2622/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.9967e-04 - acc: 1.0000 - val_loss: 1.2858 - val_acc: 0.8889\n",
      "Epoch 2623/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.9853e-04 - acc: 1.0000 - val_loss: 1.2870 - val_acc: 0.8889\n",
      "Epoch 2624/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9791e-04 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.8889\n",
      "Epoch 2625/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.9630e-04 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.8889\n",
      "Epoch 2626/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.9559e-04 - acc: 1.0000 - val_loss: 1.2871 - val_acc: 0.8889\n",
      "Epoch 2627/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.9446e-04 - acc: 1.0000 - val_loss: 1.2851 - val_acc: 0.8889\n",
      "Epoch 2628/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.9363e-04 - acc: 1.0000 - val_loss: 1.2864 - val_acc: 0.8889\n",
      "Epoch 2629/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.9293e-04 - acc: 1.0000 - val_loss: 1.2852 - val_acc: 0.8889\n",
      "Epoch 2630/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.9125e-04 - acc: 1.0000 - val_loss: 1.2845 - val_acc: 0.8889\n",
      "Epoch 2631/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9060e-04 - acc: 1.0000 - val_loss: 1.2845 - val_acc: 0.8889\n",
      "Epoch 2632/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.8951e-04 - acc: 1.0000 - val_loss: 1.2865 - val_acc: 0.8889\n",
      "Epoch 2633/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.8874e-04 - acc: 1.0000 - val_loss: 1.2863 - val_acc: 0.8889\n",
      "Epoch 2634/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.8713e-04 - acc: 1.0000 - val_loss: 1.2901 - val_acc: 0.8889\n",
      "Epoch 2635/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.8666e-04 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.8889\n",
      "Epoch 2636/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.8560e-04 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.8889\n",
      "Epoch 2637/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.8442e-04 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.8889\n",
      "Epoch 2638/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.8357e-04 - acc: 1.0000 - val_loss: 1.2868 - val_acc: 0.8889\n",
      "Epoch 2639/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.8287e-04 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.8889\n",
      "Epoch 2640/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.8163e-04 - acc: 1.0000 - val_loss: 1.2878 - val_acc: 0.8889\n",
      "Epoch 2641/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.8046e-04 - acc: 1.0000 - val_loss: 1.2883 - val_acc: 0.8889\n",
      "Epoch 2642/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7930e-04 - acc: 1.0000 - val_loss: 1.2847 - val_acc: 0.8889\n",
      "Epoch 2643/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.7963e-04 - acc: 1.0000 - val_loss: 1.2905 - val_acc: 0.8889\n",
      "Epoch 2644/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7791e-04 - acc: 1.0000 - val_loss: 1.2903 - val_acc: 0.8889\n",
      "Epoch 2645/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7699e-04 - acc: 1.0000 - val_loss: 1.2857 - val_acc: 0.8889\n",
      "Epoch 2646/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7605e-04 - acc: 1.0000 - val_loss: 1.2872 - val_acc: 0.8889\n",
      "Epoch 2647/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7547e-04 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.8889\n",
      "Epoch 2648/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 1.7483e-04 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.8889\n",
      "Epoch 2649/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 1.7349e-04 - acc: 1.0000 - val_loss: 1.2904 - val_acc: 0.8889\n",
      "Epoch 2650/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7274e-04 - acc: 1.0000 - val_loss: 1.2884 - val_acc: 0.8889\n",
      "Epoch 2651/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7211e-04 - acc: 1.0000 - val_loss: 1.2915 - val_acc: 0.8889\n",
      "Epoch 2652/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.7100e-04 - acc: 1.0000 - val_loss: 1.2928 - val_acc: 0.8889\n",
      "Epoch 2653/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 1.7076e-04 - acc: 1.0000 - val_loss: 1.2911 - val_acc: 0.8889\n",
      "Epoch 2654/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 1.6922e-04 - acc: 1.0000 - val_loss: 1.2934 - val_acc: 0.8889\n",
      "Epoch 2655/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 1.6854e-04 - acc: 1.0000 - val_loss: 1.2933 - val_acc: 0.8889\n",
      "Epoch 2656/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 1.6766e-04 - acc: 1.0000 - val_loss: 1.2973 - val_acc: 0.8889\n",
      "Epoch 2657/10000\n",
      "216/216 [==============================] - 0s 167us/step - loss: 1.6682e-04 - acc: 1.0000 - val_loss: 1.2978 - val_acc: 0.8889\n",
      "Epoch 2658/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 1.6601e-04 - acc: 1.0000 - val_loss: 1.2955 - val_acc: 0.8889\n",
      "Epoch 2659/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 1.6530e-04 - acc: 1.0000 - val_loss: 1.2909 - val_acc: 0.8889\n",
      "Epoch 2660/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.6434e-04 - acc: 1.0000 - val_loss: 1.2931 - val_acc: 0.8889\n",
      "Epoch 2661/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6323e-04 - acc: 1.0000 - val_loss: 1.2932 - val_acc: 0.8889\n",
      "Epoch 2662/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.6241e-04 - acc: 1.0000 - val_loss: 1.2932 - val_acc: 0.8889\n",
      "Epoch 2663/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6151e-04 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.8889\n",
      "Epoch 2664/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.6077e-04 - acc: 1.0000 - val_loss: 1.2962 - val_acc: 0.8889\n",
      "Epoch 2665/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6033e-04 - acc: 1.0000 - val_loss: 1.2943 - val_acc: 0.8889\n",
      "Epoch 2666/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5944e-04 - acc: 1.0000 - val_loss: 1.2982 - val_acc: 0.8889\n",
      "Epoch 2667/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5858e-04 - acc: 1.0000 - val_loss: 1.2975 - val_acc: 0.8889\n",
      "Epoch 2668/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.5746e-04 - acc: 1.0000 - val_loss: 1.2986 - val_acc: 0.8889\n",
      "Epoch 2669/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.5695e-04 - acc: 1.0000 - val_loss: 1.2974 - val_acc: 0.8889\n",
      "Epoch 2670/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 1.5595e-04 - acc: 1.0000 - val_loss: 1.2963 - val_acc: 0.8889\n",
      "Epoch 2671/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5547e-04 - acc: 1.0000 - val_loss: 1.2959 - val_acc: 0.8889\n",
      "Epoch 2672/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5446e-04 - acc: 1.0000 - val_loss: 1.2952 - val_acc: 0.8889\n",
      "Epoch 2673/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.5417e-04 - acc: 1.0000 - val_loss: 1.2966 - val_acc: 0.8889\n",
      "Epoch 2674/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5281e-04 - acc: 1.0000 - val_loss: 1.2977 - val_acc: 0.8889\n",
      "Epoch 2675/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5252e-04 - acc: 1.0000 - val_loss: 1.3006 - val_acc: 0.8889\n",
      "Epoch 2676/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5152e-04 - acc: 1.0000 - val_loss: 1.2978 - val_acc: 0.8889\n",
      "Epoch 2677/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.5064e-04 - acc: 1.0000 - val_loss: 1.2975 - val_acc: 0.8889\n",
      "Epoch 2678/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.4975e-04 - acc: 1.0000 - val_loss: 1.2974 - val_acc: 0.8889\n",
      "Epoch 2679/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.4963e-04 - acc: 1.0000 - val_loss: 1.2968 - val_acc: 0.8889\n",
      "Epoch 2680/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4847e-04 - acc: 1.0000 - val_loss: 1.2982 - val_acc: 0.8889\n",
      "Epoch 2681/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.4769e-04 - acc: 1.0000 - val_loss: 1.2985 - val_acc: 0.8889\n",
      "Epoch 2682/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.4693e-04 - acc: 1.0000 - val_loss: 1.2967 - val_acc: 0.8889\n",
      "Epoch 2683/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4628e-04 - acc: 1.0000 - val_loss: 1.2982 - val_acc: 0.8889\n",
      "Epoch 2684/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4539e-04 - acc: 1.0000 - val_loss: 1.2995 - val_acc: 0.8889\n",
      "Epoch 2685/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4443e-04 - acc: 1.0000 - val_loss: 1.3026 - val_acc: 0.8889\n",
      "Epoch 2686/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.4398e-04 - acc: 1.0000 - val_loss: 1.3021 - val_acc: 0.8889\n",
      "Epoch 2687/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4345e-04 - acc: 1.0000 - val_loss: 1.3034 - val_acc: 0.8889\n",
      "Epoch 2688/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.4230e-04 - acc: 1.0000 - val_loss: 1.3007 - val_acc: 0.8889\n",
      "Epoch 2689/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4153e-04 - acc: 1.0000 - val_loss: 1.3006 - val_acc: 0.8889\n",
      "Epoch 2690/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4103e-04 - acc: 1.0000 - val_loss: 1.2991 - val_acc: 0.8889\n",
      "Epoch 2691/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4031e-04 - acc: 1.0000 - val_loss: 1.3015 - val_acc: 0.8889\n",
      "Epoch 2692/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 1.3946e-04 - acc: 1.0000 - val_loss: 1.2972 - val_acc: 0.8889\n",
      "Epoch 2693/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3869e-04 - acc: 1.0000 - val_loss: 1.3059 - val_acc: 0.8889\n",
      "Epoch 2694/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.3829e-04 - acc: 1.0000 - val_loss: 1.3037 - val_acc: 0.8889\n",
      "Epoch 2695/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 97us/step - loss: 1.3763e-04 - acc: 1.0000 - val_loss: 1.3051 - val_acc: 0.8889\n",
      "Epoch 2696/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3682e-04 - acc: 1.0000 - val_loss: 1.3011 - val_acc: 0.8889\n",
      "Epoch 2697/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.3606e-04 - acc: 1.0000 - val_loss: 1.3010 - val_acc: 0.8889\n",
      "Epoch 2698/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3556e-04 - acc: 1.0000 - val_loss: 1.3001 - val_acc: 0.8889\n",
      "Epoch 2699/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.3491e-04 - acc: 1.0000 - val_loss: 1.3007 - val_acc: 0.8889\n",
      "Epoch 2700/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 1.3456e-04 - acc: 1.0000 - val_loss: 1.3026 - val_acc: 0.8889\n",
      "Epoch 2701/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.3320e-04 - acc: 1.0000 - val_loss: 1.2998 - val_acc: 0.8889\n",
      "Epoch 2702/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.3317e-04 - acc: 1.0000 - val_loss: 1.3025 - val_acc: 0.8889\n",
      "Epoch 2703/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.3210e-04 - acc: 1.0000 - val_loss: 1.2988 - val_acc: 0.8889\n",
      "Epoch 2704/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.3205e-04 - acc: 1.0000 - val_loss: 1.3039 - val_acc: 0.8889\n",
      "Epoch 2705/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.3081e-04 - acc: 1.0000 - val_loss: 1.2982 - val_acc: 0.8889\n",
      "Epoch 2706/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.3030e-04 - acc: 1.0000 - val_loss: 1.3002 - val_acc: 0.8889\n",
      "Epoch 2707/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.2912e-04 - acc: 1.0000 - val_loss: 1.2968 - val_acc: 0.8889\n",
      "Epoch 2708/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.2904e-04 - acc: 1.0000 - val_loss: 1.3007 - val_acc: 0.8889\n",
      "Epoch 2709/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 1.2825e-04 - acc: 1.0000 - val_loss: 1.3051 - val_acc: 0.8889\n",
      "Epoch 2710/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2771e-04 - acc: 1.0000 - val_loss: 1.3069 - val_acc: 0.8889\n",
      "Epoch 2711/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.2688e-04 - acc: 1.0000 - val_loss: 1.3034 - val_acc: 0.8889\n",
      "Epoch 2712/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 1.2656e-04 - acc: 1.0000 - val_loss: 1.3028 - val_acc: 0.8889\n",
      "Epoch 2713/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.2594e-04 - acc: 1.0000 - val_loss: 1.3034 - val_acc: 0.8889\n",
      "Epoch 2714/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.2514e-04 - acc: 1.0000 - val_loss: 1.3060 - val_acc: 0.8889\n",
      "Epoch 2715/10000\n",
      "216/216 [==============================] - 0s 144us/step - loss: 1.2438e-04 - acc: 1.0000 - val_loss: 1.3039 - val_acc: 0.8889\n",
      "Epoch 2716/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 1.2393e-04 - acc: 1.0000 - val_loss: 1.3043 - val_acc: 0.8889\n",
      "Epoch 2717/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.2319e-04 - acc: 1.0000 - val_loss: 1.3083 - val_acc: 0.8889\n",
      "Epoch 2718/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.2243e-04 - acc: 1.0000 - val_loss: 1.3036 - val_acc: 0.8889\n",
      "Epoch 2719/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 1.2225e-04 - acc: 1.0000 - val_loss: 1.3061 - val_acc: 0.8889\n",
      "Epoch 2720/10000\n",
      "216/216 [==============================] - 0s 185us/step - loss: 1.2122e-04 - acc: 1.0000 - val_loss: 1.3052 - val_acc: 0.8889\n",
      "Epoch 2721/10000\n",
      "216/216 [==============================] - 0s 268us/step - loss: 1.2064e-04 - acc: 1.0000 - val_loss: 1.3064 - val_acc: 0.8889\n",
      "Epoch 2722/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 1.2050e-04 - acc: 1.0000 - val_loss: 1.3069 - val_acc: 0.8889\n",
      "Epoch 2723/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 1.2017e-04 - acc: 1.0000 - val_loss: 1.3085 - val_acc: 0.8889\n",
      "Epoch 2724/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.1887e-04 - acc: 1.0000 - val_loss: 1.3054 - val_acc: 0.8889\n",
      "Epoch 2725/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.1883e-04 - acc: 1.0000 - val_loss: 1.3099 - val_acc: 0.8889\n",
      "Epoch 2726/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1812e-04 - acc: 1.0000 - val_loss: 1.3096 - val_acc: 0.8889\n",
      "Epoch 2727/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1759e-04 - acc: 1.0000 - val_loss: 1.3080 - val_acc: 0.8889\n",
      "Epoch 2728/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1680e-04 - acc: 1.0000 - val_loss: 1.3072 - val_acc: 0.8889\n",
      "Epoch 2729/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1606e-04 - acc: 1.0000 - val_loss: 1.3097 - val_acc: 0.8889\n",
      "Epoch 2730/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.1555e-04 - acc: 1.0000 - val_loss: 1.3064 - val_acc: 0.8889\n",
      "Epoch 2731/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1481e-04 - acc: 1.0000 - val_loss: 1.3068 - val_acc: 0.8889\n",
      "Epoch 2732/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1460e-04 - acc: 1.0000 - val_loss: 1.3079 - val_acc: 0.8889\n",
      "Epoch 2733/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1370e-04 - acc: 1.0000 - val_loss: 1.3084 - val_acc: 0.8889\n",
      "Epoch 2734/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1352e-04 - acc: 1.0000 - val_loss: 1.3108 - val_acc: 0.8889\n",
      "Epoch 2735/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.1262e-04 - acc: 1.0000 - val_loss: 1.3100 - val_acc: 0.8889\n",
      "Epoch 2736/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1224e-04 - acc: 1.0000 - val_loss: 1.3125 - val_acc: 0.8889\n",
      "Epoch 2737/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1157e-04 - acc: 1.0000 - val_loss: 1.3106 - val_acc: 0.8889\n",
      "Epoch 2738/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1112e-04 - acc: 1.0000 - val_loss: 1.3107 - val_acc: 0.8889\n",
      "Epoch 2739/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1052e-04 - acc: 1.0000 - val_loss: 1.3085 - val_acc: 0.8889\n",
      "Epoch 2740/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0971e-04 - acc: 1.0000 - val_loss: 1.3142 - val_acc: 0.8889\n",
      "Epoch 2741/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0946e-04 - acc: 1.0000 - val_loss: 1.3093 - val_acc: 0.8889\n",
      "Epoch 2742/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0882e-04 - acc: 1.0000 - val_loss: 1.3122 - val_acc: 0.8889\n",
      "Epoch 2743/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0834e-04 - acc: 1.0000 - val_loss: 1.3139 - val_acc: 0.8889\n",
      "Epoch 2744/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.0772e-04 - acc: 1.0000 - val_loss: 1.3103 - val_acc: 0.8889\n",
      "Epoch 2745/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.0728e-04 - acc: 1.0000 - val_loss: 1.3101 - val_acc: 0.8889\n",
      "Epoch 2746/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 1.0627e-04 - acc: 1.0000 - val_loss: 1.3124 - val_acc: 0.8889\n",
      "Epoch 2747/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 1.0621e-04 - acc: 1.0000 - val_loss: 1.3124 - val_acc: 0.8889\n",
      "Epoch 2748/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 1.0567e-04 - acc: 1.0000 - val_loss: 1.3113 - val_acc: 0.8889\n",
      "Epoch 2749/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.0528e-04 - acc: 1.0000 - val_loss: 1.3113 - val_acc: 0.8889\n",
      "Epoch 2750/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0468e-04 - acc: 1.0000 - val_loss: 1.3122 - val_acc: 0.8889\n",
      "Epoch 2751/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.0396e-04 - acc: 1.0000 - val_loss: 1.3115 - val_acc: 0.8889\n",
      "Epoch 2752/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.0366e-04 - acc: 1.0000 - val_loss: 1.3152 - val_acc: 0.8889\n",
      "Epoch 2753/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0310e-04 - acc: 1.0000 - val_loss: 1.3147 - val_acc: 0.8889\n",
      "Epoch 2754/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0244e-04 - acc: 1.0000 - val_loss: 1.3105 - val_acc: 0.8889\n",
      "Epoch 2755/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0212e-04 - acc: 1.0000 - val_loss: 1.3122 - val_acc: 0.8889\n",
      "Epoch 2756/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0181e-04 - acc: 1.0000 - val_loss: 1.3118 - val_acc: 0.8889\n",
      "Epoch 2757/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0101e-04 - acc: 1.0000 - val_loss: 1.3124 - val_acc: 0.8889\n",
      "Epoch 2758/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.0038e-04 - acc: 1.0000 - val_loss: 1.3139 - val_acc: 0.8889\n",
      "Epoch 2759/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.9911e-05 - acc: 1.0000 - val_loss: 1.3174 - val_acc: 0.8889\n",
      "Epoch 2760/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.9524e-05 - acc: 1.0000 - val_loss: 1.3118 - val_acc: 0.8889\n",
      "Epoch 2761/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.8938e-05 - acc: 1.0000 - val_loss: 1.3125 - val_acc: 0.8889\n",
      "Epoch 2762/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 9.8617e-05 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.8889\n",
      "Epoch 2763/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 9.8113e-05 - acc: 1.0000 - val_loss: 1.3144 - val_acc: 0.8889\n",
      "Epoch 2764/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.7528e-05 - acc: 1.0000 - val_loss: 1.3151 - val_acc: 0.8889\n",
      "Epoch 2765/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 9.6945e-05 - acc: 1.0000 - val_loss: 1.3137 - val_acc: 0.8889\n",
      "Epoch 2766/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.6579e-05 - acc: 1.0000 - val_loss: 1.3132 - val_acc: 0.8889\n",
      "Epoch 2767/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.6229e-05 - acc: 1.0000 - val_loss: 1.3161 - val_acc: 0.8889\n",
      "Epoch 2768/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.5736e-05 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.8889\n",
      "Epoch 2769/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.5066e-05 - acc: 1.0000 - val_loss: 1.3132 - val_acc: 0.8889\n",
      "Epoch 2770/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.4674e-05 - acc: 1.0000 - val_loss: 1.3131 - val_acc: 0.8889\n",
      "Epoch 2771/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.4524e-05 - acc: 1.0000 - val_loss: 1.3146 - val_acc: 0.8889\n",
      "Epoch 2772/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 9.3831e-05 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.8889\n",
      "Epoch 2773/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.3599e-05 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.8889\n",
      "Epoch 2774/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.2864e-05 - acc: 1.0000 - val_loss: 1.3154 - val_acc: 0.8889\n",
      "Epoch 2775/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.2392e-05 - acc: 1.0000 - val_loss: 1.3164 - val_acc: 0.8889\n",
      "Epoch 2776/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 9.2060e-05 - acc: 1.0000 - val_loss: 1.3156 - val_acc: 0.8889\n",
      "Epoch 2777/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.1820e-05 - acc: 1.0000 - val_loss: 1.3140 - val_acc: 0.8889\n",
      "Epoch 2778/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.1004e-05 - acc: 1.0000 - val_loss: 1.3118 - val_acc: 0.8889\n",
      "Epoch 2779/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.0778e-05 - acc: 1.0000 - val_loss: 1.3166 - val_acc: 0.8889\n",
      "Epoch 2780/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.0090e-05 - acc: 1.0000 - val_loss: 1.3150 - val_acc: 0.8889\n",
      "Epoch 2781/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 8.9890e-05 - acc: 1.0000 - val_loss: 1.3157 - val_acc: 0.8889\n",
      "Epoch 2782/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 8.9267e-05 - acc: 1.0000 - val_loss: 1.3127 - val_acc: 0.8889\n",
      "Epoch 2783/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 8.8724e-05 - acc: 1.0000 - val_loss: 1.3156 - val_acc: 0.8889\n",
      "Epoch 2784/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.8581e-05 - acc: 1.0000 - val_loss: 1.3146 - val_acc: 0.8889\n",
      "Epoch 2785/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.8085e-05 - acc: 1.0000 - val_loss: 1.3162 - val_acc: 0.8889\n",
      "Epoch 2786/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.7605e-05 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.8889\n",
      "Epoch 2787/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 8.7145e-05 - acc: 1.0000 - val_loss: 1.3151 - val_acc: 0.8889\n",
      "Epoch 2788/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 8.6622e-05 - acc: 1.0000 - val_loss: 1.3140 - val_acc: 0.8889\n",
      "Epoch 2789/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 8.6335e-05 - acc: 1.0000 - val_loss: 1.3199 - val_acc: 0.8889\n",
      "Epoch 2790/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 8.5899e-05 - acc: 1.0000 - val_loss: 1.3220 - val_acc: 0.8889\n",
      "Epoch 2791/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 8.5658e-05 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.8889\n",
      "Epoch 2792/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 8.5405e-05 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.8889\n",
      "Epoch 2793/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.4621e-05 - acc: 1.0000 - val_loss: 1.3213 - val_acc: 0.8889\n",
      "Epoch 2794/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.4286e-05 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.8889\n",
      "Epoch 2795/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.4021e-05 - acc: 1.0000 - val_loss: 1.3179 - val_acc: 0.8889\n",
      "Epoch 2796/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 8.3306e-05 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.8889\n",
      "Epoch 2797/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 8.3048e-05 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.8889\n",
      "Epoch 2798/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 8.2433e-05 - acc: 1.0000 - val_loss: 1.3185 - val_acc: 0.8889\n",
      "Epoch 2799/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 8.2385e-05 - acc: 1.0000 - val_loss: 1.3199 - val_acc: 0.8889\n",
      "Epoch 2800/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 8.1960e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.8889\n",
      "Epoch 2801/10000\n",
      "216/216 [==============================] - 0s 176us/step - loss: 8.1489e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.8889\n",
      "Epoch 2802/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 8.1170e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.8889\n",
      "Epoch 2803/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 8.0588e-05 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.8889\n",
      "Epoch 2804/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 8.0134e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.8889\n",
      "Epoch 2805/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 7.9859e-05 - acc: 1.0000 - val_loss: 1.3185 - val_acc: 0.8889\n",
      "Epoch 2806/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 7.9363e-05 - acc: 1.0000 - val_loss: 1.3212 - val_acc: 0.8889\n",
      "Epoch 2807/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 7.9036e-05 - acc: 1.0000 - val_loss: 1.3211 - val_acc: 0.8889\n",
      "Epoch 2808/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 7.8560e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.8889\n",
      "Epoch 2809/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 130us/step - loss: 7.8165e-05 - acc: 1.0000 - val_loss: 1.3177 - val_acc: 0.8889\n",
      "Epoch 2810/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.8156e-05 - acc: 1.0000 - val_loss: 1.3195 - val_acc: 0.8889\n",
      "Epoch 2811/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.7549e-05 - acc: 1.0000 - val_loss: 1.3186 - val_acc: 0.8889\n",
      "Epoch 2812/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.7094e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.8889\n",
      "Epoch 2813/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 7.6820e-05 - acc: 1.0000 - val_loss: 1.3231 - val_acc: 0.8889\n",
      "Epoch 2814/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 7.6497e-05 - acc: 1.0000 - val_loss: 1.3212 - val_acc: 0.8889\n",
      "Epoch 2815/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.6274e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.8889\n",
      "Epoch 2816/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.5654e-05 - acc: 1.0000 - val_loss: 1.3178 - val_acc: 0.8889\n",
      "Epoch 2817/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.5340e-05 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.8889\n",
      "Epoch 2818/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.5103e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.8889\n",
      "Epoch 2819/10000\n",
      "216/216 [==============================] - 0s 259us/step - loss: 7.4623e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.8889\n",
      "Epoch 2820/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 7.4230e-05 - acc: 1.0000 - val_loss: 1.3186 - val_acc: 0.8889\n",
      "Epoch 2821/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 7.3786e-05 - acc: 1.0000 - val_loss: 1.3187 - val_acc: 0.8889\n",
      "Epoch 2822/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.3486e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.8889\n",
      "Epoch 2823/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.3335e-05 - acc: 1.0000 - val_loss: 1.3211 - val_acc: 0.8889\n",
      "Epoch 2824/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.2797e-05 - acc: 1.0000 - val_loss: 1.3216 - val_acc: 0.8889\n",
      "Epoch 2825/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.2585e-05 - acc: 1.0000 - val_loss: 1.3184 - val_acc: 0.8889\n",
      "Epoch 2826/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 7.1969e-05 - acc: 1.0000 - val_loss: 1.3153 - val_acc: 0.8889\n",
      "Epoch 2827/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 7.1900e-05 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.8889\n",
      "Epoch 2828/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.1477e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.8889\n",
      "Epoch 2829/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 7.0947e-05 - acc: 1.0000 - val_loss: 1.3218 - val_acc: 0.8889\n",
      "Epoch 2830/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 7.0807e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.8889\n",
      "Epoch 2831/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 7.0335e-05 - acc: 1.0000 - val_loss: 1.3234 - val_acc: 0.8889\n",
      "Epoch 2832/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 7.0127e-05 - acc: 1.0000 - val_loss: 1.3218 - val_acc: 0.8889\n",
      "Epoch 2833/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 6.9862e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.8889\n",
      "Epoch 2834/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.9496e-05 - acc: 1.0000 - val_loss: 1.3210 - val_acc: 0.8889\n",
      "Epoch 2835/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 6.8889e-05 - acc: 1.0000 - val_loss: 1.3177 - val_acc: 0.8889\n",
      "Epoch 2836/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 6.8796e-05 - acc: 1.0000 - val_loss: 1.3236 - val_acc: 0.8889\n",
      "Epoch 2837/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.8481e-05 - acc: 1.0000 - val_loss: 1.3233 - val_acc: 0.8889\n",
      "Epoch 2838/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.7851e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.8889\n",
      "Epoch 2839/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.7815e-05 - acc: 1.0000 - val_loss: 1.3195 - val_acc: 0.8889\n",
      "Epoch 2840/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 6.7626e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.8889\n",
      "Epoch 2841/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.7035e-05 - acc: 1.0000 - val_loss: 1.3238 - val_acc: 0.8889\n",
      "Epoch 2842/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.6768e-05 - acc: 1.0000 - val_loss: 1.3221 - val_acc: 0.8889\n",
      "Epoch 2843/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.6355e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.8889\n",
      "Epoch 2844/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.6046e-05 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.8889\n",
      "Epoch 2845/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.5763e-05 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.8889\n",
      "Epoch 2846/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.5547e-05 - acc: 1.0000 - val_loss: 1.3210 - val_acc: 0.8889\n",
      "Epoch 2847/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.5101e-05 - acc: 1.0000 - val_loss: 1.3210 - val_acc: 0.8889\n",
      "Epoch 2848/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.4955e-05 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.8889\n",
      "Epoch 2849/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.4513e-05 - acc: 1.0000 - val_loss: 1.3237 - val_acc: 0.8889\n",
      "Epoch 2850/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.4047e-05 - acc: 1.0000 - val_loss: 1.3243 - val_acc: 0.8889\n",
      "Epoch 2851/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.3879e-05 - acc: 1.0000 - val_loss: 1.3209 - val_acc: 0.8889\n",
      "Epoch 2852/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.3603e-05 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.8889\n",
      "Epoch 2853/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 6.3250e-05 - acc: 1.0000 - val_loss: 1.3235 - val_acc: 0.8889\n",
      "Epoch 2854/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.3073e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.8889\n",
      "Epoch 2855/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 6.2685e-05 - acc: 1.0000 - val_loss: 1.3238 - val_acc: 0.8889\n",
      "Epoch 2856/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.2403e-05 - acc: 1.0000 - val_loss: 1.3217 - val_acc: 0.8889\n",
      "Epoch 2857/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.2080e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.8889\n",
      "Epoch 2858/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.1830e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.8889\n",
      "Epoch 2859/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 6.1467e-05 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.8889\n",
      "Epoch 2860/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 6.1399e-05 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.8889\n",
      "Epoch 2861/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.1016e-05 - acc: 1.0000 - val_loss: 1.3207 - val_acc: 0.8889\n",
      "Epoch 2862/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.0702e-05 - acc: 1.0000 - val_loss: 1.3207 - val_acc: 0.8889\n",
      "Epoch 2863/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 6.0298e-05 - acc: 1.0000 - val_loss: 1.3213 - val_acc: 0.8889\n",
      "Epoch 2864/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.0063e-05 - acc: 1.0000 - val_loss: 1.3191 - val_acc: 0.8889\n",
      "Epoch 2865/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.9885e-05 - acc: 1.0000 - val_loss: 1.3171 - val_acc: 0.9074\n",
      "Epoch 2866/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 5.9467e-05 - acc: 1.0000 - val_loss: 1.3189 - val_acc: 0.9074\n",
      "Epoch 2867/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.9370e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.8889\n",
      "Epoch 2868/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.8912e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.8889\n",
      "Epoch 2869/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 5.8763e-05 - acc: 1.0000 - val_loss: 1.3213 - val_acc: 0.8889\n",
      "Epoch 2870/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 5.8276e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.9074\n",
      "Epoch 2871/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 5.8302e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 2872/10000\n",
      "216/216 [==============================] - 0s 162us/step - loss: 5.7810e-05 - acc: 1.0000 - val_loss: 1.3236 - val_acc: 0.9074\n",
      "Epoch 2873/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.7540e-05 - acc: 1.0000 - val_loss: 1.3199 - val_acc: 0.9074\n",
      "Epoch 2874/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 5.7379e-05 - acc: 1.0000 - val_loss: 1.3210 - val_acc: 0.9074\n",
      "Epoch 2875/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.6943e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2876/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.6774e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 2877/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.6419e-05 - acc: 1.0000 - val_loss: 1.3220 - val_acc: 0.9074\n",
      "Epoch 2878/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.6259e-05 - acc: 1.0000 - val_loss: 1.3204 - val_acc: 0.9074\n",
      "Epoch 2879/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.5990e-05 - acc: 1.0000 - val_loss: 1.3212 - val_acc: 0.9074\n",
      "Epoch 2880/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.5685e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.9074\n",
      "Epoch 2881/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 5.5432e-05 - acc: 1.0000 - val_loss: 1.3232 - val_acc: 0.9074\n",
      "Epoch 2882/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 5.5107e-05 - acc: 1.0000 - val_loss: 1.3212 - val_acc: 0.9074\n",
      "Epoch 2883/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 5.4925e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.9074\n",
      "Epoch 2884/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 5.4609e-05 - acc: 1.0000 - val_loss: 1.3213 - val_acc: 0.9074\n",
      "Epoch 2885/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.4393e-05 - acc: 1.0000 - val_loss: 1.3176 - val_acc: 0.9074\n",
      "Epoch 2886/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.4144e-05 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.9074\n",
      "Epoch 2887/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.3804e-05 - acc: 1.0000 - val_loss: 1.3222 - val_acc: 0.9074\n",
      "Epoch 2888/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.3518e-05 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.9074\n",
      "Epoch 2889/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 5.3355e-05 - acc: 1.0000 - val_loss: 1.3197 - val_acc: 0.9074\n",
      "Epoch 2890/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.3035e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 2891/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.2717e-05 - acc: 1.0000 - val_loss: 1.3228 - val_acc: 0.9074\n",
      "Epoch 2892/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.2669e-05 - acc: 1.0000 - val_loss: 1.3193 - val_acc: 0.9074\n",
      "Epoch 2893/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.2383e-05 - acc: 1.0000 - val_loss: 1.3197 - val_acc: 0.9074\n",
      "Epoch 2894/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.2111e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 2895/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 5.1782e-05 - acc: 1.0000 - val_loss: 1.3214 - val_acc: 0.9074\n",
      "Epoch 2896/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 5.1709e-05 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.9074\n",
      "Epoch 2897/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 5.1411e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 2898/10000\n",
      "216/216 [==============================] - 0s 171us/step - loss: 5.1037e-05 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.9074\n",
      "Epoch 2899/10000\n",
      "216/216 [==============================] - 0s 236us/step - loss: 5.0785e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2900/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 5.0637e-05 - acc: 1.0000 - val_loss: 1.3189 - val_acc: 0.9074\n",
      "Epoch 2901/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 5.0307e-05 - acc: 1.0000 - val_loss: 1.3195 - val_acc: 0.9074\n",
      "Epoch 2902/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 5.0144e-05 - acc: 1.0000 - val_loss: 1.3183 - val_acc: 0.9074\n",
      "Epoch 2903/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 4.9903e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.9074\n",
      "Epoch 2904/10000\n",
      "216/216 [==============================] - 0s 231us/step - loss: 4.9623e-05 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.9074\n",
      "Epoch 2905/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 4.9390e-05 - acc: 1.0000 - val_loss: 1.3174 - val_acc: 0.9074\n",
      "Epoch 2906/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 4.9312e-05 - acc: 1.0000 - val_loss: 1.3179 - val_acc: 0.9074\n",
      "Epoch 2907/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 4.8842e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2908/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 4.8795e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 2909/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 4.8426e-05 - acc: 1.0000 - val_loss: 1.3182 - val_acc: 0.9074\n",
      "Epoch 2910/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 4.8287e-05 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.9074\n",
      "Epoch 2911/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 4.8038e-05 - acc: 1.0000 - val_loss: 1.3217 - val_acc: 0.9074\n",
      "Epoch 2912/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.7676e-05 - acc: 1.0000 - val_loss: 1.3252 - val_acc: 0.9074\n",
      "Epoch 2913/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 4.7623e-05 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.9074\n",
      "Epoch 2914/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.7260e-05 - acc: 1.0000 - val_loss: 1.3198 - val_acc: 0.9074\n",
      "Epoch 2915/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.7054e-05 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.9074\n",
      "Epoch 2916/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.6830e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 2917/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.6567e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n",
      "Epoch 2918/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.6497e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2919/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 4.6161e-05 - acc: 1.0000 - val_loss: 1.3195 - val_acc: 0.9074\n",
      "Epoch 2920/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.5954e-05 - acc: 1.0000 - val_loss: 1.3226 - val_acc: 0.9074\n",
      "Epoch 2921/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.5656e-05 - acc: 1.0000 - val_loss: 1.3198 - val_acc: 0.9074\n",
      "Epoch 2922/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.5477e-05 - acc: 1.0000 - val_loss: 1.3207 - val_acc: 0.9074\n",
      "Epoch 2923/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 97us/step - loss: 4.5265e-05 - acc: 1.0000 - val_loss: 1.3226 - val_acc: 0.9074\n",
      "Epoch 2924/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.5084e-05 - acc: 1.0000 - val_loss: 1.3233 - val_acc: 0.9074\n",
      "Epoch 2925/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.4810e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n",
      "Epoch 2926/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 4.4569e-05 - acc: 1.0000 - val_loss: 1.3209 - val_acc: 0.9074\n",
      "Epoch 2927/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.4412e-05 - acc: 1.0000 - val_loss: 1.3211 - val_acc: 0.9074\n",
      "Epoch 2928/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.4134e-05 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.9074\n",
      "Epoch 2929/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.4054e-05 - acc: 1.0000 - val_loss: 1.3221 - val_acc: 0.9074\n",
      "Epoch 2930/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.3695e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2931/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 4.3547e-05 - acc: 1.0000 - val_loss: 1.3220 - val_acc: 0.9074\n",
      "Epoch 2932/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.3273e-05 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.9074\n",
      "Epoch 2933/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 4.3183e-05 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.9074\n",
      "Epoch 2934/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.2934e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2935/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.2794e-05 - acc: 1.0000 - val_loss: 1.3212 - val_acc: 0.9074\n",
      "Epoch 2936/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.2530e-05 - acc: 1.0000 - val_loss: 1.3221 - val_acc: 0.9074\n",
      "Epoch 2937/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.2431e-05 - acc: 1.0000 - val_loss: 1.3226 - val_acc: 0.9074\n",
      "Epoch 2938/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.2156e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.9074\n",
      "Epoch 2939/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 4.1935e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.9074\n",
      "Epoch 2940/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 4.1797e-05 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.9074\n",
      "Epoch 2941/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.1604e-05 - acc: 1.0000 - val_loss: 1.3204 - val_acc: 0.9074\n",
      "Epoch 2942/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.1295e-05 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.9074\n",
      "Epoch 2943/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 4.1195e-05 - acc: 1.0000 - val_loss: 1.3210 - val_acc: 0.9074\n",
      "Epoch 2944/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 4.1012e-05 - acc: 1.0000 - val_loss: 1.3220 - val_acc: 0.9074\n",
      "Epoch 2945/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 4.0771e-05 - acc: 1.0000 - val_loss: 1.3222 - val_acc: 0.9074\n",
      "Epoch 2946/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 4.0589e-05 - acc: 1.0000 - val_loss: 1.3233 - val_acc: 0.9074\n",
      "Epoch 2947/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 4.0397e-05 - acc: 1.0000 - val_loss: 1.3225 - val_acc: 0.9074\n",
      "Epoch 2948/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 4.0271e-05 - acc: 1.0000 - val_loss: 1.3222 - val_acc: 0.9074\n",
      "Epoch 2949/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.9936e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n",
      "Epoch 2950/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.9806e-05 - acc: 1.0000 - val_loss: 1.3187 - val_acc: 0.9074\n",
      "Epoch 2951/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.9758e-05 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.9074\n",
      "Epoch 2952/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.9339e-05 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.9074\n",
      "Epoch 2953/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.9303e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 2954/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 3.9000e-05 - acc: 1.0000 - val_loss: 1.3191 - val_acc: 0.9074\n",
      "Epoch 2955/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.8823e-05 - acc: 1.0000 - val_loss: 1.3234 - val_acc: 0.9074\n",
      "Epoch 2956/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.8798e-05 - acc: 1.0000 - val_loss: 1.3217 - val_acc: 0.9074\n",
      "Epoch 2957/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.8571e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 2958/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.8307e-05 - acc: 1.0000 - val_loss: 1.3183 - val_acc: 0.9074\n",
      "Epoch 2959/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.8091e-05 - acc: 1.0000 - val_loss: 1.3174 - val_acc: 0.9074\n",
      "Epoch 2960/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.8046e-05 - acc: 1.0000 - val_loss: 1.3189 - val_acc: 0.9074\n",
      "Epoch 2961/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.7779e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 2962/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.7556e-05 - acc: 1.0000 - val_loss: 1.3175 - val_acc: 0.9074\n",
      "Epoch 2963/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 3.7495e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n",
      "Epoch 2964/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.7270e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n",
      "Epoch 2965/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.7129e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 2966/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.6827e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 2967/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6698e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 2968/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.6471e-05 - acc: 1.0000 - val_loss: 1.3231 - val_acc: 0.9074\n",
      "Epoch 2969/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.6337e-05 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.9074\n",
      "Epoch 2970/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6240e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 2971/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.6031e-05 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.9074\n",
      "Epoch 2972/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.5813e-05 - acc: 1.0000 - val_loss: 1.3184 - val_acc: 0.9074\n",
      "Epoch 2973/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.5695e-05 - acc: 1.0000 - val_loss: 1.3229 - val_acc: 0.9074\n",
      "Epoch 2974/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.5549e-05 - acc: 1.0000 - val_loss: 1.3222 - val_acc: 0.9074\n",
      "Epoch 2975/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.5330e-05 - acc: 1.0000 - val_loss: 1.3198 - val_acc: 0.9074\n",
      "Epoch 2976/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.5221e-05 - acc: 1.0000 - val_loss: 1.3207 - val_acc: 0.9074\n",
      "Epoch 2977/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.4996e-05 - acc: 1.0000 - val_loss: 1.3228 - val_acc: 0.9074\n",
      "Epoch 2978/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.4926e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 2979/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.4599e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.9074\n",
      "Epoch 2980/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.4575e-05 - acc: 1.0000 - val_loss: 1.3193 - val_acc: 0.9074\n",
      "Epoch 2981/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.4353e-05 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.9074\n",
      "Epoch 2982/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.4131e-05 - acc: 1.0000 - val_loss: 1.3167 - val_acc: 0.9074\n",
      "Epoch 2983/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.4027e-05 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.9074\n",
      "Epoch 2984/10000\n",
      "216/216 [==============================] - ETA: 0s - loss: 3.1542e-05 - acc: 1.000 - 0s 97us/step - loss: 3.3816e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.9074\n",
      "Epoch 2985/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.3766e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2986/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.3507e-05 - acc: 1.0000 - val_loss: 1.3180 - val_acc: 0.9074\n",
      "Epoch 2987/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.3418e-05 - acc: 1.0000 - val_loss: 1.3209 - val_acc: 0.9074\n",
      "Epoch 2988/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.3247e-05 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.9074\n",
      "Epoch 2989/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.3036e-05 - acc: 1.0000 - val_loss: 1.3163 - val_acc: 0.9074\n",
      "Epoch 2990/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.2939e-05 - acc: 1.0000 - val_loss: 1.3184 - val_acc: 0.9074\n",
      "Epoch 2991/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2795e-05 - acc: 1.0000 - val_loss: 1.3183 - val_acc: 0.9074\n",
      "Epoch 2992/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.2627e-05 - acc: 1.0000 - val_loss: 1.3204 - val_acc: 0.9074\n",
      "Epoch 2993/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.2467e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 2994/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.2332e-05 - acc: 1.0000 - val_loss: 1.3237 - val_acc: 0.9074\n",
      "Epoch 2995/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2111e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.9074\n",
      "Epoch 2996/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.2099e-05 - acc: 1.0000 - val_loss: 1.3228 - val_acc: 0.9074\n",
      "Epoch 2997/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 3.1924e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 2998/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.1778e-05 - acc: 1.0000 - val_loss: 1.3239 - val_acc: 0.9074\n",
      "Epoch 2999/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.1635e-05 - acc: 1.0000 - val_loss: 1.3233 - val_acc: 0.9074\n",
      "Epoch 3000/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.1393e-05 - acc: 1.0000 - val_loss: 1.3189 - val_acc: 0.9074\n",
      "Epoch 3001/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.1352e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.9074\n",
      "Epoch 3002/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.1158e-05 - acc: 1.0000 - val_loss: 1.3174 - val_acc: 0.9074\n",
      "Epoch 3003/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.1022e-05 - acc: 1.0000 - val_loss: 1.3220 - val_acc: 0.9074\n",
      "Epoch 3004/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.0903e-05 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.9074\n",
      "Epoch 3005/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.0710e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 3006/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.0595e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n",
      "Epoch 3007/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.0459e-05 - acc: 1.0000 - val_loss: 1.3210 - val_acc: 0.9074\n",
      "Epoch 3008/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.0305e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 3009/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.0258e-05 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.9074\n",
      "Epoch 3010/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.0093e-05 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.9074\n",
      "Epoch 3011/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.9938e-05 - acc: 1.0000 - val_loss: 1.3178 - val_acc: 0.9074\n",
      "Epoch 3012/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.9699e-05 - acc: 1.0000 - val_loss: 1.3212 - val_acc: 0.9074\n",
      "Epoch 3013/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.9613e-05 - acc: 1.0000 - val_loss: 1.3191 - val_acc: 0.9074\n",
      "Epoch 3014/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.9526e-05 - acc: 1.0000 - val_loss: 1.3228 - val_acc: 0.9074\n",
      "Epoch 3015/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.9362e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 3016/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.9247e-05 - acc: 1.0000 - val_loss: 1.3185 - val_acc: 0.9074\n",
      "Epoch 3017/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.9105e-05 - acc: 1.0000 - val_loss: 1.3207 - val_acc: 0.9074\n",
      "Epoch 3018/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.8956e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.9074\n",
      "Epoch 3019/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.8787e-05 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.9074\n",
      "Epoch 3020/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.8698e-05 - acc: 1.0000 - val_loss: 1.3184 - val_acc: 0.9074\n",
      "Epoch 3021/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.8518e-05 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.9074\n",
      "Epoch 3022/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.8400e-05 - acc: 1.0000 - val_loss: 1.3242 - val_acc: 0.9074\n",
      "Epoch 3023/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.8319e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 3024/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.8100e-05 - acc: 1.0000 - val_loss: 1.3152 - val_acc: 0.9074\n",
      "Epoch 3025/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.8005e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 3026/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.7852e-05 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.9074\n",
      "Epoch 3027/10000\n",
      "216/216 [==============================] - 0s 153us/step - loss: 2.7746e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 3028/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 2.7622e-05 - acc: 1.0000 - val_loss: 1.3154 - val_acc: 0.9074\n",
      "Epoch 3029/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.7470e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 3030/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.7439e-05 - acc: 1.0000 - val_loss: 1.3189 - val_acc: 0.9074\n",
      "Epoch 3031/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.7197e-05 - acc: 1.0000 - val_loss: 1.3184 - val_acc: 0.9074\n",
      "Epoch 3032/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.7093e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 3033/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.7008e-05 - acc: 1.0000 - val_loss: 1.3234 - val_acc: 0.9074\n",
      "Epoch 3034/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.6845e-05 - acc: 1.0000 - val_loss: 1.3238 - val_acc: 0.9074\n",
      "Epoch 3035/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.6732e-05 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.9074\n",
      "Epoch 3036/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.6614e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3037/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.6505e-05 - acc: 1.0000 - val_loss: 1.3173 - val_acc: 0.9074\n",
      "Epoch 3038/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.6428e-05 - acc: 1.0000 - val_loss: 1.3186 - val_acc: 0.9074\n",
      "Epoch 3039/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.6257e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 3040/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.6142e-05 - acc: 1.0000 - val_loss: 1.3193 - val_acc: 0.9074\n",
      "Epoch 3041/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.6103e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 3042/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.5958e-05 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.9074\n",
      "Epoch 3043/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.5762e-05 - acc: 1.0000 - val_loss: 1.3224 - val_acc: 0.9074\n",
      "Epoch 3044/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.5767e-05 - acc: 1.0000 - val_loss: 1.3179 - val_acc: 0.9074\n",
      "Epoch 3045/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.5525e-05 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9074\n",
      "Epoch 3046/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5438e-05 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.9074\n",
      "Epoch 3047/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.5315e-05 - acc: 1.0000 - val_loss: 1.3211 - val_acc: 0.9074\n",
      "Epoch 3048/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5249e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 3049/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.5158e-05 - acc: 1.0000 - val_loss: 1.3191 - val_acc: 0.9074\n",
      "Epoch 3050/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4965e-05 - acc: 1.0000 - val_loss: 1.3222 - val_acc: 0.9074\n",
      "Epoch 3051/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.4858e-05 - acc: 1.0000 - val_loss: 1.3221 - val_acc: 0.9074\n",
      "Epoch 3052/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.4803e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.9074\n",
      "Epoch 3053/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.4662e-05 - acc: 1.0000 - val_loss: 1.3199 - val_acc: 0.9074\n",
      "Epoch 3054/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4562e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 3055/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.4487e-05 - acc: 1.0000 - val_loss: 1.3210 - val_acc: 0.9074\n",
      "Epoch 3056/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.4367e-05 - acc: 1.0000 - val_loss: 1.3197 - val_acc: 0.9074\n",
      "Epoch 3057/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.4237e-05 - acc: 1.0000 - val_loss: 1.3223 - val_acc: 0.9074\n",
      "Epoch 3058/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.4136e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.9074\n",
      "Epoch 3059/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.4020e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 3060/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.3880e-05 - acc: 1.0000 - val_loss: 1.3237 - val_acc: 0.9074\n",
      "Epoch 3061/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3757e-05 - acc: 1.0000 - val_loss: 1.3189 - val_acc: 0.9074\n",
      "Epoch 3062/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 2.3655e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.9074\n",
      "Epoch 3063/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3617e-05 - acc: 1.0000 - val_loss: 1.3193 - val_acc: 0.9074\n",
      "Epoch 3064/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 2.3453e-05 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.9074\n",
      "Epoch 3065/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.3430e-05 - acc: 1.0000 - val_loss: 1.3217 - val_acc: 0.9074\n",
      "Epoch 3066/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3248e-05 - acc: 1.0000 - val_loss: 1.3184 - val_acc: 0.9074\n",
      "Epoch 3067/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.3115e-05 - acc: 1.0000 - val_loss: 1.3231 - val_acc: 0.9074\n",
      "Epoch 3068/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.3020e-05 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.9074\n",
      "Epoch 3069/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2948e-05 - acc: 1.0000 - val_loss: 1.3195 - val_acc: 0.9074\n",
      "Epoch 3070/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.2825e-05 - acc: 1.0000 - val_loss: 1.3217 - val_acc: 0.9074\n",
      "Epoch 3071/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.2763e-05 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.9074\n",
      "Epoch 3072/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 2.2627e-05 - acc: 1.0000 - val_loss: 1.3232 - val_acc: 0.9074\n",
      "Epoch 3073/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.2571e-05 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.9074\n",
      "Epoch 3074/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.2399e-05 - acc: 1.0000 - val_loss: 1.3232 - val_acc: 0.9074\n",
      "Epoch 3075/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.2346e-05 - acc: 1.0000 - val_loss: 1.3187 - val_acc: 0.9074\n",
      "Epoch 3076/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.2196e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 3077/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.2139e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 3078/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.2028e-05 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9074\n",
      "Epoch 3079/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.1927e-05 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.9074\n",
      "Epoch 3080/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.1781e-05 - acc: 1.0000 - val_loss: 1.3163 - val_acc: 0.9074\n",
      "Epoch 3081/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.1719e-05 - acc: 1.0000 - val_loss: 1.3223 - val_acc: 0.9074\n",
      "Epoch 3082/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 2.1646e-05 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.9074\n",
      "Epoch 3083/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.1483e-05 - acc: 1.0000 - val_loss: 1.3193 - val_acc: 0.9074\n",
      "Epoch 3084/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 2.1382e-05 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.9074\n",
      "Epoch 3085/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.1283e-05 - acc: 1.0000 - val_loss: 1.3201 - val_acc: 0.9074\n",
      "Epoch 3086/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.1100e-05 - acc: 1.0000 - val_loss: 1.3146 - val_acc: 0.9074\n",
      "Epoch 3087/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.1132e-05 - acc: 1.0000 - val_loss: 1.3150 - val_acc: 0.9074\n",
      "Epoch 3088/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.1020e-05 - acc: 1.0000 - val_loss: 1.3197 - val_acc: 0.9074\n",
      "Epoch 3089/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.0925e-05 - acc: 1.0000 - val_loss: 1.3186 - val_acc: 0.9074\n",
      "Epoch 3090/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.0844e-05 - acc: 1.0000 - val_loss: 1.3175 - val_acc: 0.9074\n",
      "Epoch 3091/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 2.0697e-05 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.9074\n",
      "Epoch 3092/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 2.0660e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.9074\n",
      "Epoch 3093/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0506e-05 - acc: 1.0000 - val_loss: 1.3182 - val_acc: 0.9074\n",
      "Epoch 3094/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0402e-05 - acc: 1.0000 - val_loss: 1.3164 - val_acc: 0.9074\n",
      "Epoch 3095/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0353e-05 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9074\n",
      "Epoch 3096/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0232e-05 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.9074\n",
      "Epoch 3097/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 2.0181e-05 - acc: 1.0000 - val_loss: 1.3173 - val_acc: 0.9074\n",
      "Epoch 3098/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 2.0003e-05 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.9074\n",
      "Epoch 3099/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.9951e-05 - acc: 1.0000 - val_loss: 1.3158 - val_acc: 0.9074\n",
      "Epoch 3100/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9885e-05 - acc: 1.0000 - val_loss: 1.3182 - val_acc: 0.9074\n",
      "Epoch 3101/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.9772e-05 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9074\n",
      "Epoch 3102/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.9716e-05 - acc: 1.0000 - val_loss: 1.3175 - val_acc: 0.9074\n",
      "Epoch 3103/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.9591e-05 - acc: 1.0000 - val_loss: 1.3171 - val_acc: 0.9074\n",
      "Epoch 3104/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.9495e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 3105/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9452e-05 - acc: 1.0000 - val_loss: 1.3175 - val_acc: 0.9074\n",
      "Epoch 3106/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.9354e-05 - acc: 1.0000 - val_loss: 1.3199 - val_acc: 0.9074\n",
      "Epoch 3107/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.9242e-05 - acc: 1.0000 - val_loss: 1.3180 - val_acc: 0.9074\n",
      "Epoch 3108/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9191e-05 - acc: 1.0000 - val_loss: 1.3177 - val_acc: 0.9074\n",
      "Epoch 3109/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.9054e-05 - acc: 1.0000 - val_loss: 1.3161 - val_acc: 0.9074\n",
      "Epoch 3110/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.9004e-05 - acc: 1.0000 - val_loss: 1.3154 - val_acc: 0.9074\n",
      "Epoch 3111/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.9024e-05 - acc: 1.0000 - val_loss: 1.3171 - val_acc: 0.9074\n",
      "Epoch 3112/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.8823e-05 - acc: 1.0000 - val_loss: 1.3169 - val_acc: 0.9074\n",
      "Epoch 3113/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.8817e-05 - acc: 1.0000 - val_loss: 1.3174 - val_acc: 0.9074\n",
      "Epoch 3114/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.8719e-05 - acc: 1.0000 - val_loss: 1.3177 - val_acc: 0.9074\n",
      "Epoch 3115/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.8578e-05 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.9074\n",
      "Epoch 3116/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.8562e-05 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.9074\n",
      "Epoch 3117/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.8404e-05 - acc: 1.0000 - val_loss: 1.3182 - val_acc: 0.9074\n",
      "Epoch 3118/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.8402e-05 - acc: 1.0000 - val_loss: 1.3163 - val_acc: 0.9074\n",
      "Epoch 3119/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.8278e-05 - acc: 1.0000 - val_loss: 1.3174 - val_acc: 0.9074\n",
      "Epoch 3120/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.8181e-05 - acc: 1.0000 - val_loss: 1.3149 - val_acc: 0.9074\n",
      "Epoch 3121/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.8129e-05 - acc: 1.0000 - val_loss: 1.3153 - val_acc: 0.9074\n",
      "Epoch 3122/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.8043e-05 - acc: 1.0000 - val_loss: 1.3175 - val_acc: 0.9074\n",
      "Epoch 3123/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.7965e-05 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.9074\n",
      "Epoch 3124/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.7904e-05 - acc: 1.0000 - val_loss: 1.3212 - val_acc: 0.9074\n",
      "Epoch 3125/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.7814e-05 - acc: 1.0000 - val_loss: 1.3160 - val_acc: 0.9074\n",
      "Epoch 3126/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7683e-05 - acc: 1.0000 - val_loss: 1.3171 - val_acc: 0.9074\n",
      "Epoch 3127/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7638e-05 - acc: 1.0000 - val_loss: 1.3152 - val_acc: 0.9074\n",
      "Epoch 3128/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.7564e-05 - acc: 1.0000 - val_loss: 1.3157 - val_acc: 0.9074\n",
      "Epoch 3129/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.7505e-05 - acc: 1.0000 - val_loss: 1.3171 - val_acc: 0.9074\n",
      "Epoch 3130/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.7428e-05 - acc: 1.0000 - val_loss: 1.3197 - val_acc: 0.9074\n",
      "Epoch 3131/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.7328e-05 - acc: 1.0000 - val_loss: 1.3171 - val_acc: 0.9074\n",
      "Epoch 3132/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7225e-05 - acc: 1.0000 - val_loss: 1.3166 - val_acc: 0.9074\n",
      "Epoch 3133/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7169e-05 - acc: 1.0000 - val_loss: 1.3158 - val_acc: 0.9074\n",
      "Epoch 3134/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.7081e-05 - acc: 1.0000 - val_loss: 1.3156 - val_acc: 0.9074\n",
      "Epoch 3135/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.7058e-05 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9074\n",
      "Epoch 3136/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.6978e-05 - acc: 1.0000 - val_loss: 1.3158 - val_acc: 0.9074\n",
      "Epoch 3137/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.6917e-05 - acc: 1.0000 - val_loss: 1.3151 - val_acc: 0.9074\n",
      "Epoch 3138/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 1.6805e-05 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.9074\n",
      "Epoch 3139/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 1.6727e-05 - acc: 1.0000 - val_loss: 1.3162 - val_acc: 0.9074\n",
      "Epoch 3140/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.6672e-05 - acc: 1.0000 - val_loss: 1.3166 - val_acc: 0.9074\n",
      "Epoch 3141/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.6596e-05 - acc: 1.0000 - val_loss: 1.3176 - val_acc: 0.9074\n",
      "Epoch 3142/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 1.6518e-05 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.9074\n",
      "Epoch 3143/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.6492e-05 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9074\n",
      "Epoch 3144/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.6363e-05 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.9074\n",
      "Epoch 3145/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6290e-05 - acc: 1.0000 - val_loss: 1.3160 - val_acc: 0.9074\n",
      "Epoch 3146/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.6227e-05 - acc: 1.0000 - val_loss: 1.3156 - val_acc: 0.9074\n",
      "Epoch 3147/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.6168e-05 - acc: 1.0000 - val_loss: 1.3166 - val_acc: 0.9074\n",
      "Epoch 3148/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.6099e-05 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9074\n",
      "Epoch 3149/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.6036e-05 - acc: 1.0000 - val_loss: 1.3145 - val_acc: 0.9074\n",
      "Epoch 3150/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 1.5951e-05 - acc: 1.0000 - val_loss: 1.3166 - val_acc: 0.9074\n",
      "Epoch 3151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 93us/step - loss: 1.5898e-05 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.9074\n",
      "Epoch 3152/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5860e-05 - acc: 1.0000 - val_loss: 1.3162 - val_acc: 0.9074\n",
      "Epoch 3153/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.5777e-05 - acc: 1.0000 - val_loss: 1.3146 - val_acc: 0.9074\n",
      "Epoch 3154/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.5687e-05 - acc: 1.0000 - val_loss: 1.3157 - val_acc: 0.9074\n",
      "Epoch 3155/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.5587e-05 - acc: 1.0000 - val_loss: 1.3147 - val_acc: 0.9074\n",
      "Epoch 3156/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.5546e-05 - acc: 1.0000 - val_loss: 1.3123 - val_acc: 0.9074\n",
      "Epoch 3157/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.5491e-05 - acc: 1.0000 - val_loss: 1.3127 - val_acc: 0.9074\n",
      "Epoch 3158/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5416e-05 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.9074\n",
      "Epoch 3159/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.5377e-05 - acc: 1.0000 - val_loss: 1.3158 - val_acc: 0.9074\n",
      "Epoch 3160/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5296e-05 - acc: 1.0000 - val_loss: 1.3166 - val_acc: 0.9074\n",
      "Epoch 3161/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.5199e-05 - acc: 1.0000 - val_loss: 1.3155 - val_acc: 0.9074\n",
      "Epoch 3162/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.5175e-05 - acc: 1.0000 - val_loss: 1.3149 - val_acc: 0.9074\n",
      "Epoch 3163/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.5081e-05 - acc: 1.0000 - val_loss: 1.3130 - val_acc: 0.9074\n",
      "Epoch 3164/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.5034e-05 - acc: 1.0000 - val_loss: 1.3131 - val_acc: 0.9074\n",
      "Epoch 3165/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4942e-05 - acc: 1.0000 - val_loss: 1.3136 - val_acc: 0.9074\n",
      "Epoch 3166/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.4883e-05 - acc: 1.0000 - val_loss: 1.3167 - val_acc: 0.9074\n",
      "Epoch 3167/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4842e-05 - acc: 1.0000 - val_loss: 1.3130 - val_acc: 0.9074\n",
      "Epoch 3168/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4753e-05 - acc: 1.0000 - val_loss: 1.3109 - val_acc: 0.9074\n",
      "Epoch 3169/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.4688e-05 - acc: 1.0000 - val_loss: 1.3147 - val_acc: 0.9074\n",
      "Epoch 3170/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.4655e-05 - acc: 1.0000 - val_loss: 1.3182 - val_acc: 0.9074\n",
      "Epoch 3171/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.4578e-05 - acc: 1.0000 - val_loss: 1.3147 - val_acc: 0.9074\n",
      "Epoch 3172/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4490e-05 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9074\n",
      "Epoch 3173/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4444e-05 - acc: 1.0000 - val_loss: 1.3146 - val_acc: 0.9074\n",
      "Epoch 3174/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4400e-05 - acc: 1.0000 - val_loss: 1.3138 - val_acc: 0.9074\n",
      "Epoch 3175/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.4332e-05 - acc: 1.0000 - val_loss: 1.3124 - val_acc: 0.9074\n",
      "Epoch 3176/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.4258e-05 - acc: 1.0000 - val_loss: 1.3121 - val_acc: 0.9074\n",
      "Epoch 3177/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4203e-05 - acc: 1.0000 - val_loss: 1.3139 - val_acc: 0.9074\n",
      "Epoch 3178/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.4122e-05 - acc: 1.0000 - val_loss: 1.3175 - val_acc: 0.9074\n",
      "Epoch 3179/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.4054e-05 - acc: 1.0000 - val_loss: 1.3133 - val_acc: 0.9074\n",
      "Epoch 3180/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.4031e-05 - acc: 1.0000 - val_loss: 1.3152 - val_acc: 0.9074\n",
      "Epoch 3181/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.4000e-05 - acc: 1.0000 - val_loss: 1.3129 - val_acc: 0.9074\n",
      "Epoch 3182/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3887e-05 - acc: 1.0000 - val_loss: 1.3124 - val_acc: 0.9074\n",
      "Epoch 3183/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.3825e-05 - acc: 1.0000 - val_loss: 1.3150 - val_acc: 0.9074\n",
      "Epoch 3184/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.3800e-05 - acc: 1.0000 - val_loss: 1.3120 - val_acc: 0.9074\n",
      "Epoch 3185/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3735e-05 - acc: 1.0000 - val_loss: 1.3141 - val_acc: 0.9074\n",
      "Epoch 3186/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3661e-05 - acc: 1.0000 - val_loss: 1.3164 - val_acc: 0.9074\n",
      "Epoch 3187/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.3649e-05 - acc: 1.0000 - val_loss: 1.3144 - val_acc: 0.9074\n",
      "Epoch 3188/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.3555e-05 - acc: 1.0000 - val_loss: 1.3127 - val_acc: 0.9074\n",
      "Epoch 3189/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.3530e-05 - acc: 1.0000 - val_loss: 1.3123 - val_acc: 0.9074\n",
      "Epoch 3190/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3460e-05 - acc: 1.0000 - val_loss: 1.3106 - val_acc: 0.9074\n",
      "Epoch 3191/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.3397e-05 - acc: 1.0000 - val_loss: 1.3125 - val_acc: 0.9074\n",
      "Epoch 3192/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3346e-05 - acc: 1.0000 - val_loss: 1.3124 - val_acc: 0.9074\n",
      "Epoch 3193/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.3299e-05 - acc: 1.0000 - val_loss: 1.3153 - val_acc: 0.9074\n",
      "Epoch 3194/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.3235e-05 - acc: 1.0000 - val_loss: 1.3141 - val_acc: 0.9074\n",
      "Epoch 3195/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.3176e-05 - acc: 1.0000 - val_loss: 1.3117 - val_acc: 0.9074\n",
      "Epoch 3196/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.3113e-05 - acc: 1.0000 - val_loss: 1.3130 - val_acc: 0.9074\n",
      "Epoch 3197/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.3076e-05 - acc: 1.0000 - val_loss: 1.3081 - val_acc: 0.9074\n",
      "Epoch 3198/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.3034e-05 - acc: 1.0000 - val_loss: 1.3102 - val_acc: 0.9074\n",
      "Epoch 3199/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2948e-05 - acc: 1.0000 - val_loss: 1.3130 - val_acc: 0.9074\n",
      "Epoch 3200/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2902e-05 - acc: 1.0000 - val_loss: 1.3102 - val_acc: 0.9074\n",
      "Epoch 3201/10000\n",
      "216/216 [==============================] - 0s 157us/step - loss: 1.2864e-05 - acc: 1.0000 - val_loss: 1.3106 - val_acc: 0.9074\n",
      "Epoch 3202/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2800e-05 - acc: 1.0000 - val_loss: 1.3119 - val_acc: 0.9074\n",
      "Epoch 3203/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.2746e-05 - acc: 1.0000 - val_loss: 1.3121 - val_acc: 0.9074\n",
      "Epoch 3204/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.2696e-05 - acc: 1.0000 - val_loss: 1.3130 - val_acc: 0.9074\n",
      "Epoch 3205/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2650e-05 - acc: 1.0000 - val_loss: 1.3077 - val_acc: 0.9074\n",
      "Epoch 3206/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2577e-05 - acc: 1.0000 - val_loss: 1.3093 - val_acc: 0.9074\n",
      "Epoch 3207/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2512e-05 - acc: 1.0000 - val_loss: 1.3104 - val_acc: 0.9074\n",
      "Epoch 3208/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.2485e-05 - acc: 1.0000 - val_loss: 1.3104 - val_acc: 0.9074\n",
      "Epoch 3209/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.2405e-05 - acc: 1.0000 - val_loss: 1.3135 - val_acc: 0.9074\n",
      "Epoch 3210/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2387e-05 - acc: 1.0000 - val_loss: 1.3109 - val_acc: 0.9074\n",
      "Epoch 3211/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2287e-05 - acc: 1.0000 - val_loss: 1.3090 - val_acc: 0.9074\n",
      "Epoch 3212/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.2281e-05 - acc: 1.0000 - val_loss: 1.3118 - val_acc: 0.9074\n",
      "Epoch 3213/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.2208e-05 - acc: 1.0000 - val_loss: 1.3130 - val_acc: 0.9074\n",
      "Epoch 3214/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.2123e-05 - acc: 1.0000 - val_loss: 1.3109 - val_acc: 0.9074\n",
      "Epoch 3215/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 1.2124e-05 - acc: 1.0000 - val_loss: 1.3095 - val_acc: 0.9074\n",
      "Epoch 3216/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.2088e-05 - acc: 1.0000 - val_loss: 1.3104 - val_acc: 0.9074\n",
      "Epoch 3217/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1992e-05 - acc: 1.0000 - val_loss: 1.3098 - val_acc: 0.9074\n",
      "Epoch 3218/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.1973e-05 - acc: 1.0000 - val_loss: 1.3101 - val_acc: 0.9074\n",
      "Epoch 3219/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1918e-05 - acc: 1.0000 - val_loss: 1.3098 - val_acc: 0.9074\n",
      "Epoch 3220/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.1877e-05 - acc: 1.0000 - val_loss: 1.3086 - val_acc: 0.9074\n",
      "Epoch 3221/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1847e-05 - acc: 1.0000 - val_loss: 1.3081 - val_acc: 0.9074\n",
      "Epoch 3222/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1756e-05 - acc: 1.0000 - val_loss: 1.3066 - val_acc: 0.9074\n",
      "Epoch 3223/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.1733e-05 - acc: 1.0000 - val_loss: 1.3073 - val_acc: 0.9074\n",
      "Epoch 3224/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1682e-05 - acc: 1.0000 - val_loss: 1.3084 - val_acc: 0.9074\n",
      "Epoch 3225/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1632e-05 - acc: 1.0000 - val_loss: 1.3076 - val_acc: 0.9074\n",
      "Epoch 3226/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1582e-05 - acc: 1.0000 - val_loss: 1.3088 - val_acc: 0.9074\n",
      "Epoch 3227/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1523e-05 - acc: 1.0000 - val_loss: 1.3081 - val_acc: 0.9074\n",
      "Epoch 3228/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1456e-05 - acc: 1.0000 - val_loss: 1.3106 - val_acc: 0.9074\n",
      "Epoch 3229/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1424e-05 - acc: 1.0000 - val_loss: 1.3092 - val_acc: 0.9074\n",
      "Epoch 3230/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1395e-05 - acc: 1.0000 - val_loss: 1.3080 - val_acc: 0.9074\n",
      "Epoch 3231/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1339e-05 - acc: 1.0000 - val_loss: 1.3101 - val_acc: 0.9074\n",
      "Epoch 3232/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 1.1314e-05 - acc: 1.0000 - val_loss: 1.3083 - val_acc: 0.9074\n",
      "Epoch 3233/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.1229e-05 - acc: 1.0000 - val_loss: 1.3093 - val_acc: 0.9074\n",
      "Epoch 3234/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.1213e-05 - acc: 1.0000 - val_loss: 1.3073 - val_acc: 0.9074\n",
      "Epoch 3235/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1183e-05 - acc: 1.0000 - val_loss: 1.3086 - val_acc: 0.9074\n",
      "Epoch 3236/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 1.1100e-05 - acc: 1.0000 - val_loss: 1.3088 - val_acc: 0.9074\n",
      "Epoch 3237/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1083e-05 - acc: 1.0000 - val_loss: 1.3056 - val_acc: 0.9074\n",
      "Epoch 3238/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.1040e-05 - acc: 1.0000 - val_loss: 1.3079 - val_acc: 0.9074\n",
      "Epoch 3239/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0991e-05 - acc: 1.0000 - val_loss: 1.3053 - val_acc: 0.9074\n",
      "Epoch 3240/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.0938e-05 - acc: 1.0000 - val_loss: 1.3092 - val_acc: 0.9074\n",
      "Epoch 3241/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0908e-05 - acc: 1.0000 - val_loss: 1.3098 - val_acc: 0.9074\n",
      "Epoch 3242/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0842e-05 - acc: 1.0000 - val_loss: 1.3066 - val_acc: 0.9074\n",
      "Epoch 3243/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0801e-05 - acc: 1.0000 - val_loss: 1.3052 - val_acc: 0.9074\n",
      "Epoch 3244/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.0745e-05 - acc: 1.0000 - val_loss: 1.3081 - val_acc: 0.9074\n",
      "Epoch 3245/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0736e-05 - acc: 1.0000 - val_loss: 1.3086 - val_acc: 0.9074\n",
      "Epoch 3246/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0692e-05 - acc: 1.0000 - val_loss: 1.3069 - val_acc: 0.9074\n",
      "Epoch 3247/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0639e-05 - acc: 1.0000 - val_loss: 1.3077 - val_acc: 0.9074\n",
      "Epoch 3248/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 1.0594e-05 - acc: 1.0000 - val_loss: 1.3082 - val_acc: 0.9074\n",
      "Epoch 3249/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0550e-05 - acc: 1.0000 - val_loss: 1.3070 - val_acc: 0.9074\n",
      "Epoch 3250/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 1.0532e-05 - acc: 1.0000 - val_loss: 1.3043 - val_acc: 0.9074\n",
      "Epoch 3251/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 1.0458e-05 - acc: 1.0000 - val_loss: 1.3055 - val_acc: 0.9074\n",
      "Epoch 3252/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0398e-05 - acc: 1.0000 - val_loss: 1.3057 - val_acc: 0.9074\n",
      "Epoch 3253/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0378e-05 - acc: 1.0000 - val_loss: 1.3059 - val_acc: 0.9074\n",
      "Epoch 3254/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0355e-05 - acc: 1.0000 - val_loss: 1.3045 - val_acc: 0.9074\n",
      "Epoch 3255/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 1.0283e-05 - acc: 1.0000 - val_loss: 1.3039 - val_acc: 0.9074\n",
      "Epoch 3256/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0270e-05 - acc: 1.0000 - val_loss: 1.3078 - val_acc: 0.9074\n",
      "Epoch 3257/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0209e-05 - acc: 1.0000 - val_loss: 1.3043 - val_acc: 0.9074\n",
      "Epoch 3258/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0176e-05 - acc: 1.0000 - val_loss: 1.3069 - val_acc: 0.9074\n",
      "Epoch 3259/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 1.0140e-05 - acc: 1.0000 - val_loss: 1.3047 - val_acc: 0.9074\n",
      "Epoch 3260/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 1.0093e-05 - acc: 1.0000 - val_loss: 1.3042 - val_acc: 0.9074\n",
      "Epoch 3261/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0054e-05 - acc: 1.0000 - val_loss: 1.3045 - val_acc: 0.9074\n",
      "Epoch 3262/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 1.0008e-05 - acc: 1.0000 - val_loss: 1.3036 - val_acc: 0.9074\n",
      "Epoch 3263/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.9768e-06 - acc: 1.0000 - val_loss: 1.3029 - val_acc: 0.9074\n",
      "Epoch 3264/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 9.9385e-06 - acc: 1.0000 - val_loss: 1.3021 - val_acc: 0.9074\n",
      "Epoch 3265/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 93us/step - loss: 9.9100e-06 - acc: 1.0000 - val_loss: 1.3058 - val_acc: 0.9074\n",
      "Epoch 3266/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.8645e-06 - acc: 1.0000 - val_loss: 1.3047 - val_acc: 0.9074\n",
      "Epoch 3267/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.8248e-06 - acc: 1.0000 - val_loss: 1.3033 - val_acc: 0.9074\n",
      "Epoch 3268/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.7787e-06 - acc: 1.0000 - val_loss: 1.3036 - val_acc: 0.9074\n",
      "Epoch 3269/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.7240e-06 - acc: 1.0000 - val_loss: 1.3024 - val_acc: 0.9074\n",
      "Epoch 3270/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.7072e-06 - acc: 1.0000 - val_loss: 1.3034 - val_acc: 0.9074\n",
      "Epoch 3271/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.6854e-06 - acc: 1.0000 - val_loss: 1.3027 - val_acc: 0.9074\n",
      "Epoch 3272/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.6330e-06 - acc: 1.0000 - val_loss: 1.3025 - val_acc: 0.9074\n",
      "Epoch 3273/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 9.5955e-06 - acc: 1.0000 - val_loss: 1.3030 - val_acc: 0.9074\n",
      "Epoch 3274/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.5513e-06 - acc: 1.0000 - val_loss: 1.3027 - val_acc: 0.9074\n",
      "Epoch 3275/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.5334e-06 - acc: 1.0000 - val_loss: 1.3045 - val_acc: 0.9074\n",
      "Epoch 3276/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.4674e-06 - acc: 1.0000 - val_loss: 1.3049 - val_acc: 0.9074\n",
      "Epoch 3277/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.4299e-06 - acc: 1.0000 - val_loss: 1.3028 - val_acc: 0.9074\n",
      "Epoch 3278/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.3951e-06 - acc: 1.0000 - val_loss: 1.3018 - val_acc: 0.9074\n",
      "Epoch 3279/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.3567e-06 - acc: 1.0000 - val_loss: 1.3031 - val_acc: 0.9074\n",
      "Epoch 3280/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 9.3167e-06 - acc: 1.0000 - val_loss: 1.2998 - val_acc: 0.9074\n",
      "Epoch 3281/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.2781e-06 - acc: 1.0000 - val_loss: 1.3023 - val_acc: 0.9074\n",
      "Epoch 3282/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 9.2439e-06 - acc: 1.0000 - val_loss: 1.3011 - val_acc: 0.9074\n",
      "Epoch 3283/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 9.2003e-06 - acc: 1.0000 - val_loss: 1.3008 - val_acc: 0.9074\n",
      "Epoch 3284/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 9.1757e-06 - acc: 1.0000 - val_loss: 1.3024 - val_acc: 0.9074\n",
      "Epoch 3285/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.1437e-06 - acc: 1.0000 - val_loss: 1.3022 - val_acc: 0.9074\n",
      "Epoch 3286/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.0844e-06 - acc: 1.0000 - val_loss: 1.3046 - val_acc: 0.9074\n",
      "Epoch 3287/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 9.0430e-06 - acc: 1.0000 - val_loss: 1.3048 - val_acc: 0.9074\n",
      "Epoch 3288/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 9.0361e-06 - acc: 1.0000 - val_loss: 1.3039 - val_acc: 0.9074\n",
      "Epoch 3289/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.9966e-06 - acc: 1.0000 - val_loss: 1.3032 - val_acc: 0.9074\n",
      "Epoch 3290/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.9492e-06 - acc: 1.0000 - val_loss: 1.2999 - val_acc: 0.9074\n",
      "Epoch 3291/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.9412e-06 - acc: 1.0000 - val_loss: 1.3008 - val_acc: 0.9074\n",
      "Epoch 3292/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 8.8920e-06 - acc: 1.0000 - val_loss: 1.2999 - val_acc: 0.9074\n",
      "Epoch 3293/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.8548e-06 - acc: 1.0000 - val_loss: 1.2987 - val_acc: 0.9074\n",
      "Epoch 3294/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 8.8043e-06 - acc: 1.0000 - val_loss: 1.3005 - val_acc: 0.9074\n",
      "Epoch 3295/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.7916e-06 - acc: 1.0000 - val_loss: 1.3030 - val_acc: 0.9074\n",
      "Epoch 3296/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 8.7618e-06 - acc: 1.0000 - val_loss: 1.3045 - val_acc: 0.9074\n",
      "Epoch 3297/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 8.7077e-06 - acc: 1.0000 - val_loss: 1.3034 - val_acc: 0.9074\n",
      "Epoch 3298/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.6751e-06 - acc: 1.0000 - val_loss: 1.3039 - val_acc: 0.9074\n",
      "Epoch 3299/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.6663e-06 - acc: 1.0000 - val_loss: 1.3040 - val_acc: 0.9074\n",
      "Epoch 3300/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.5968e-06 - acc: 1.0000 - val_loss: 1.3020 - val_acc: 0.9074\n",
      "Epoch 3301/10000\n",
      "216/216 [==============================] - ETA: 0s - loss: 1.3930e-05 - acc: 1.000 - 0s 106us/step - loss: 8.5876e-06 - acc: 1.0000 - val_loss: 1.3018 - val_acc: 0.9074\n",
      "Epoch 3302/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.5341e-06 - acc: 1.0000 - val_loss: 1.3008 - val_acc: 0.9074\n",
      "Epoch 3303/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 8.5256e-06 - acc: 1.0000 - val_loss: 1.3008 - val_acc: 0.9074\n",
      "Epoch 3304/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.4891e-06 - acc: 1.0000 - val_loss: 1.2995 - val_acc: 0.9074\n",
      "Epoch 3305/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.4397e-06 - acc: 1.0000 - val_loss: 1.3017 - val_acc: 0.9074\n",
      "Epoch 3306/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.4108e-06 - acc: 1.0000 - val_loss: 1.3014 - val_acc: 0.9074\n",
      "Epoch 3307/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 8.3981e-06 - acc: 1.0000 - val_loss: 1.2998 - val_acc: 0.9074\n",
      "Epoch 3308/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 8.3288e-06 - acc: 1.0000 - val_loss: 1.2974 - val_acc: 0.9074\n",
      "Epoch 3309/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.3031e-06 - acc: 1.0000 - val_loss: 1.2973 - val_acc: 0.9074\n",
      "Epoch 3310/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 8.2855e-06 - acc: 1.0000 - val_loss: 1.2964 - val_acc: 0.9074\n",
      "Epoch 3311/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 8.2419e-06 - acc: 1.0000 - val_loss: 1.3005 - val_acc: 0.9074\n",
      "Epoch 3312/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 8.2159e-06 - acc: 1.0000 - val_loss: 1.3014 - val_acc: 0.9074\n",
      "Epoch 3313/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.1842e-06 - acc: 1.0000 - val_loss: 1.2974 - val_acc: 0.9074\n",
      "Epoch 3314/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.1646e-06 - acc: 1.0000 - val_loss: 1.2984 - val_acc: 0.9074\n",
      "Epoch 3315/10000\n",
      "216/216 [==============================] - 0s 148us/step - loss: 8.1205e-06 - acc: 1.0000 - val_loss: 1.3004 - val_acc: 0.9074\n",
      "Epoch 3316/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 8.0882e-06 - acc: 1.0000 - val_loss: 1.2996 - val_acc: 0.9074\n",
      "Epoch 3317/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.0531e-06 - acc: 1.0000 - val_loss: 1.2991 - val_acc: 0.9074\n",
      "Epoch 3318/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 8.0291e-06 - acc: 1.0000 - val_loss: 1.2964 - val_acc: 0.9074\n",
      "Epoch 3319/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.9927e-06 - acc: 1.0000 - val_loss: 1.2993 - val_acc: 0.9074\n",
      "Epoch 3320/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 7.9513e-06 - acc: 1.0000 - val_loss: 1.2970 - val_acc: 0.9074\n",
      "Epoch 3321/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.9306e-06 - acc: 1.0000 - val_loss: 1.2966 - val_acc: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3322/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.9016e-06 - acc: 1.0000 - val_loss: 1.2963 - val_acc: 0.9074\n",
      "Epoch 3323/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.8699e-06 - acc: 1.0000 - val_loss: 1.2978 - val_acc: 0.9074\n",
      "Epoch 3324/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.8489e-06 - acc: 1.0000 - val_loss: 1.2972 - val_acc: 0.9074\n",
      "Epoch 3325/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.8219e-06 - acc: 1.0000 - val_loss: 1.2968 - val_acc: 0.9074\n",
      "Epoch 3326/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.7747e-06 - acc: 1.0000 - val_loss: 1.2972 - val_acc: 0.9074\n",
      "Epoch 3327/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.7507e-06 - acc: 1.0000 - val_loss: 1.2986 - val_acc: 0.9074\n",
      "Epoch 3328/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.7151e-06 - acc: 1.0000 - val_loss: 1.2988 - val_acc: 0.9074\n",
      "Epoch 3329/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.6864e-06 - acc: 1.0000 - val_loss: 1.2963 - val_acc: 0.9074\n",
      "Epoch 3330/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.6533e-06 - acc: 1.0000 - val_loss: 1.2985 - val_acc: 0.9074\n",
      "Epoch 3331/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 7.6546e-06 - acc: 1.0000 - val_loss: 1.2983 - val_acc: 0.9074\n",
      "Epoch 3332/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.6063e-06 - acc: 1.0000 - val_loss: 1.2980 - val_acc: 0.9074\n",
      "Epoch 3333/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.5666e-06 - acc: 1.0000 - val_loss: 1.2970 - val_acc: 0.9074\n",
      "Epoch 3334/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.5291e-06 - acc: 1.0000 - val_loss: 1.2979 - val_acc: 0.9074\n",
      "Epoch 3335/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.5095e-06 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.9074\n",
      "Epoch 3336/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 7.5076e-06 - acc: 1.0000 - val_loss: 1.2979 - val_acc: 0.9074\n",
      "Epoch 3337/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.4675e-06 - acc: 1.0000 - val_loss: 1.2963 - val_acc: 0.9074\n",
      "Epoch 3338/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.4239e-06 - acc: 1.0000 - val_loss: 1.2932 - val_acc: 0.9074\n",
      "Epoch 3339/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.4217e-06 - acc: 1.0000 - val_loss: 1.2950 - val_acc: 0.9074\n",
      "Epoch 3340/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.3610e-06 - acc: 1.0000 - val_loss: 1.2963 - val_acc: 0.9074\n",
      "Epoch 3341/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.3450e-06 - acc: 1.0000 - val_loss: 1.2921 - val_acc: 0.9074\n",
      "Epoch 3342/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.3246e-06 - acc: 1.0000 - val_loss: 1.2933 - val_acc: 0.9074\n",
      "Epoch 3343/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.2879e-06 - acc: 1.0000 - val_loss: 1.2946 - val_acc: 0.9074\n",
      "Epoch 3344/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.2617e-06 - acc: 1.0000 - val_loss: 1.2953 - val_acc: 0.9074\n",
      "Epoch 3345/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.2341e-06 - acc: 1.0000 - val_loss: 1.2943 - val_acc: 0.9074\n",
      "Epoch 3346/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.1979e-06 - acc: 1.0000 - val_loss: 1.2924 - val_acc: 0.9074\n",
      "Epoch 3347/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.1687e-06 - acc: 1.0000 - val_loss: 1.2945 - val_acc: 0.9074\n",
      "Epoch 3348/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.1394e-06 - acc: 1.0000 - val_loss: 1.2923 - val_acc: 0.9074\n",
      "Epoch 3349/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 7.1325e-06 - acc: 1.0000 - val_loss: 1.2946 - val_acc: 0.9074\n",
      "Epoch 3350/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 7.1088e-06 - acc: 1.0000 - val_loss: 1.2945 - val_acc: 0.9074\n",
      "Epoch 3351/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.0693e-06 - acc: 1.0000 - val_loss: 1.2932 - val_acc: 0.9074\n",
      "Epoch 3352/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 7.0448e-06 - acc: 1.0000 - val_loss: 1.2951 - val_acc: 0.9074\n",
      "Epoch 3353/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 7.0150e-06 - acc: 1.0000 - val_loss: 1.2951 - val_acc: 0.9074\n",
      "Epoch 3354/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.9863e-06 - acc: 1.0000 - val_loss: 1.2959 - val_acc: 0.9074\n",
      "Epoch 3355/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.9440e-06 - acc: 1.0000 - val_loss: 1.2934 - val_acc: 0.9074\n",
      "Epoch 3356/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.9344e-06 - acc: 1.0000 - val_loss: 1.2941 - val_acc: 0.9074\n",
      "Epoch 3357/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.9137e-06 - acc: 1.0000 - val_loss: 1.2939 - val_acc: 0.9074\n",
      "Epoch 3358/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.8875e-06 - acc: 1.0000 - val_loss: 1.2967 - val_acc: 0.9074\n",
      "Epoch 3359/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.8497e-06 - acc: 1.0000 - val_loss: 1.2932 - val_acc: 0.9074\n",
      "Epoch 3360/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.8356e-06 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.9074\n",
      "Epoch 3361/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.7986e-06 - acc: 1.0000 - val_loss: 1.2951 - val_acc: 0.9074\n",
      "Epoch 3362/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.7796e-06 - acc: 1.0000 - val_loss: 1.2931 - val_acc: 0.9074\n",
      "Epoch 3363/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.7702e-06 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.9074\n",
      "Epoch 3364/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.7213e-06 - acc: 1.0000 - val_loss: 1.2920 - val_acc: 0.9074\n",
      "Epoch 3365/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.6943e-06 - acc: 1.0000 - val_loss: 1.2945 - val_acc: 0.9074\n",
      "Epoch 3366/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.6706e-06 - acc: 1.0000 - val_loss: 1.2945 - val_acc: 0.9074\n",
      "Epoch 3367/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.6598e-06 - acc: 1.0000 - val_loss: 1.2942 - val_acc: 0.9074\n",
      "Epoch 3368/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.6306e-06 - acc: 1.0000 - val_loss: 1.2914 - val_acc: 0.9074\n",
      "Epoch 3369/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.5977e-06 - acc: 1.0000 - val_loss: 1.2930 - val_acc: 0.9074\n",
      "Epoch 3370/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 6.5756e-06 - acc: 1.0000 - val_loss: 1.2915 - val_acc: 0.9074\n",
      "Epoch 3371/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 6.5621e-06 - acc: 1.0000 - val_loss: 1.2926 - val_acc: 0.9074\n",
      "Epoch 3372/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.5323e-06 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.9074\n",
      "Epoch 3373/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.5067e-06 - acc: 1.0000 - val_loss: 1.2912 - val_acc: 0.9074\n",
      "Epoch 3374/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.4746e-06 - acc: 1.0000 - val_loss: 1.2901 - val_acc: 0.9074\n",
      "Epoch 3375/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.4493e-06 - acc: 1.0000 - val_loss: 1.2931 - val_acc: 0.9074\n",
      "Epoch 3376/10000\n",
      "216/216 [==============================] - 0s 139us/step - loss: 6.4225e-06 - acc: 1.0000 - val_loss: 1.2954 - val_acc: 0.9074\n",
      "Epoch 3377/10000\n",
      "216/216 [==============================] - 0s 143us/step - loss: 6.4012e-06 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.9074\n",
      "Epoch 3378/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 6.3695e-06 - acc: 1.0000 - val_loss: 1.2935 - val_acc: 0.9074\n",
      "Epoch 3379/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.3596e-06 - acc: 1.0000 - val_loss: 1.2922 - val_acc: 0.9074\n",
      "Epoch 3380/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 6.3328e-06 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.9074\n",
      "Epoch 3381/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.3135e-06 - acc: 1.0000 - val_loss: 1.2932 - val_acc: 0.9074\n",
      "Epoch 3382/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.2939e-06 - acc: 1.0000 - val_loss: 1.2929 - val_acc: 0.9074\n",
      "Epoch 3383/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.2644e-06 - acc: 1.0000 - val_loss: 1.2914 - val_acc: 0.9074\n",
      "Epoch 3384/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.2384e-06 - acc: 1.0000 - val_loss: 1.2936 - val_acc: 0.9074\n",
      "Epoch 3385/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.2006e-06 - acc: 1.0000 - val_loss: 1.2913 - val_acc: 0.9074\n",
      "Epoch 3386/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.1998e-06 - acc: 1.0000 - val_loss: 1.2907 - val_acc: 0.9074\n",
      "Epoch 3387/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.1727e-06 - acc: 1.0000 - val_loss: 1.2923 - val_acc: 0.9074\n",
      "Epoch 3388/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 6.1520e-06 - acc: 1.0000 - val_loss: 1.2934 - val_acc: 0.9074\n",
      "Epoch 3389/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.1247e-06 - acc: 1.0000 - val_loss: 1.2924 - val_acc: 0.9074\n",
      "Epoch 3390/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 6.1024e-06 - acc: 1.0000 - val_loss: 1.2926 - val_acc: 0.9074\n",
      "Epoch 3391/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.0866e-06 - acc: 1.0000 - val_loss: 1.2899 - val_acc: 0.9074\n",
      "Epoch 3392/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.0748e-06 - acc: 1.0000 - val_loss: 1.2912 - val_acc: 0.9074\n",
      "Epoch 3393/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 6.0359e-06 - acc: 1.0000 - val_loss: 1.2903 - val_acc: 0.9074\n",
      "Epoch 3394/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 6.0077e-06 - acc: 1.0000 - val_loss: 1.2923 - val_acc: 0.9074\n",
      "Epoch 3395/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 5.9970e-06 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.9074\n",
      "Epoch 3396/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 5.9663e-06 - acc: 1.0000 - val_loss: 1.2897 - val_acc: 0.9074\n",
      "Epoch 3397/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.9558e-06 - acc: 1.0000 - val_loss: 1.2908 - val_acc: 0.9074\n",
      "Epoch 3398/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.9161e-06 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.9074\n",
      "Epoch 3399/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.8968e-06 - acc: 1.0000 - val_loss: 1.2909 - val_acc: 0.9074\n",
      "Epoch 3400/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.9062e-06 - acc: 1.0000 - val_loss: 1.2906 - val_acc: 0.9074\n",
      "Epoch 3401/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.8645e-06 - acc: 1.0000 - val_loss: 1.2903 - val_acc: 0.9074\n",
      "Epoch 3402/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 5.8377e-06 - acc: 1.0000 - val_loss: 1.2919 - val_acc: 0.9074\n",
      "Epoch 3403/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.8187e-06 - acc: 1.0000 - val_loss: 1.2907 - val_acc: 0.9074\n",
      "Epoch 3404/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.7903e-06 - acc: 1.0000 - val_loss: 1.2908 - val_acc: 0.9074\n",
      "Epoch 3405/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.7743e-06 - acc: 1.0000 - val_loss: 1.2897 - val_acc: 0.9074\n",
      "Epoch 3406/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.7544e-06 - acc: 1.0000 - val_loss: 1.2894 - val_acc: 0.9074\n",
      "Epoch 3407/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.7351e-06 - acc: 1.0000 - val_loss: 1.2892 - val_acc: 0.9074\n",
      "Epoch 3408/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.7113e-06 - acc: 1.0000 - val_loss: 1.2911 - val_acc: 0.9074\n",
      "Epoch 3409/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 5.6907e-06 - acc: 1.0000 - val_loss: 1.2893 - val_acc: 0.9074\n",
      "Epoch 3410/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.6705e-06 - acc: 1.0000 - val_loss: 1.2913 - val_acc: 0.9074\n",
      "Epoch 3411/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.6498e-06 - acc: 1.0000 - val_loss: 1.2899 - val_acc: 0.9074\n",
      "Epoch 3412/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.6247e-06 - acc: 1.0000 - val_loss: 1.2897 - val_acc: 0.9074\n",
      "Epoch 3413/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.6076e-06 - acc: 1.0000 - val_loss: 1.2906 - val_acc: 0.9074\n",
      "Epoch 3414/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.5891e-06 - acc: 1.0000 - val_loss: 1.2899 - val_acc: 0.9074\n",
      "Epoch 3415/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.5720e-06 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.9074\n",
      "Epoch 3416/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.5568e-06 - acc: 1.0000 - val_loss: 1.2912 - val_acc: 0.9074\n",
      "Epoch 3417/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 5.5207e-06 - acc: 1.0000 - val_loss: 1.2903 - val_acc: 0.9074\n",
      "Epoch 3418/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.5005e-06 - acc: 1.0000 - val_loss: 1.2879 - val_acc: 0.9074\n",
      "Epoch 3419/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 5.4914e-06 - acc: 1.0000 - val_loss: 1.2884 - val_acc: 0.9074\n",
      "Epoch 3420/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 5.4575e-06 - acc: 1.0000 - val_loss: 1.2901 - val_acc: 0.9074\n",
      "Epoch 3421/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.4520e-06 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.9074\n",
      "Epoch 3422/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.4197e-06 - acc: 1.0000 - val_loss: 1.2919 - val_acc: 0.9074\n",
      "Epoch 3423/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.4012e-06 - acc: 1.0000 - val_loss: 1.2880 - val_acc: 0.9074\n",
      "Epoch 3424/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.3907e-06 - acc: 1.0000 - val_loss: 1.2918 - val_acc: 0.9074\n",
      "Epoch 3425/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.3766e-06 - acc: 1.0000 - val_loss: 1.2878 - val_acc: 0.9074\n",
      "Epoch 3426/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.3457e-06 - acc: 1.0000 - val_loss: 1.2895 - val_acc: 0.9074\n",
      "Epoch 3427/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.3327e-06 - acc: 1.0000 - val_loss: 1.2906 - val_acc: 0.9074\n",
      "Epoch 3428/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.3029e-06 - acc: 1.0000 - val_loss: 1.2877 - val_acc: 0.9074\n",
      "Epoch 3429/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.2980e-06 - acc: 1.0000 - val_loss: 1.2883 - val_acc: 0.9074\n",
      "Epoch 3430/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.2715e-06 - acc: 1.0000 - val_loss: 1.2872 - val_acc: 0.9074\n",
      "Epoch 3431/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.2497e-06 - acc: 1.0000 - val_loss: 1.2888 - val_acc: 0.9074\n",
      "Epoch 3432/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.2237e-06 - acc: 1.0000 - val_loss: 1.2885 - val_acc: 0.9074\n",
      "Epoch 3433/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 5.2130e-06 - acc: 1.0000 - val_loss: 1.2883 - val_acc: 0.9074\n",
      "Epoch 3434/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 5.2080e-06 - acc: 1.0000 - val_loss: 1.2866 - val_acc: 0.9074\n",
      "Epoch 3435/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 5.1788e-06 - acc: 1.0000 - val_loss: 1.2872 - val_acc: 0.9074\n",
      "Epoch 3436/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 93us/step - loss: 5.1688e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3437/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.1349e-06 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.9074\n",
      "Epoch 3438/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.1247e-06 - acc: 1.0000 - val_loss: 1.2862 - val_acc: 0.9074\n",
      "Epoch 3439/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.1117e-06 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.9074\n",
      "Epoch 3440/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 5.0808e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3441/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.0681e-06 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.9074\n",
      "Epoch 3442/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 5.0510e-06 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.9074\n",
      "Epoch 3443/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 5.0347e-06 - acc: 1.0000 - val_loss: 1.2885 - val_acc: 0.9074\n",
      "Epoch 3444/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 5.0104e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3445/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.9961e-06 - acc: 1.0000 - val_loss: 1.2858 - val_acc: 0.9074\n",
      "Epoch 3446/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.9732e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3447/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.9566e-06 - acc: 1.0000 - val_loss: 1.2860 - val_acc: 0.9074\n",
      "Epoch 3448/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.9271e-06 - acc: 1.0000 - val_loss: 1.2877 - val_acc: 0.9074\n",
      "Epoch 3449/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.9216e-06 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.9074\n",
      "Epoch 3450/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.9028e-06 - acc: 1.0000 - val_loss: 1.2899 - val_acc: 0.9074\n",
      "Epoch 3451/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.8965e-06 - acc: 1.0000 - val_loss: 1.2872 - val_acc: 0.9074\n",
      "Epoch 3452/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.8697e-06 - acc: 1.0000 - val_loss: 1.2865 - val_acc: 0.9074\n",
      "Epoch 3453/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 4.8570e-06 - acc: 1.0000 - val_loss: 1.2853 - val_acc: 0.9074\n",
      "Epoch 3454/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.8355e-06 - acc: 1.0000 - val_loss: 1.2864 - val_acc: 0.9074\n",
      "Epoch 3455/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.8095e-06 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.9074\n",
      "Epoch 3456/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 4.8084e-06 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.9074\n",
      "Epoch 3457/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.7748e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3458/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 4.7690e-06 - acc: 1.0000 - val_loss: 1.2878 - val_acc: 0.9074\n",
      "Epoch 3459/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.7488e-06 - acc: 1.0000 - val_loss: 1.2865 - val_acc: 0.9074\n",
      "Epoch 3460/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.7447e-06 - acc: 1.0000 - val_loss: 1.2866 - val_acc: 0.9074\n",
      "Epoch 3461/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.7221e-06 - acc: 1.0000 - val_loss: 1.2867 - val_acc: 0.9074\n",
      "Epoch 3462/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.7069e-06 - acc: 1.0000 - val_loss: 1.2849 - val_acc: 0.9074\n",
      "Epoch 3463/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 4.6820e-06 - acc: 1.0000 - val_loss: 1.2852 - val_acc: 0.9074\n",
      "Epoch 3464/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.6732e-06 - acc: 1.0000 - val_loss: 1.2863 - val_acc: 0.9074\n",
      "Epoch 3465/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.6426e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3466/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.6387e-06 - acc: 1.0000 - val_loss: 1.2860 - val_acc: 0.9074\n",
      "Epoch 3467/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.6227e-06 - acc: 1.0000 - val_loss: 1.2855 - val_acc: 0.9074\n",
      "Epoch 3468/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.6111e-06 - acc: 1.0000 - val_loss: 1.2867 - val_acc: 0.9074\n",
      "Epoch 3469/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.5890e-06 - acc: 1.0000 - val_loss: 1.2864 - val_acc: 0.9074\n",
      "Epoch 3470/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.5764e-06 - acc: 1.0000 - val_loss: 1.2885 - val_acc: 0.9074\n",
      "Epoch 3471/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.5631e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3472/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.5402e-06 - acc: 1.0000 - val_loss: 1.2857 - val_acc: 0.9074\n",
      "Epoch 3473/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.5112e-06 - acc: 1.0000 - val_loss: 1.2858 - val_acc: 0.9074\n",
      "Epoch 3474/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.5170e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3475/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 4.4927e-06 - acc: 1.0000 - val_loss: 1.2870 - val_acc: 0.9074\n",
      "Epoch 3476/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.4729e-06 - acc: 1.0000 - val_loss: 1.2891 - val_acc: 0.9074\n",
      "Epoch 3477/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.4657e-06 - acc: 1.0000 - val_loss: 1.2879 - val_acc: 0.9074\n",
      "Epoch 3478/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 4.4422e-06 - acc: 1.0000 - val_loss: 1.2857 - val_acc: 0.9074\n",
      "Epoch 3479/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.4337e-06 - acc: 1.0000 - val_loss: 1.2871 - val_acc: 0.9074\n",
      "Epoch 3480/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.4088e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3481/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 4.3931e-06 - acc: 1.0000 - val_loss: 1.2859 - val_acc: 0.9074\n",
      "Epoch 3482/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.3837e-06 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.9074\n",
      "Epoch 3483/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.3617e-06 - acc: 1.0000 - val_loss: 1.2873 - val_acc: 0.9074\n",
      "Epoch 3484/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.3490e-06 - acc: 1.0000 - val_loss: 1.2849 - val_acc: 0.9074\n",
      "Epoch 3485/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 4.3330e-06 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.9074\n",
      "Epoch 3486/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.3139e-06 - acc: 1.0000 - val_loss: 1.2876 - val_acc: 0.9074\n",
      "Epoch 3487/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 4.3222e-06 - acc: 1.0000 - val_loss: 1.2872 - val_acc: 0.9074\n",
      "Epoch 3488/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.2891e-06 - acc: 1.0000 - val_loss: 1.2889 - val_acc: 0.9074\n",
      "Epoch 3489/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.2684e-06 - acc: 1.0000 - val_loss: 1.2861 - val_acc: 0.9074\n",
      "Epoch 3490/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.2568e-06 - acc: 1.0000 - val_loss: 1.2868 - val_acc: 0.9074\n",
      "Epoch 3491/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.2527e-06 - acc: 1.0000 - val_loss: 1.2854 - val_acc: 0.9074\n",
      "Epoch 3492/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.2408e-06 - acc: 1.0000 - val_loss: 1.2860 - val_acc: 0.9074\n",
      "Epoch 3493/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.2311e-06 - acc: 1.0000 - val_loss: 1.2866 - val_acc: 0.9074\n",
      "Epoch 3494/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.2044e-06 - acc: 1.0000 - val_loss: 1.2881 - val_acc: 0.9074\n",
      "Epoch 3495/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 4.1782e-06 - acc: 1.0000 - val_loss: 1.2888 - val_acc: 0.9074\n",
      "Epoch 3496/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.1748e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3497/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 4.1655e-06 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.9074\n",
      "Epoch 3498/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.1472e-06 - acc: 1.0000 - val_loss: 1.2858 - val_acc: 0.9074\n",
      "Epoch 3499/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.1293e-06 - acc: 1.0000 - val_loss: 1.2861 - val_acc: 0.9074\n",
      "Epoch 3500/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.1103e-06 - acc: 1.0000 - val_loss: 1.2870 - val_acc: 0.9074\n",
      "Epoch 3501/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.0967e-06 - acc: 1.0000 - val_loss: 1.2891 - val_acc: 0.9074\n",
      "Epoch 3502/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.0854e-06 - acc: 1.0000 - val_loss: 1.2878 - val_acc: 0.9074\n",
      "Epoch 3503/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 4.0689e-06 - acc: 1.0000 - val_loss: 1.2868 - val_acc: 0.9074\n",
      "Epoch 3504/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.0672e-06 - acc: 1.0000 - val_loss: 1.2865 - val_acc: 0.9074\n",
      "Epoch 3505/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.0424e-06 - acc: 1.0000 - val_loss: 1.2863 - val_acc: 0.9074\n",
      "Epoch 3506/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 4.0316e-06 - acc: 1.0000 - val_loss: 1.2887 - val_acc: 0.9074\n",
      "Epoch 3507/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 4.0159e-06 - acc: 1.0000 - val_loss: 1.2888 - val_acc: 0.9074\n",
      "Epoch 3508/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 4.0002e-06 - acc: 1.0000 - val_loss: 1.2897 - val_acc: 0.9074\n",
      "Epoch 3509/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.9944e-06 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.9074\n",
      "Epoch 3510/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.9739e-06 - acc: 1.0000 - val_loss: 1.2892 - val_acc: 0.9074\n",
      "Epoch 3511/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.9687e-06 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.9074\n",
      "Epoch 3512/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.9486e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3513/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.9406e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3514/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.9248e-06 - acc: 1.0000 - val_loss: 1.2865 - val_acc: 0.9074\n",
      "Epoch 3515/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.9099e-06 - acc: 1.0000 - val_loss: 1.2862 - val_acc: 0.9074\n",
      "Epoch 3516/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.9066e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3517/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.8862e-06 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.9074\n",
      "Epoch 3518/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.8757e-06 - acc: 1.0000 - val_loss: 1.2876 - val_acc: 0.9074\n",
      "Epoch 3519/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.8567e-06 - acc: 1.0000 - val_loss: 1.2855 - val_acc: 0.9074\n",
      "Epoch 3520/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.8622e-06 - acc: 1.0000 - val_loss: 1.2870 - val_acc: 0.9074\n",
      "Epoch 3521/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.8368e-06 - acc: 1.0000 - val_loss: 1.2859 - val_acc: 0.9074\n",
      "Epoch 3522/10000\n",
      "216/216 [==============================] - 0s 111us/step - loss: 3.8175e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3523/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.8111e-06 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.9074\n",
      "Epoch 3524/10000\n",
      "216/216 [==============================] - 0s 88us/step - loss: 3.8042e-06 - acc: 1.0000 - val_loss: 1.2871 - val_acc: 0.9074\n",
      "Epoch 3525/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.7882e-06 - acc: 1.0000 - val_loss: 1.2870 - val_acc: 0.9074\n",
      "Epoch 3526/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.7728e-06 - acc: 1.0000 - val_loss: 1.2854 - val_acc: 0.9074\n",
      "Epoch 3527/10000\n",
      "216/216 [==============================] - 0s 134us/step - loss: 3.7634e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3528/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.7504e-06 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.9074\n",
      "Epoch 3529/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.7372e-06 - acc: 1.0000 - val_loss: 1.2883 - val_acc: 0.9074\n",
      "Epoch 3530/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.7215e-06 - acc: 1.0000 - val_loss: 1.2863 - val_acc: 0.9074\n",
      "Epoch 3531/10000\n",
      "216/216 [==============================] - 0s 125us/step - loss: 3.7126e-06 - acc: 1.0000 - val_loss: 1.2869 - val_acc: 0.9074\n",
      "Epoch 3532/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.6963e-06 - acc: 1.0000 - val_loss: 1.2865 - val_acc: 0.9074\n",
      "Epoch 3533/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.6870e-06 - acc: 1.0000 - val_loss: 1.2863 - val_acc: 0.9074\n",
      "Epoch 3534/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.6710e-06 - acc: 1.0000 - val_loss: 1.2842 - val_acc: 0.9074\n",
      "Epoch 3535/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6607e-06 - acc: 1.0000 - val_loss: 1.2871 - val_acc: 0.9074\n",
      "Epoch 3536/10000\n",
      "216/216 [==============================] - 0s 120us/step - loss: 3.6494e-06 - acc: 1.0000 - val_loss: 1.2862 - val_acc: 0.9074\n",
      "Epoch 3537/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6445e-06 - acc: 1.0000 - val_loss: 1.2860 - val_acc: 0.9074\n",
      "Epoch 3538/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6243e-06 - acc: 1.0000 - val_loss: 1.2851 - val_acc: 0.9074\n",
      "Epoch 3539/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.6207e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3540/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.6089e-06 - acc: 1.0000 - val_loss: 1.2856 - val_acc: 0.9074\n",
      "Epoch 3541/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.5835e-06 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.9074\n",
      "Epoch 3542/10000\n",
      "216/216 [==============================] - 0s 83us/step - loss: 3.5724e-06 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.9074\n",
      "Epoch 3543/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.5639e-06 - acc: 1.0000 - val_loss: 1.2862 - val_acc: 0.9074\n",
      "Epoch 3544/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.5603e-06 - acc: 1.0000 - val_loss: 1.2868 - val_acc: 0.9074\n",
      "Epoch 3545/10000\n",
      "216/216 [==============================] - 0s 97us/step - loss: 3.5435e-06 - acc: 1.0000 - val_loss: 1.2857 - val_acc: 0.9074\n",
      "Epoch 3546/10000\n",
      "216/216 [==============================] - 0s 93us/step - loss: 3.5294e-06 - acc: 1.0000 - val_loss: 1.2858 - val_acc: 0.9074\n",
      "Epoch 3547/10000\n",
      "216/216 [==============================] - 0s 102us/step - loss: 3.5258e-06 - acc: 1.0000 - val_loss: 1.2870 - val_acc: 0.9074\n",
      "Epoch 3548/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.5048e-06 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.9074\n",
      "Epoch 3549/10000\n",
      "216/216 [==============================] - 0s 116us/step - loss: 3.4941e-06 - acc: 1.0000 - val_loss: 1.2877 - val_acc: 0.9074\n",
      "Epoch 3550/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 102us/step - loss: 3.4866e-06 - acc: 1.0000 - val_loss: 1.2852 - val_acc: 0.9074\n",
      "Epoch 3551/10000\n",
      "216/216 [==============================] - ETA: 0s - loss: 4.4048e-06 - acc: 1.000 - 0s 167us/step - loss: 3.4805e-06 - acc: 1.0000 - val_loss: 1.2873 - val_acc: 0.9074\n",
      "Epoch 3552/10000\n",
      "216/216 [==============================] - 0s 130us/step - loss: 3.4648e-06 - acc: 1.0000 - val_loss: 1.2859 - val_acc: 0.9074\n",
      "Epoch 3553/10000\n",
      "216/216 [==============================] - 0s 106us/step - loss: 3.4626e-06 - acc: 1.0000 - val_loss: 1.2852 - val_acc: 0.9074\n",
      "Epoch 3554/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d7f3c2e7ee53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cesar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for neurons in range(1,51):\n",
    "neurons = 20\n",
    "model = Sequential()\n",
    "\n",
    "classes = 27\n",
    "# hidden_layers = 0\n",
    "# neurons = [25] * hidden_layers\n",
    "# neurons = 1\n",
    "epochs = 10000\n",
    "\n",
    "# Camada de entrada\n",
    "model.add(Dense(units=neurons, activation='sigmoid', input_dim=30))\n",
    "\n",
    "model.add(Dense(units=10, activation='sigmoid'))\n",
    "# model.add(Dropout(0.2))\n",
    "# Camadas escondidas\n",
    "# for i in range(hidden_layers):\n",
    "#     model.add(Dense(units=neurons[i], activation='sigmoid'))\n",
    "\n",
    "# Camada de saída\\\n",
    "model.add(Dense(units=classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size = 20, validation_data=(X_val, y_val), verbose=1)\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "with open('variacao_neuronios_completo/' + str(neurons) + '_neurons.pickle', 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# model.save('modelo_alfabeto_treinado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_acc_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = []\n",
    "for i in range(1,6):\n",
    "    with open('variacao_neuronios/'+str(i)+'_neurons.pickle', 'rb') as handle:\n",
    "        history = pickle.load(handle)\n",
    "        \n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    legend = legend + ['Treinamento ' + str(i), 'Teste '+ str(i)]\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.legend(legend, loc='best')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Dados_continuo3'\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "files_list = os.listdir(directory)\n",
    "    \n",
    "stats = []\n",
    "# all_dataframe = {}\n",
    "\n",
    "for f in files_list:\n",
    "    print(len(dataset))\n",
    "    with open(directory+\"/\"+f) as file:\n",
    "        lines = [line.strip() for line in file]\n",
    "        lines = ast.literal_eval(lines[0])\n",
    "        test = pd.DataFrame(lines)\n",
    "#         d = {'media':test.mean(), 'desvio_padrao': test.std(), 'max': test.max(), 'min': test.min()}\n",
    "\n",
    "#         stats.append(pd.DataFrame(d))\n",
    "        dataset = dataset.append(test, ignore_index = True)\n",
    "\n",
    "#         if letra not in all_dataframe:\n",
    "#             all_dataframe[letra] = []\n",
    "#         all_dataframe[letra].append(test)\n",
    "dataset  = dataset/16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_df = dataset.diff(axis = 0, periods = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot(dif_df.iloc[:,:].pow(2).sum(axis=1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot(dataset.iloc[:,:].pow(2).sum(axis=1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Dados_continuo4'\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "files_list = os.listdir(directory)\n",
    "    \n",
    "stats = []\n",
    "# all_dataframe = {}\n",
    "\n",
    "for f in files_list:\n",
    "    print(len(dataset))\n",
    "    with open(directory+\"/\"+f) as file:\n",
    "        lines = [line.strip() for line in file]\n",
    "        lines = ast.literal_eval(lines[0])\n",
    "        test = pd.DataFrame(lines)\n",
    "#         d = {'media':test.mean(), 'desvio_padrao': test.std(), 'max': test.max(), 'min': test.min()}\n",
    "\n",
    "#         stats.append(pd.DataFrame(d))\n",
    "        dataset = dataset.append(test, ignore_index = True)\n",
    "\n",
    "#         if letra not in all_dataframe:\n",
    "#             all_dataframe[letra] = []\n",
    "#         all_dataframe[letra].append(test)\n",
    "dataset  = dataset/16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_df = dataset.diff(axis = 0, periods = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot(dif_df.iloc[:,:].abs().sum(axis=1).rolling(window=15).mean())\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot(dataset.iloc[:,:].abs().sum(axis=1).rolling(window=15).mean())\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.plot(prevs)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('modelo_alfabeto_treinado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors = get_incorrects(model, X_DT, y_DT)\n",
    "\n",
    "p = model.predict(dataset)\n",
    "    \n",
    "# errors = []\n",
    "# for i in range(len(data)):\n",
    "#     equal = (np.where(labels[i] == np.amax(labels[i]))[0][0]) == (np.where(p[i] == np.amax(p[i])))[0][0]\n",
    "#     if not equal:\n",
    "#         print((np.where(labels[i] == np.amax(labels[i]))[0][0]), (np.where(p[i] == np.amax(p[i])))[0][0])\n",
    "#         print()\n",
    "#         errors.append(i)\n",
    "\n",
    "# print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevs = []\n",
    "for a in range(len(p)):\n",
    "    prev = np.where(p[a] == np.amax(p[a]))[0][0]\n",
    "    prevs.append(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
